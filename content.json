[{"title":"HDFS","date":"2020-07-26T13:17:31.000Z","path":"2020/07/26/HDFS/","text":"介绍&emsp;&emsp;在现代的企业环境中，单机容量往往无法存储大量数据，需要跨机器存储。统一管理分布在集群上的文件系统称为分布式文件系统。而一旦在系统中，引入网络，就不可避免地引入了所有网络编程的复杂性，例如挑战之一是如果保证在节点不可用的时候数据不丢失。 &emsp;&emsp;传统的网络文件系统（NFS）虽然也称为分布式文件系统，但是其存在一些限制。由于NFS中，文件是存储在单机上，因此无法提供可靠性保证，当很多客户端同时访问NFS Server时，很容易造成服务器压力，造成性能瓶颈。另外如果要对NFS中的文件中进行操作，需要首先同步到本地，这些修改在同步到服务端之前，其他客户端是不可见的。某种程度上，NFS不是一种典型的分布式系统，虽然它的文件的确放在远端（单一）的服务器上面。 &emsp;&emsp;从NFS的协议栈可以看到，它事实上是一种VFS（操作系统对文件的一种抽象）实现。 &emsp;&emsp;HDFS，是Hadoop Distributed File System的简称，是Hadoop抽象文件系统的一种实现。Hadoop抽象文件系统可以与本地系统、Amazon S3等集成，甚至可以通过Web协议（webhsfs）来操作。HDFS的文件分布在集群机器上，同时提供副本进行容错及可靠性保证。例如客户端写入读取文件的直接操作都是分布在集群各个机器上的，没有单点性能压力。 设计原则设计目标 存储非常大的文件 这里非常大指的是几百M、G、或者TB级别。实际应用中已有很多集群存储的数据达到PB级别。根据Hadoop官网，Yahoo！的Hadoop集群约有10万颗CPU，运行在4万个机器节点上。更多世界上的Hadoop集群使用情况，参考Hadoop官网. 采用流式的数据访问方式 HDFS基于这样的一个假设：最有效的数据处理模式是一次写入、多次读取数据集经常从数据源生成或者拷贝一次，然后在其上做很多分析工作分析工作经常读取其中的大部分数据，即使不是全部。 因此读取整个数据集所需时间比读取第一条记录的延时更重要。 运行于商业硬件上 Hadoop不需要特别贵的、reliable的机器，可运行于普通商用机器（可以从多家供应商采购） 商用机器不代表低端机器在集群中（尤其是大的集群），节点失败率是比较高的HDFS的目标是确保集群在节点失败的时候不会让用户感觉到明显的中断。 不适用的场景 低延时的数据访问 对延时要求在毫秒级别的应用，不适合采用HDFS。HDFS是为高吞吐数据传输设计的,因此可能牺牲延时HBase更适合低延时的数据访问。 大量小文件 文件的元数据（如目录结构，文件block的节点列表，block-node mapping）保存在NameNode的内存中， 整个文件系统的文件数量会受限于NameNode的内存大小。经验而言，一个文件/目录/文件块一般占有150字节的元数据内存空间。如果有100万个文件，每个文件占用1个文件块，则需要大约300M的内存。因此十亿级别的文件数量在现有商用机器上难以支持。 多方读写，需要任意的文件修改 HDFS采用追加（append-only）的方式写入数据。不支持文件任意offset的修改。不支持多个写入器（writer）。 架构设计 &emsp;&emsp;HDFS 是一个主从结构，一个 HDFS 集群有一个名字节点，它是一个管理文件命名空间和调节客户端访问文件的主服务器，当然还有一些数据节点，通常是一个节点一个机器，它来管理对应节点的存储。HDFS 对外开放文件命名空间并允许用户数据以文件形式存储。 &emsp;&emsp;内部机制是将一个文件分割成一个或多个块，这些块被存储在一组数据节点中。名字节点用来操作文件命名空间的文件或目录操作，如打开、关闭、重命名等等。它同时确定块与数据节点的映射。数据节点来负责来自文件系统客户的读写请求。数据节点同时还要执行块的创建、删除、和来自名字节点的块复制指令。 &emsp;&emsp;集群中只有一个名字节点极大地简单化了系统的体系结构。名字节点是仲裁者和所有 HDFS 元数据的仓库，用户的实际数据不经过名字节点。 基础结构Namenode&emsp;&emsp;Namenode存放文件系统树及所有文件、目录的元数据。元数据持久化为2种形式： namespcae image edit log &emsp;&emsp;但是持久化数据中不包括Block所在的节点列表，及文件的Block分布在集群中的哪些节点上，这些信息是在系统重启的时候重新构建（通过Datanode汇报的Block信息）。在HDFS中，Namenode可能成为集群的单点故障，Namenode不可用时，整个文件系统是不可用的。HDFS针对单点故障提供了2种解决机制： 备份持久化元数据 将文件系统的元数据同时写到多个文件系统， 例如同时将元数据写到本地文件系统及NFS。这些备份操作都是同步的、原子的。 Secondary Namenode Secondary节点定期合并主Namenode的namespace image和edit log， 避免edit log过大，通过创建检查点checkpoint来合并。它会维护一个合并后的namespace image副本， 可用于在Namenode完全崩溃时恢复数据。Secondary Namenode通常运行在另一台机器，因为合并操作需要耗费大量的CPU和内存。其数据落后于Namenode，因此当Namenode完全崩溃时，会出现数据丢失。 通常做法是拷贝NFS中的备份元数据到Second，将其作为新的主Namenode。在HA中可以运行一个Hot Standby，作为热备份，在Active Namenode故障之后，替代原有Namenode成为Active Namenode。 Datanode&emsp;&emsp;数据节点负责存储和提取Block，读写请求可能来自namenode，也可能直接来自客户端。数据节点周期性向Namenode汇报自己节点上所存储的Block相关信息。 副本技术&emsp;&emsp;副本技术即分布式数据复制技术，是分布式计算的一个重要组成部分。该技术允许数据在多个服务器端共享，一个本地服务器可以存取不同物理地点的远程服务器上的数据，也可以使所有的服务器均持有数据的拷贝。 优点通过过副本技术可以有以下优点： 提高系统可靠性 系统不可避免的会产生故障和错误，拥有多个副本的文件系统不会导致无法访问的情况，从而提高了系统的可用性。另外，系统可以通过其他完好的副本对发生错误的副本进行修复，从而提高了系统的容错性。 负载均衡 副本可以对系统的负载量进行扩展。多个副本存放在不同的服务器上，可有效的分担工作量，从而将较大的工作量有效的分布在不同的站点上。 提高访问效率 将副本创建在访问频度较大的区域，即副本在访问节点的附近，相应减小了其通信开销，从而提高了整体的访问效率。 数据复制&emsp;&emsp;HDFS 设计成能可靠地在集群中大量机器之间存储大量的文件，它以块序列的形式存储文件。文件中除了最后一个块，其他块都有相同的大小。属于文件的块为了故障容错而被复制。块的大小和复制数是以文件为单位进行配置的，应用可以在文件创建时或者之后修改复制因子。HDFS 中的文件是一次写的，并且任何时候都只有一个写操作。&emsp;&emsp;名字节点负责处理与所有的块复制相关的决策。它周期性地接受集群中数据节点的心跳和块报告。一个心跳的到达表示这个数据节点是正常的。一个块报告包括该数据节点上所有块的列表。 副本放置策略&emsp;&emsp;块副本存放位置的选择严重影响 HDFS 的可靠性和性能。HDFS 采用机架敏感（rack awareness）的副本存放策略来提高数据的可靠性、可用性和网络带宽的利用率。 &emsp;&emsp;HDFS 运行在跨越大量机架的集群之上。两个不同机架上的节点是通过交换机实现通信的，在大多数情况下，相同机架上机器间的网络带宽优于在不同机架上的机器。&emsp;&emsp;在开始的时候，每一个数据节点自检它所属的机架 id，然后在向名字节点注册的时候告知它的机架 id。HDFS 提供接口以便很容易地挂载检测机架标示的模块。一个简单但不是最优的方式就是将副本放置在不同的机架上，这就防止了机架故障时数据的丢失，并且在读数据的时候可以充分利用不同机架的带宽。这个方式均匀地将复制分散在集群中，这就简单地实现了组建故障时的负载均衡。然而这种方式增加了写的成本，因为写的时候需要跨越多个机架传输文件块。 &emsp;&emsp;HDFS的副本的存放策略是可靠性、写带宽、读带宽之间的权衡。默认策略如下： 第一个副本放在客户端相同的机器上，如果机器在集群之外，随机选择一个（但是会尽可能选择容量不是太慢或者当前操作太繁忙的） 第二个副本随机放在不同于第一个副本的机架上。 第三个副本放在跟第二个副本同一机架上，但是不同的节点上，满足条件的节点中随机选择。 更多的副本在整个集群上随机选择，虽然会尽量便面太多副本在同一机架上。 高可用&emsp;&emsp;在Hadoop 1.x 中，Namenode是集群的单点故障，一旦Namenode出现故障，整个集群将不可用，重启或者开启一个新的Namenode才能够从中恢复。值得一提的是，Secondary Namenode并没有提供故障转移的能力。集群的可用性受到影响表现在： 当机器发生故障，如断电时，管理员必须重启Namenode才能恢复可用。 在日常的维护升级中，需要停止Namenode，也会导致集群一段时间不可用。 架构&emsp;&emsp;Hadoop HA（High Available）通过同时配置两个处于Active/Passive模式的Namenode来解决上述问题，分别叫Active Namenode和Standby Namenode. Standby Namenode作为热备份，从而允许在机器发生故障时能够快速进行故障转移，同时在日常维护的时候使用优雅的方式进行Namenode切换。Namenode只能配置一主一备，不能多于两个Namenode。 &emsp;&emsp;主Namenode处理所有的操作请求（读写），而Standby只是作为slave，维护尽可能同步的状态，使得故障时能够快速切换到Standby。为了使Standby Namenode与Active Namenode数据保持同步，两个Namenode都与一组Journal Node进行通信。当主Namenode进行任务的namespace操作时，都会确保持久会修改日志到Journal Node节点中的大部分。Standby Namenode持续监控这些edit，当监测到变化时，将这些修改应用到自己的namespace。 &emsp;&emsp;当进行故障转移时，Standby在成为Active Namenode之前，会确保自己已经读取了Journal Node中的所有edit日志，从而保持数据状态与故障发生前一致。 &emsp;&emsp;为了确保故障转移能够快速完成，Standby Namenode需要维护最新的Block位置信息，即每个Block副本存放在集群中的哪些节点上。为了达到这一点，Datanode同时配置主备两个Namenode，并同时发送Block报告和心跳到两台Namenode。 &emsp;&emsp;确保任何时刻只有一个Namenode处于Active状态非常重要，否则可能出现数据丢失或者数据损坏。当两台Namenode都认为自己的Active Namenode时，会同时尝试写入数据（不会再去检测和同步数据）。为了防止这种脑裂现象，Journal Nodes只允许一个Namenode写入数据，内部通过维护epoch数来控制，从而安全地进行故障转移。 有两种方式可以进行edit log共享： 使用NFS共享edit log（存储在NAS/SAN） 使用QJM共享edit log NFS &emsp;&emsp;如图所示，NFS作为主备Namenode的共享存储。这种方案可能会出现脑裂（split-brain），即两个节点都认为自己是主Namenode并尝试向edit log写入数据，这可能会导致数据损坏。通过配置fencin脚本来解决这个问题，fencing脚本用于： 将之前的Namenode关机 禁止之前的Namenode继续访问共享的edit log文件 使用这种方案，管理员就可以手工触发Namenode切换，然后进行升级维护。但这种方式存在以下问题： 只能手动进行故障转移，每次故障都要求管理员采取措施切换。 NAS/SAN设置部署复杂，容易出错，且NAS本身是单点故障。 Fencing 很复杂，经常会配置错误。 无法解决意外（unplanned）事故，如硬件或者软件故障 因此需要另一种方式来处理这些问题： 自动故障转移（引入ZooKeeper达到自动化） 移除对外界软件硬件的依赖（NAS/SAN） 同时解决意外事故及日常维护导致的不可用 Quorum + ZooKeeper&emsp;&emsp;QJM（Quorum Journal Manager）是Hadoop专门为Namenode共享存储开发的组件。其集群运行一组Journal Node，每个Journal 节点暴露一个简单的RPC接口，允许Namenode读取和写入数据，数据存放在Journal节点的本地磁盘。当Namenode写入edit log时，它向集群的所有Journal Node发送写入请求，当多数节点回复确认成功写入之后，edit log就认为是成功写入。例如有3个Journal Node，Namenode如果收到来自2个节点的确认消息，则认为写入成功。 &emsp;&emsp;而在故障自动转移的处理上，引入了监控Namenode状态的ZookeeperFailController（ZKFC）。ZKFC一般运行在Namenode的宿主机器上，与Zookeeper集群协作完成故障的自动转移。整个集群架构图如下： QJM&emsp;&emsp;Namenode使用QJM 客户端提供的RPC接口与Namenode进行交互。写入edit log时采用基于仲裁的方式，即数据必须写入JournalNode集群的大部分节点。服务端Journal运行轻量级的守护进程，暴露RPC接口供客户端调用。实际的edit log数据保存在Journal Node本地磁盘。架构图如下： &emsp;&emsp;Journal Node通过epoch数来解决脑裂的问题，称为JournalNode fencing。具体工作原理如下： 当Namenode变成Active状态时，被分配一个整型的epoch数，这个epoch数是独一无二的，并且比之前所有Namenode持有的epoch number都高。 当Namenode向Journal Node发送消息的时候，同时也带上了epoch。当Journal Node收到消息时，将收到的epoch数与存储在本地的promised epoch比较，如果收到的epoch比自己的大，则使用收到的epoch更新自己本地的epoch数。如果收到的比本地的epoch小，则拒绝请求。 edit log必须写入大部分节点才算成功，也就是其epoch要比大多数节点的epoch高。 这种方式解决了NFS方式的3个问题： 不需要额外的硬件，使用原有的物理机 Fencing通过epoch数来控制，避免出错。 自动故障转移：Zookeeper处理该问题。 基于Zookeeper自动故障转移&emsp;&emsp;前面提到，为了支持故障转移，Hadoop引入两个新的组件：Zookeeper Quorum和ZKFailoverController process（简称ZKFC）。 &emsp;&emsp;Zookeeper的任务包括： 失败检测 每个Namnode都在ZK中维护一个持久性session，如果Namnode故障，session过期，使用zk的事件机制通知其他Namenode需要故障转移。 Namenode选举 如果当前Active namenode挂了，另一个namenode会尝试获取ZK中的一个排它锁，获取这个锁就表名它将成为下一个Active NN。 &emsp;&emsp;在每个Namenode守护进程的机器上，同时也会运行一个ZKFC，用于完成以下任务： Namenode健康健康 ZK Session管理 基于ZK的Namenode选举 &emsp;&emsp;如果ZKFC所在机器的Namenode健康状态良好，并且用于选举的znode锁未被其他节点持有，则ZKFC会尝试获取锁,成功获取这个排它锁就代表获得选举，获得选举之后负责故障转移，如果有必要，会fencing掉之前的namenode使其不可用，然后将自己的namenode切换为Active状态。 读写流程读流程 客户端传递一个文件Path给FileSystem的open方法 DFS采用RPC远程获取文件最开始的几个block的datanode地址。Namenode会根据网络拓扑结构决定返回哪些节点（前提是节点有block副本），如果客户端本身是Datanode并且节点上刚好有block副本，直接从本地读取。 客户端使用open方法返回的FSDataInputStream对象读取数据（调用read方法） DFSInputStream（FSDataInputStream实现了改类）连接持有第一个block的、最近的节点，反复调用read方法读取数据 第一个block读取完毕之后，寻找下一个block的最佳datanode，读取数据。如果有必要，DFSInputStream会联系Namenode获取下一批Block 的节点信息(存放于内存，不持久化），这些寻址过程对客户端都是不可见的。 数据读取完毕，客户端调用close方法关闭流对象 &emsp;&emsp;在读数据过程中，如果与Datanode的通信发生错误，DFSInputStream对象会尝试从下一个最佳节点读取数据，并且记住该失败节点， 后续Block的读取不会再连接该节点。&emsp;&emsp;读取一个Block之后，DFSInputStram会进行检验和验证，如果Block损坏，尝试从其他节点读取数据，并且将损坏的block汇报给Namenode。&emsp;&emsp;客户端连接哪个datanode获取数据，是由namenode来指导的，这样可以支持大量并发的客户端请求，namenode尽可能将流量均匀分布到整个集群。&emsp;&emsp;Block的位置信息是存储在namenode的内存中，因此相应位置请求非常高效，不会成为瓶颈。 写流程 通过Client向远程的NameNode发送RPC请求； 接收到请求后NameNode会首先判断对应的文件是否存在以及用户是否有对应的权限，成功则会为文件创建一个记录，否则会让客户端抛出异常； 当客户端开始写入文件的时候，开发库会将文件切分成多个packets，并在内部以”data queue”的形式管理这些packets，并向Namenode申请新的blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。 开始以pipeline（管道）的形式将packet写入所有的replicas中。开发库把packet以流的方式写入第一个 datanode，该datanode把该packet存储之后，再将其传递给在此pipeline中的下一个datanode，直到最后一个 datanode， 这种写数据的方式呈流水线的形式。 最后一个datanode成功存储之后会返回一个ack packet，在pipeline里传递至客户端，在客户端的开发库内部维护着 “ack queue”，成功收到datanode返回的ack packet后会从”ack queue”移除相应的packet。 如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的 pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的 datanode，保持replicas设定的数量。 DFSOutputStream&emsp;&emsp;打开一个DFSOutputStream流，Client会写数据到流内部的一个缓冲区中，然后数据被分解成多个Packet，每个Packet大小为64k字节，每个Packet又由一组chunk和这组chunk对应的checksum数据组成，默认chunk大小为512字节，每个checksum是对512字节数据计算的校验和数据。 &emsp;&emsp;当Client写入的字节流数据达到一个Packet的长度，这个Packet会被构建出来，然后会被放到队列dataQueue中，接着DataStreamer线程会不断地从dataQueue队列中取出Packet，发送到复制Pipeline中的第一个DataNode上，并将该Packet从dataQueue队列中移到ackQueue队列中。ResponseProcessor线程接收从Datanode发送过来的ack，如果是一个成功的ack，表示复制Pipeline中的所有Datanode都已经接收到这个Packet，ResponseProcessor线程将packet从队列ackQueue中删除。 &emsp;&emsp;在发送过程中，如果发生错误，所有未完成的Packet都会从ackQueue队列中移除掉，然后重新创建一个新的Pipeline，排除掉出错的那些DataNode节点，接着DataStreamer线程继续从dataQueue队列中发送Packet。 &emsp;&emsp;下面是DFSOutputStream的结构及其原理，如图所示：从下面3个方面来描述内部流程： 创建Packet Client写数据时，会将字节流数据缓存到内部的缓冲区中，当长度满足一个Chunk大小（512B）时，便会创建一个Packet对象，然后向该Packet对象中写Chunk Checksum校验和数据，以及实际数据块Chunk Data，校验和数据是基于实际数据块计算得到的。每次满足一个Chunk大小时，都会向Packet中写上述数据内容，直到达到一个Packet对象大小（64K），就会将该Packet对象放入到dataQueue队列中，等待DataStreamer线程取出并发送到DataNode节点。 发送Packet DataStreamer线程从dataQueue队列中取出Packet对象，放到ackQueue队列中，然后向DataNode节点发送这个Packet对象所对应的数据。 接收ack 发送一个Packet数据包以后，会有一个用来接收ack的ResponseProcessor线程，如果收到成功的ack，则表示一个Packet发送成功。如果成功，则ResponseProcessor线程会将ackQueue队列中对应的Packet删除。","tags":[{"name":"大数据","slug":"大数据","permalink":"http://langonggong.com/tags/大数据/"},{"name":"HDFS","slug":"HDFS","permalink":"http://langonggong.com/tags/HDFS/"}]},{"title":"YARN","date":"2020-07-26T05:48:00.000Z","path":"2020/07/26/YARN/","text":"基本服务组件&nbsp;&nbsp;&nbsp;&nbsp;YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源管理器ResourceManager和每个应用程序特有的ApplicationMaster。其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。 &nbsp;&nbsp;&nbsp;&nbsp;YARN总体上仍然是master/slave结构，在整个资源管理框架中，resourcemanager为master，nodemanager是slave。Resourcemanager负责对各个nademanger上资源进行统一管理和调度。当用户提交一个应用程序时，需要提供一个用以跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManger启动可以占用一定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。 &nbsp;&nbsp;&nbsp;&nbsp;YARN的基本组成结构，YARN主要由ResourceManager、NodeManager、ApplicationMaster和Container等几个组件构成。 &nbsp;&nbsp;&nbsp;&nbsp;ResourceManager是Master上一个独立运行的进程，负责集群统一的资源管理、调度、分配等等；NodeManager是Slave上一个独立运行的进程，负责上报节点的状态；App Master和Container是运行在Slave上的组件，Container是yarn中分配资源的一个单位，包涵内存、CPU等等资源，yarn以Container为单位分配资源。Client向ResourceManager提交的每一个应用程序都必须有一个Application Master，它经过ResourceManager分配资源后，运行于某一个Slave节点的Container中，具体做事情的Task，同样也运行与某一个Slave节点的Container中。RM，NM，AM乃至普通的Container之间的通信，都是用RPC机制。 &nbsp;&nbsp;&nbsp;&nbsp;YARN的架构设计使其越来越像是一个云操作系统，数据处理操作系统。 Resourcemanager&nbsp;&nbsp;&nbsp;&nbsp;RM是一个全局的资源管理器，集群只有一个，负责整个系统的资源管理和分配，包括处理客户端请求、启动/监控APP master、监控nodemanager、资源的分配与调度。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，ASM）。 调度器 调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。 应用程序管理器 应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。 ApplicationMaster（AM）管理YARN内运行的应用程序的每个实例。功能： 数据切分 为应用程序申请资源并进一步分配给内部任务。 任务监控与容错 负责协调来自resourcemanager的资源，并通过nodemanager监视容易的执行和资源使用情况。 NodeManager（NM）Nodemanager整个集群有多个，负责每个节点上的资源和使用。功能： 单个节点上的资源管理和任务。 处理来自于resourcemanager的命令。 处理来自域app master的命令。 Nodemanager管理着抽象容器，这些抽象容器代表着一些特定程序使用针对每个节点的资源。Nodemanager定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态（cpu和内存等资源） ContainerContainer是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。需要注意的是，Container不同于MRv1中的slot，它是一个动态资源划分单位，是根据应用程序的需求动态生成的。目前为止，YARN仅支持CPU和内存两种资源，且使用了轻量级资源隔离机制Cgroups进行资源隔离。功能： 对task环境的抽象 描述一系列信息 任务运行资源的集合（cpu、内存、io等） 任务运行环境 运行流程 客户端向RM中提交程序 RM向NM中分配一个container，并在该container中启动AM AM向RM注册，这样用户可以直接通过RM査看应用程序的运行状态(然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束) AM采用轮询的方式通过RPC协议向RM申请和领取资源，资源的协调通过异步完成 AM申请到资源后，便与对应的NM通信，要求它启动任务 NM为任务设置好运行环境(包括环境变量、JAR包、二进制程序等)后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务 各个任务通过某个RPC协议向AM汇报自己的状态和进度，以让AM随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务 应用程序运行完成后，AM向RM注销并关闭自己 调度器FIFO Scheduler(先进先出调度器)&nbsp;&nbsp;&nbsp;&nbsp;FIFO Scheduler把应用按提交的顺序排成一个队列，这是一个先进先出队列，在进行资源分配的时候，先给队列中最头上的应用进行分配资源，待最头上的应用需求满足后再给下一个分配，以此类推。FIFO Scheduler是最简单也是最容易理解的调度器，也不需要任何配置，但它并不适用于共享集群。大的应用可能会占用所有集群资源，这就导致其它应用被阻塞。在共享集群中，更适合采用Capacity Scheduler或Fair Scheduler，这两个调度器都允许大任务和小任务在提交的同时获得一定的系统资源。下面“Yarn调度器对比图”展示了这几个调度器的区别，从图中可以看出，在FIFO 调度器中，小任务会被大任务阻塞。 Capacity Scheduler(容量调度器)&nbsp;&nbsp;&nbsp;&nbsp;yarn-site.xml中默认配置的资源调度器。而对于Capacity调度器，有一个专门的队列用来运行小任务，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间。用这个资源调度器，就可以配置yarn资源队列，这个后面后介绍用到。 FairS cheduler(公平调度器)&nbsp;&nbsp;&nbsp;&nbsp;Fair调度器的设计目标是为所有的应用分配公平的资源（对公平的定义可以通过参数来设置）。在上面的“Yarn调度器对比图”展示了一个队列中两个应用的公平调度；当然，公平调度在也可以在多个队列间工作。举个例子，假设有两个用户A和B，他们分别拥有一个队列。当A启动一个job而B没有任务时，A会获得全部集群资源；当B启动一个job后，A的job会继续运行，不过一会儿之后两个任务会各自获得一半的集群资源。如果此时B再启动第二个job并且其它job还在运行，则它将会和B的第一个job共享B这个队列的资源，也就是B的两个job会用于四分之一的集群资源，而A的job仍然用于集群一半的资源，结果就是资源最终在两个用户之间平等的共享。在Fair调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。 公平调度器，就是能够共享整个集群的资源 不用预先占用资源，每一个作业都是共享的 每当提交一个作业的时候，就会占用整个资源。如果再提交一个作业，那么第一个作业就会分给第二个作业一部分资源，第一个作业也就释放一部分资源。再提交其他的作业时，也同理。。。。也就是说每一个作业进来，都有机会获取资源。 假设我们有如下层次的队列 root prod dev mapreduce spark &nbsp;&nbsp;&nbsp;&nbsp;下面是一个简单的 Capacity 调度器的配置文件，文件名为 capacity-scheduler.xml。 &nbsp;&nbsp;&nbsp;&nbsp;在这个配置中，在 root 队列下面定义了两个子队列 prod 和 dev，分别占 40%和 60%的容量。需要注意，一个队列的配置是通过属性 yarn.sheduler.capacity..指定的，代表的是队列的继承树，如 root.prod 队列，一般指 capacity 和 maximum-capacity。 123456789101112131415161718192021222324252627282930&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt; &lt;value&gt;prod,dev&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.queues&lt;/name&gt; &lt;value&gt;mapreduce,spark&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.prod.capacity&lt;/name&gt; &lt;value&gt;40&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.capacity&lt;/name&gt; &lt;value&gt;60&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.maximum-capacity&lt;/name&gt; &lt;value&gt;75&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.mapreduce.capacity&lt;/name&gt; &lt;value&gt;50&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.spark.capacity&lt;/name&gt; &lt;value&gt;50&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; &nbsp;&nbsp;&nbsp;&nbsp;dev 队列又被分成了 mapreduce 和 spark 两个相同容量的子队列。dev的 maximum-capacity 属性被设置成了 75%，所以即使 prod 队列完全空闲 dev 也不会占用全部集群资源，也就是说，prod 队列仍有 25%的可用资源用来应急。我们注意到，mapreduce和 spark 两个队列没有设置 maximum-capacity 属性，也就是说 mapreduce 或 spark 队列中的 job 可能会用到整个 dev 队列的所有资源（最多为集群的 75%）。而类似的，prod 由于没有设置 maximum-capacity 属性，它有可能会占用集群全部资源。 &nbsp;&nbsp;&nbsp;&nbsp;关于队列的设置，这取决于我们具体的应用。比如，在 MapReduce 中，我们可以通过mapreduce.job.queuename 属性指定要用的队列。如果队列不存在，我们在提交任务时就会收到错误。如果我们没有定义任何队列，所有的应用将会放在一个 default 队列中。","tags":[{"name":"YARN","slug":"YARN","permalink":"http://langonggong.com/tags/YARN/"},{"name":"大数据","slug":"大数据","permalink":"http://langonggong.com/tags/大数据/"}]},{"title":"spark简介","date":"2020-06-22T15:10:25.000Z","path":"2020/06/22/spark简介/","text":"简介Spark 是使用 scala 实现的基于内存计算的大数据开源集群计算环境。提供了 java,scala, python,R 等语言的调用接口 Hadoop 和 Spark 的关系Google 在 2003 年和 2004 年先后发表了 Google 文件系统 GFS 和 MapReduce 编程模型两篇文章。 基于这两篇开源文档,06 年 Nutch 项目子项目之一的 Hadoop 实现了两个强有力的开源产品:HDFS 和 MapReduce. Hadoop 成为了典型的大数据批量处理架构,由 HDFS 负责静态数据的存储,并通过 MapReduce 将计算逻辑分配到各数据节点进行数据计算和价值发现。之后以 HDFS 和 MapReduce 为基础建立了很多项目，形成了 Hadoop 生态圈。 而 Spark 则是UC Berkeley AMP lab (加州大学伯克利分校AMP实验室)所开源的类Hadoop MapReduce的通用并行框架, 专门用于大数据量下的迭代式计算。是为了跟 Hadoop 配合而开发出来的，不是为了取代 Hadoop。Spark 运算比 Hadoop 的 MapReduce 框架快的原因是因为 Hadoop 在一次 MapReduce 运算之后，会将数据的运算结果从内存写入到磁盘中，第二次 Mapredue 运算时在从磁盘中读取数据，所以其瓶颈在2次运算间的多余 IO 消耗.。Spark 则是将数据一直缓存在内存中,直到计算得到最后的结果,再将结果写入到磁盘，所以多次运算的情况下，Spark 是比较快的。其优化了迭代式工作负载 基本模块 Spark Core：包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都是构建在RDD和Spark Core之上的 Spark SQL：提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。 Spark Streaming：对实时数据流进行处理和控制。Spark Streaming允许程序能够像普通RDD一样处理实时数据 MLlib：一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，比如分类、回归等需要对大量数据集进行迭代的操作。 GraphX：控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、创建子图、访问路径上所有顶点的操作 Spark 的主要特点还包括: 提供 Cache 机制来支持需要反复迭代计算或者多次数据共享,减少数据读取的 IO 开销; 提供了一套支持 DAG 图的分布式并行计算的编程框架,减少多次计算之间中间结果写到 Hdfs 的开销; 使用多线程池模型减少 Task 启动开稍, shuffle 过程中避免不必要的 sort 操作并减少磁盘 IO 操作。(Hadoop 的 Map 和 reduce 之间的 shuffle 需要 sort) 总体架构架构设计Spark 集群由集群管理器 Cluster Manager、工作节点 Worker、执行器 Executor、驱动器 Driver、应用程序 Application 等部分组成。 Cluter Manager Spark 的集群管理器，主要负责对整个集群资源的分配和管理。根据部署模式的不同，可以分为如下： Hadoop YARN: 主要是指 YARN 中的 ResourceManager。YARN 是 Hadoop2.0 中引入的集群管理器，可以让多种数据处理框架运行在一个共享的资源池上，让 Spark 运行在配置了 YARN 的集群上是一个非常好的选择，可以利用 YARN 来管理资源。 Apache Mesos：主要是指 Mesos Master。Mesos 起源于Berkeley AMP实验室，是一个通用的集群管理器。能够将CPU、内存、存储以及其它计算资源由设备（物理或虚拟）中抽象出来，形成一个池的逻辑概念，从而实现高容错与弹性分布式系统的轻松构建与高效运行。 Standalone：主要是指 Standalone Master。Standalone Master 是 spark 原生的资源管理，由Master负责资源的分配。 Worker Spark 的工作节点，用于执行提交的作业。在 YARN 部署模式下 Worker 由 NodeManager 代替。Worker 有如下作用： 通过注册机制向 Cluster Master 汇报自身的 cpu 和 memory 等资源 在 Master 的指示下创建启动 Executor，Executor 是执行真正计算的苦力 将资源和任务进一步分配给 Executor 同步资源信息、Executor 状态信息给 Cluster Master Executor真正执行计算任务的组件。Executor 是某个 Application 运行在 Worker 节点上的一个进程，该进程负责运行某些 Task， 并且负责将数据存到内存或磁盘上，每个 Application 都有各自独立的一批 Executor， 在 Spark on Yarn 模式下，其进程名称为 CoarseGrainedExecutor Backend。一个 CoarseGrainedExecutor Backend 有且仅有一个 Executor 对象， 负责将 Task 包装成 taskRunner，并从线程池中抽取一个空闲线程运行 Task， 每个 CoarseGrainedExecutorBackend 能并行运行 Task 的数量取决于分配给它的 CPU 的个数。 DriverApplication 的驱动程序。可以理解为使程序运行中的 main 函数，它会创建 SparkContext。Application 通过 Driver 与 Cluster Master 和 Executor 进行通信。Driver 可以运行在 Application 中，也可以由 Application 提交给 Cluster Master，由 Cluster Master 安排 Worker 运行。Driver 的作用： 运行应用程序的 main 函数 创建 Spark 的上下文 划分 RDD 并生成有向无环图（DAGScheduler） 与 Spark 中的其他组进行协调，协调资源等等（SchedulerBackend） 生成并发送 task 到 executor（taskScheduler） Application用户使用 Spark API 编写的的应用程序，其中包括一个 Driver 功能的代码和分布在集群中多个节点上运行的 Executor 代码。Application 通过 Spark API 创建 RDD，对 RDD 进行转换，创建 DAG，并通过 Driver 将 Application 注册到 Cluster Master。 运行流程 构建Spark Application的运行环境，启动SparkContext SparkContext向资源管理器（可以是Standalone，Mesos，Yarn）申请运行Executor资源，并启动StandaloneExecutorbackend， Executor向SparkContext申请Task SparkContext将应用程序分发给Executor SparkContext构建成DAG图，将DAG图分解成Stage、将Taskset发送给Task Scheduler，最后由Task Scheduler将Task发送给Executor运行 Task在Executor上运行，运行完释放所有资源 Spark运行特点： 每个Application获取专属的executor进程，该进程在Application期间一直驻留，并以多线程方式运行Task。这种Application隔离机制是有优势的，无论是从调度角度看（每个Driver调度他自己的任务），还是从运行角度看（来自不同Application的Task运行在不同JVM中），当然这样意味着Spark Application不能跨应用程序共享数据，除非将数据写入外部存储系统 Spark与资源管理器无关，只要能够获取executor进程，并能保持相互通信就可以了 提交SparkContext的Client应该靠近Worker节点（运行Executor的节点），最好是在同一个Rack里，因为Spark Application运行过程中SparkContext和Executor之间有大量的信息交换 Task采用了数据本地性和推测执行的优化机制 RDD基本概念RDD 是 Spark 提供的最重要的抽象概念，它是一种有容错机制的特殊数据集合，可以分布在集群的结点上，以函数式操作集合的方式进行各种并行操作。 通俗点来讲，可以将 RDD 理解为一个分布式对象集合，本质上是一个只读的分区记录集合。每个 RDD 可以分成多个分区，每个分区就是一个数据集片段。一个 RDD 的不同分区可以保存到集群中的不同结点上，从而可以在集群中的不同结点上进行并行计算。 如图展示了 RDD 的分区及分区与工作结点（Worker Node）的分布关系。 RDD 具有容错机制，并且只读不能修改，可以执行确定的转换操作创建新的 RDD。具体来讲，RDD 具有以下几个属性。 只读：不能修改，只能通过转换操作生成新的 RDD。 分布式：可以分布在多台机器上进行并行处理。 弹性：计算过程中内存不够时它会和磁盘进行数据交换。 基于内存：可以全部或部分缓存在内存中，在多次计算间重用。 RDD 实质上是一种更为通用的迭代并行计算框架，用户可以显示控制计算的中间结果，然后将其自由运用于之后的计算。 在大数据实际应用开发中存在许多迭代算法，如机器学习、图算法等，和交互式数据挖掘工具。这些应用场景的共同之处是在不同计算阶段之间会重用中间结果，即一个阶段的输出结果会作为下一个阶段的输入。 RDD 正是为了满足这种需求而设计的。虽然 MapReduce 具有自动容错、负载平衡和可拓展性的优点，但是其最大的缺点是采用非循环式的数据流模型，使得在迭代计算时要进行大量的磁盘 I/O 操作。 通过使用 RDD，用户不必担心底层数据的分布式特性，只需要将具体的应用逻辑表达为一系列转换处理，就可以实现管道化，从而避免了中间结果的存储，大大降低了数据复制、磁盘 I/O 和数据序列化的开销。 基本操作RDD 的操作分为转化（Transformation）操作和行动（Action）操作。转化操作就是从一个 RDD 产生一个新的 RDD，而行动操作就是进行实际的计算。 RDD 的操作是惰性的，当 RDD 执行转化操作的时候，实际计算并没有被执行，只有当 RDD 执行行动操作时才会促发计算任务提交，从而执行相应的计算操作。 构建操作Spark 里的计算都是通过操作 RDD 完成的，学习 RDD 的第一个问题就是如何构建 RDD，构建 RDD 的方式从数据来源角度分为以下两类。 从内存里直接读取数据。 从文件系统里读取数据，文件系统的种类很多，常见的就是 HDFS 及本地文件系统。 第一类方式是从内存里构造 RDD，需要使用 makeRDD 方法，代码如下所示。 1val rdd01 = sc.makeRDD(List(l,2,3,4,5,6)) 这个语句创建了一个由“1,2,3,4,5,6”六个元素组成的 RDD。 第二类方式是通过文件系统构造 RDD，代码如下所示。 val rdd:RDD[String] == sc.textFile(“file:///D:/sparkdata.txt”,1) 这里例子使用的是本地文件系统，所以文件路径协议前缀是 file://。 转换操作RDD 的转换操作是返回新的 RDD 的操作。转换出来的 RDD 是惰性求值的，只有在行动操作中用到这些 RDD 时才会被计算。 许多转换操作都是针对各个元素的，也就是说，这些转换操作每次只会操作 RDD 中的一个元素，不过并不是所有的转换操作都是这样的。表 1 描述了常用的 RDD 转换操作。 表 1 RDD转换操作（rdd1={1, 2, 3, 3}，rdd2={3,4,5}) 名称 说明 表达式 结果 map() 将函数应用于 RDD 的每个元素，返回值是新的 RDD rdd1.map(x=&gt;x+l) {2,3,4,4} flatMap() 将函数应用于 RDD 的每个元素，将元素数据进行拆分，变成迭代器，返回值是新的 RDD rdd1.flatMap(x=&gt;x.to(3)) {1,2,3,2,3,3,3} filter() 函数会过滤掉不符合条件的元素，返回值是新的 RDD rdd1.filter(x=&gt;x!=1) {2,3,3} distinct() 将 RDD 里的元素进行去重操作 rdd1.distinct() (1,2,3) union() 生成包含两个 RDD 所有元素的新的 RDD rdd1.union(rdd2) {1,2,3,3,3,4,5} intersection() 求出两个 RDD 的共同元素 rdd1.intersection(rdd2) {3} subtract() 将原 RDD 里和参数 RDD 里相同的元素去掉 rdd1.subtract(rdd2) {1,2} cartesian() 求两个 RDD 的笛卡儿积 rdd1.cartesian(rdd2) {(1,3),(1,4)……(3,5)} 行动操作行动操作用于执行计算并按指定的方式输出结果。行动操作接受 RDD，但是返回非 RDD，即输出一个值或者结果。在 RDD 执行过程中，真正的计算发生在行动操作。表 2 描述了常用的 RDD 行动操作。 表 2 RDD 行动操作（rdd={1,2,3,3}） 名称 说明 表达式 结果 collect() 返回 RDD 的所有元素 rdd.collect() {1,2,3,3} count() RDD 里元素的个数 rdd.count() 4 countByValue() 各元素在 RDD 中的出现次数 rdd.countByValue() {(1,1),(2,1),(3,2})} take(num) 从 RDD 中返回 num 个元素 rdd.take(2) {1,2} top(num) 从 RDD 中，按照默认（降序）或者指定的排序返回最前面的 num 个元素 rdd.top(2) {3,3} reduce() 并行整合所有 RDD 数据，如求和操作 rdd.reduce((x,y)=&gt;x+y) 9 fold(zero)(func) 和 reduce() 功能一样，但需要提供初始值 rdd.fold(0)((x,y)=&gt;x+y) 9 foreach(func) 对 RDD 的每个元素都使用特定函数 rdd1.foreach(x=&gt;printIn(x)) 打印每一个元素 saveAsTextFile(path) 将数据集的元素，以文本的形式保存到文件系统中 rdd1.saveAsTextFile(file://home/test) saveAsSequenceFile(path) 将数据集的元素，以顺序文件格式保存到指 定的目录下 saveAsSequenceFile(hdfs://home/test) aggregate() 函数的返回类型不需要和 RDD 中的元素类型一致，所以在使用时，需要提供所期待的返回类型的初始值，然后通过一个函数把 RDD 中的元素累加起来放入累加器。 考虑到每个结点都是在本地进行累加的，所以最终还需要提供第二个函数来将累加器两两合并。 aggregate(zero)(seqOp,combOp) 函数首先使用 seqOp 操作聚合各分区中的元素，然后再使用 combOp 操作把所有分区的聚合结果再次聚合，两个操作的初始值都是 zero。 seqOp 的操作是遍历分区中的所有元素 T，第一个 T 跟 zero 做操作，结果再作为与第二个 T 做操作的 zero，直到遍历完整个分区。 combOp 操作是把各分区聚合的结果再聚合。aggregate() 函数会返回一个跟 RDD 不同类型的值。因此，需要 seqOp 操作来把分区中的元素 T 合并成一个 U，以及 combOp 操作把所有 U 聚合。 下面举一个利用 aggreated() 函数求平均数的例子。 123456789val rdd = List (1,2,3,4)val input = sc.parallelize(rdd)val result = input.aggregate((0,0))( (acc,value) =&gt; (acc._1 + value,acc._2 + 1), (acc1,acc2) =&gt; (acc1._1 + acc2._1,acc1._2 + acc2._2))result:(Int,Int) = (10,4)val avg = result._1 / result._2avg:Int = 2.5 程序的详细过程大概如下。 定义一个初始值 (0,0)，即所期待的返回类型的初始值。代码 (acc,value) =&gt; (acc._1 + value,acc._2 + 1) 中的 value 是函数定义里面的 T，这里是 List 里面的元素。acc._1 + value，acc._2 + 1 的过程如下。(0+1,0+1)→(1+2,1+1)→(3+3,2+1)→(6+4,3+1)，结果为(10,4)。 实际的 Spark 执行过程是分布式计算，可能会把 List 分成多个分区，假如是两个：p1(1,2) 和 p2(3,4)。 经过计算，各分区的结果分别为 (3,2) 和 (7,2)。这样，执行 (acc1,acc2) =&gt; (acc1._1 + acc2._2,acc1._2 + acc2._2) 的结果就是 (3+7,2+2)，即 (10,4)，然后可计算平均值。 血缘关系RDD 的最重要的特性之一就是血缘关系（Lineage )，它描述了一个 RDD 是如何从父 RDD 计算得来的。如果某个 RDD 丢失了，则可以根据血缘关系，从父 RDD 计算得来。 如图给出了一个 RDD 执行过程的实例。系统从输入中逻辑上生成了 A 和 C 两个 RDD， 经过一系列转换操作，逻辑上生成了 F 这个 RDD。 Spark 记录了 RDD 之间的生成和依赖关系。当 F 进行行动操作时，Spark 才会根据 RDD 的依赖关系生成 DAG，并从起点开始真正的计算。 上述一系列处理称为一个血缘关系（Lineage），即 DAG 拓扑排序的结果。在血缘关系中，下一代的 RDD 依赖于上一代的 RDD。例如，在图 2 中，B 依赖于 A，D 依赖于 C，而 E 依赖于 B 和 D。 依赖类型根据不同的转换操作，RDD 血缘关系的依赖分为窄依赖和宽依赖。窄依赖是指父 RDD 的每个分区都只被子 RDD 的一个分区所使用。宽依赖是指父 RDD 的每个分区都被多个子 RDD 的分区所依赖。 map、filter、union 等操作是窄依赖，而 groupByKey、reduceByKey 等操作是宽依赖，如图 所示。 join 操作有两种情况，如果 join 操作中使用的每个 Partition 仅仅和固定个 Partition 进行 join，则该 join 操作是窄依赖，其他情况下的 join 操作是宽依赖。 所以可得出一个结论，窄依赖不仅包含一对一的窄依赖，还包含一对固定个数的窄依赖，也就是说，对父 RDD 依赖的 Partition 不会随着 RDD 数据规模的改变而改变。 窄依赖 子 RDD 的每个分区依赖于常数个父分区（即与数据规模无关)。 输入输出一对一的算子，且结果 RDD 的分区结构不变，如 map、flatMap。 输入输出一对一的算子，但结果 RDD 的分区结构发生了变化，如 union。 从输入中选择部分元素的算子，如 filter、distinct、subtract、sample。 宽依赖 子 RDD 的每个分区依赖于所有父 RDD 分区。 对单个 RDD 基于 Key 进行重组和 reduce，如 groupByKey、reduceByKey。 对两个 RDD 基于 Key 进行 join 和重组，如 join。 Spark 的这种依赖关系设计，使其具有了天生的容错性，大大加快了 Spark 的执行速度。RDD 通过血缘关系记住了它是如何从其他 RDD 中演变过来的。当这个 RDD 的部分分区数据丢失时，它可以通过血缘关系获取足够的信息来重新运算和恢复丢失的数据分区，从而带来性能的提升。 相对而言，窄依赖的失败恢复更为高效，它只需要根据父 RDD 分区重新计算丢失的分区即可，而不需要重新计算父 RDD 的所有分区。而对于宽依赖来讲，单个结点失效，即使只是 RDD 的一个分区失效，也需要重新计算父 RDD 的所有分区，开销较大。 宽依赖操作就像是将父 RDD 中所有分区的记录进行了“洗牌”，数据被打散，然后在子 RDD 中进行重组。 阶段划分用户提交的计算任务是一个由 RDD 构成的 DAG，如果 RDD 的转换是宽依赖，那么这个宽依赖转换就将这个 DAG 分为了不同的阶段（Stage)。由于宽依赖会带来“洗牌”，所以不同的 Stage 是不能并行计算的，后面 Stage 的 RDD 的计算需要等待前面 Stage 的 RDD 的所有分区全部计算完毕以后才能进行。 这点就类似于在 MapReduce 中，Reduce 阶段的计算必须等待所有 Map 任务完成后才能开始一样。 在对 Job 中的所有操作划分 Stage 时，一般会按照倒序进行，即从 Action 开始，遇到窄依赖操作，则划分到同一个执行阶段，遇到宽依赖操作，则划分一个新的执行阶段。后面的 Stage 需要等待所有的前面的 Stage 执行完之后才可以执行，这样 Stage 之间根据依赖关系就构成了一个大粒度的 DAG。 下面如图详细解释一下阶段划分。 假设从 HDFS 中读入数据生成 3 个不同的 RDD(A、C 和 E)，通过一系列转换操作后得到新的 RDD(G)，并把结果保存到 HDFS 中。可以看到这幅 DAG 中只有 join 操作是一个宽依赖，Spark 会以此为边界将其前后划分成不同的阶段。 同时可以注意到，在 Stage2 中，从 map 到 union 都是窄依赖，这两步操作可以形成一个流水线操作，通过 map 操作生成的分区可以不用等待整个 RDD 计算结束，而是继续进行 union 操作，这样大大提高了计算的效率。 把一个 DAG 图划分成多个 Stage 以后，每个 Stage 都代表了一组由关联的、相互之间没有宽依赖关系的任务组成的任务集合。在运行的时候，Spark 会把每个任务集合提交给任务调度器进行处理。","tags":[{"name":"大数据","slug":"大数据","permalink":"http://langonggong.com/tags/大数据/"},{"name":"spark","slug":"spark","permalink":"http://langonggong.com/tags/spark/"},{"name":"hadoop","slug":"hadoop","permalink":"http://langonggong.com/tags/hadoop/"}]},{"title":"Damerau–Levenshtein distance","date":"2019-11-16T10:06:22.000Z","path":"2019/11/16/Damerau–Levenshtein-distance/","text":"算法介绍Damerau–Levenshtein distance（D氏距离）对比L氏距离，还新增了交换操作（响铃两个字符的交换），一共包含了新增、删除、替换、交换四种编辑操作。计算公式如下 该公式的最后一步，表示a字符串前i个字符序列可以通过相邻两个 示例将abc转换为acbLevenshtein Distance算法解决方法如下：方法一： abc-&gt;acc（将字符b替换成字符c）acc-&gt;acb（将字符c替换成字符b）一共进行两次字符替换操作方法二： abc-&gt;ac（删除字符b）ac-&gt;acb（新增字符b）先删除中间的字符b，再在末尾添加字符b方法三： abc-&gt;acbc（新增字符c）acbc-&gt;acb（删除字符c）先新增字符c，再删除末尾的字符c Damerau–Levenshtein distance算法解决过程如下： 将b字符和c字符替换即可，满足条件","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"Lucune","slug":"Lucune","permalink":"http://langonggong.com/tags/Lucune/"},{"name":"编辑距离","slug":"编辑距离","permalink":"http://langonggong.com/tags/编辑距离/"}]},{"title":"Levenshtein Distance","date":"2019-11-16T09:46:00.000Z","path":"2019/11/16/Levenshtein-Distance/","text":"算法介绍Levenshtein Distance（L氏距离）是一个度量两个字符序列之间差异的字符串度量标准，两个单词之间的Levenshtein Distance是将一个单词转换为另一个单词所需的单字符编辑（插入、删除或替换）的最小数量 例如：将单词abroad转换为aboarc abroad-&gt;aboad（删除字符r） aboad-&gt;aboard（插入字符r） aboard-&gt;aboarc（将字符d替换为字符c） 编辑距离为3 算法实现对于两个字符串a、b，长度分别为|a|、|b|，i、j分别为a、b的下标值，它们的Levenshtein Distance 为： 表示字符串a的前i个字符序列转换为字符串b的前j个字符序列所需要的最短的编辑距离 1、空字符串与任意非空字符串的编剧距离等于非空字符串的长度 如图第二行，将空字符串转换为k需要插入一个字符，编辑距离为1；将空字符串转化为kf，需要插入两个字符，编辑距离为2；如图第二列，将k转换为空字符串，需要删除一个字符，编辑距离为1；将kc转换为空字符串，需要删除两个字符，编辑距离为2 2、删除一个字符 1234a=\"kfc\",b=\"kc\",i=2,j=1,lev(1,1)等同于将字符串a中的\"k\"转换为字符串b中的\"k\"，编辑距离为0lev(2,1)等同于将字符串a中的\"kf\"转换为字符串b中的\"k\"，编辑距离为1，需要一步删除操作lev(i,j)=lev(2,1)=lev(1,1)+1=0+1=1 由图像可知：在前一行的编辑距离上加一 3、新增一个字符 1234a=\"kc\",b=\"kfc\",i=1,j=2lev(1,1)等同于将字符串a中的\"k\"转换为字符串b中的\"k\"，编辑距离为0lev(1,2)等同于将字符串a中的\"k\"转换为字符串b中的\"kf\"，编辑距离为1，需要一步新增操作lev(i,j)=lev(1,2)=lev(1,1)+1=1 由图像可知：在前一列的编辑距离上加一 4、当前两个字符相同，编辑距离不变 1234a=\"kc\",b=\"kfc\",i=2,j=3lev(1,2)等同于将字符串a中的\"k\"转换为字符串b中的\"kf\"，编辑距离为1，需要一步新增操作lev(2,3)等同于将字符串a中的\"kc\"转换为字符串b中的\"kfc\"，编辑距离为1因为字符串a中的c字符等于字符串b中的c字符，所以lev(i,j)=lev(2,3)=lev(1,2)+0 由图像可知：与左上角坐标所示编辑距离相同 5、当前两个字符不同，替换操作 123a=\"kc\",b=\"kb\",i=j=2lev(1,1)等同于将字符串a中的\"k\"转换为字符串b中的\"k\"，编辑距离为0lev(2,2)等同于将字符串a中的\"kc\"转换为字符串b中的\"kb\"，编辑距离为1，需要替换一个字符串 由图像可知：将左上角坐标所示编辑距离加一 示例求最优编辑距离示例：将单词abroad转换为aboarc1、将abr转换为ab，删除字符r 2、将aboa（之前已删除字符r）转换为aboar，新增字符r 3、将aboard转换为aboarc，将字符d替换为字符c 字符串的相似度 应用DNA序列分析、拼写检查、语音辨识、抄袭侦测","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"Lucune","slug":"Lucune","permalink":"http://langonggong.com/tags/Lucune/"},{"name":"编辑距离","slug":"编辑距离","permalink":"http://langonggong.com/tags/编辑距离/"}]},{"title":"AC自动机","date":"2019-11-16T09:36:46.000Z","path":"2019/11/16/AC自动机/","text":"应用背景在互联网应用中，通常会用到关键词检测功能，以防止用户发表包括了指定关键词的内容。如游戏的聊天系统、角色名称检测，论坛发帖、直播弹幕等，都需要对用户发布的内容进行检测，以检测是否包含敏感的关键字。 通常需要检测的关键词，会有很多很多，比如侮辱人的关键词，政治敏感的关键词，系统相关的特定关键词等。毫不夸张的说，通常要检测的关键词会有几千个，甚至过万。这时效率都变得尤为突出，如果检测关键词的效率低下，对大型互联网应用来说，很可能有是致命的。 以8000个关键词为例，如果使用正则表达式，则需要对用户发布的内容遍历8000遍。如果同一秒中，有100位，1000位，10000位…用户发布内容，可想而知仅仅在关键词检测方面服务器上CPU的开销。 AC多模式匹配算法，可以有效的解决关键词检测的效率问题。时间复杂度为O(n),n为用户发布内容的长度n。基本与关键词的数量无关。 AC算法介绍AC算法是一个经典的多模式匹配算法，可以保证对于给定的长度为n的文本，和模式集合P{p1,p2,…pm}，在O(n)时间复杂度内，找到文本中的所有目标模式，而与模式集合的规模m无关。 AC算法实现原理：ac自动机,就是在tire树的基础上,增加一个fail指针,如果当前点匹配失败,则将指针转移到fail指针指向的地方,这样就不用回溯,而可以路匹配下去了 举例：如要查找abce和bcd是否在abcd中出现,我们找到c发现下一个要找的不是e,就跳到bcd中的c处,看看此处的下一个字符(d)是不是应该找的那一个因为abc部分的后缀与bcd的部分前缀相同，便能构造fail指针 完整流程： 构建敏感词树型结构，并标注结束节点（即是否是一个敏感词的结束）； 为树上的结点，构建匹配失败时的跳转-失败结点（即匹配失败时，跳转到哪个结点继续匹配）； 对用户内容进行一次遍历，对于每个字符（字节）都去敏感词树型结构中，从当前结点位置开始匹配。 构建过程以模式串he,she,him,hers,shit为例，先构造一颗字典树 图像说明 图中根节点为空节点 红色节点表示该节点是一个存在的字符串 蓝色实线连接父子节点 黄色虚线表示fail指针 没有标注黄色虚线的节点，fail指针默认都指向根节点 fail指针构造过程 第三行的h节点，找到父节点的fail节点的子节点中，与当前节点相同的点，将h的fail指针指向该节点 第四行的i节点，找他i节点的父节点的fail节点的子节点中是否有i节点 依次类推 匹配示例拿主串ashers上去匹配 第三步确定找到she，接续沿着线头则匹配失败，根据fail指针跳转 第四步找到he，继续往下找 第六步找到hers，匹配结束","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"树","slug":"树","permalink":"http://langonggong.com/tags/树/"},{"name":"Lucune","slug":"Lucune","permalink":"http://langonggong.com/tags/Lucune/"}]},{"title":"Double Array Trie","date":"2019-11-16T09:20:56.000Z","path":"2019/11/16/Double-Array-Trie/","text":"问题Trie树的创建要考虑的是父节点如何保存孩子节点，主要有链表和数组两种方式： 使用节点数组，因为是英文字符，可以用Node[26]来保存孩子节点(如果是数字我们可以用Node[10])，这种方式最快，但是并不是所有节点都会有很多孩子，所以这种方式浪费的空间太多 用一个链表根据需要动态添加节点。这样我们就可以省下不小的空间，但是缺点是搜索的时候需要遍历这个链表，增加了时间复杂度。 Trie也可以按照DFA的方式存储，即表示为转移矩阵。行表示状态，列表示输入字符，(行, 列)位置表示转移状态。这种方式的查询效率很高，但由于稀疏的现象严重，空间利用效率很低。 如果是中文词典，子节点的数目范围跨度更大，问题将会更加严重 原理双数组Trie树（Double-array Trie, DAT）是一种Trie树的高效实现，兼顾了查询效率与空间存储 Double-Array Trie包含base和check两个数组。base数组的每个元素表示一个Trie节点，即一个状态；check数组表示某个状态的前驱状态。其中，s是当前状态的下标，t是转移状态的下标，c是输入字符的数值。如图所示：base和check的关系满足下述条件：base[s] + c = tcheck[t] = s 以bachelor, baby, badge, jar为例 其中，字符的编码表为{‘#’=1, ‘a’=2, ‘b’=3, ‘c’=4, etc. }。为了对Trie做进一步的压缩，用tail数组存储无公共前缀的尾字符串，且满足如下的特点：p = -base[m], tail[p] = b1, tail[p+1] = b2, …, tail[p+h-1] = bh；h为该尾字符串的长度 检索示例检索词badge的过程如下： 123456789101112// root -&gt; bbase[1] + 'b' = 4 + 3 = 7check[7]=1// root -&gt; b -&gt; abase[7] + 'a' = 1 + 2 = 3check[3]=7// root -&gt; b -&gt; a -&gt; dbase[3] + 'd' = 1 + 5 = 6check[6]=3// badge#base[6] = -12tail[12..14] = 'ge#'","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"树","slug":"树","permalink":"http://langonggong.com/tags/树/"},{"name":"Lucune","slug":"Lucune","permalink":"http://langonggong.com/tags/Lucune/"}]},{"title":"字典树","date":"2019-11-16T08:59:24.000Z","path":"2019/11/16/字典树/","text":"概念如果现在有b，abc，abd，bcd，abcd，efg，hii 这7个单词，我们可以构建一棵如下图所示的树： 如上图所示，对于每一个节点，从根遍历到他的过程就是一个单词，如果这个节点被标记为红色，就表示这个单词存在，否则不存在。 Trie树，又称字典树，单词查找树或者前缀树，是一种用于快速检索的多叉树结构，如英文字母的字典树是一个26叉树，数字的字典树是一个10叉树。与二叉查找树不同，Trie树的键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。 基本性质： 根节点不包含字符，除根节点外每一个节点都只包含一个字符。 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符都不相同。 复杂度Trie树优点是最大限度地减少无谓的字符串比较，查询效率比较高。核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。 插入、查找的时间复杂度均为O(N)，其中N为字符串长度。 空间复杂度是26^n级别的，非常庞大（可采用双数组实现改善）。 Trie树的实现trie树实际上是一个DFA，通常用转移矩阵表示。行表示状态，列表示输入字符，（行，列）位置表示转移状态。这种方式的查询效率很高，但由于稀疏的现象严重，空间利用效率很低。也可以采用压缩的存储方式即链表来表示状态转移，但由于要线性查询，会造成效率低下。 Trie树的创建要考虑的是父节点如何保存孩子节点，主要有链表和数组两种方式： 使用节点数组，因为是英文字符，可以用Node[26]来保存孩子节点(如果是数字我们可以用Node[10])，这种方式最快，但是并不是所有节点都会有很多孩子，所以这种方式浪费的空间太多 用一个链表根据需要动态添加节点。这样我们就可以省下不小的空间，但是缺点是搜索的时候需要遍历这个链表，增加了时间复杂度。 应用场景 字符串检索 事先将已知的一些字符串（字典）的有关信息保存到trie树里，查找另外一些未知字符串是否出现过或者出现频率。例如：给出一个词典，其中的单词为不良单词。单词均为小写字母。再给出一段文本，文本的每一行也由小写字母构成。判断文本中是否含有任何不良单词 字符串最长公共前缀 Trie树利用多个字符串的公共前缀来节省存储空间，反之，当我们把大量字符串存储到一棵trie树上时，我们可以快速得到某些字符串的公共前缀。 排序 Trie树是一棵多叉树，只要先序遍历整棵树，输出相应的字符串便是按字典序排序的结果。也可以快速获得最小、最大字符串（举出数据地图分页查看分区、求最大最小分区的例子） 词频统计 统计每个单词出现的次数，以及找到出现频率最高的n个单词 字符串搜索的前缀匹配 trie树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。 作为其他数据结构和算法的辅助结构 如后缀树，AC自动机等 数据结构的比较二叉搜索树（binary search tree）二叉搜索树又叫做二叉排序树，它满足： 任意节点如果左子树不为空，左子树所有节点的值都小于根节点的值； 任意节点如果右子树不为空，右子树所有节点的值都大于根节点的值； 左右子树也都是二叉搜索树； 所有节点的值都不相同。 其实二叉搜索树的优势已经在与查找、插入的时间复杂度上了，通常只有 O(log n)，很多集合都是通过它来实现的。在进行插入的时候，实质上是给树添加新的叶子节点，避免了节点移动，搜索、插入和删除的复杂度等于树的高度，属于 O(log n)，最坏情况下整棵树所有的节点都只有一个子节点，完全变成一个线性表，复杂度是 O(n)。Trie 树在最坏情况下查找要快过二叉搜索树，如果搜索字符串长度用 m 来表示的话，它只有 O(m)，通常情况（树的节点个数要远大于搜索字符串的长度）下要远小于 O(n)。我们给 Trie 树举例子都是拿字符串举例的，其实它本身对 key 的适宜性是有严格要求的，如果 key 是浮点数的话，就可能导致整个 Trie 树巨长无比，节点可读性也非常差，这种情况下是不适宜用 Trie 树来保存数据的；而二叉搜索树就不存在这个问题。 Hash表Trie 树可以比较方便地按照 key 的字母序来排序（整棵树先序遍历一次就好了），这是绝大多数 Hash 表是不同的（Hash 表一般对于不同的 key 来说是无序的）。考虑一下 Hash 表键冲突的问题。Hash 表通常我们说它的复杂度是 O(1)，其实严格说起来这是接近完美的 Hash 表的复杂度，另外还需要考虑到 hash 函数本身需要遍历搜索字符串，复杂度是 O(m)。在不同键被映射到 “同一个位置”（考虑 closed hashing，这 “同一个位置” 可以由一个普通链表来取代）的时候，需要进行查找的复杂度取决于这 “同一个位置” 下节点的数目，因此，在最坏情况下，Hash 表也是可以成为一张单向链表的。在较理想的情况下，Hash 表可以以 O(1) 的速度迅速命中目标，如果这张表非常大，需要放到磁盘上的话，Hash 表的查找访问在理想情况下只需要一次即可；但是 Trie 树访问磁盘的数目需要等于节点深度。很多时候 Trie 树比 Hash 表需要更多的空间，我们考虑这种一个节点存放一个字符的情况的话，在保存一个字符串的时候，没有办法把它保存成一个单独的块。Trie 树的节点压缩可以明显缓解这个问题，后面会讲到。 参考链接 字典树(Trie树)的实现及应用Trie（前缀树/字典树）及其应用Trie 树和其它数据结构的比较Lucene数字类型处理","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"树","slug":"树","permalink":"http://langonggong.com/tags/树/"},{"name":"Lucune","slug":"Lucune","permalink":"http://langonggong.com/tags/Lucune/"}]},{"title":"线程池","date":"2019-10-03T08:12:49.000Z","path":"2019/10/03/线程池/","text":"ThreadPoolExecutor构造参数 corePoolSize 线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。 maximumPoolSize 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize keepAliveTime 线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间。默认情况下，该参数只在线程数大于corePoolSize时才有用 workQueue workQueue必须是BlockingQueue阻塞队列。当线程池中的线程数超过它的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。通过workQueue，线程池实现了阻塞功能 threadFactory 创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名 几种排队的策略：不排队，直接提交将任务直接交给线程处理而不保持它们，可使用SynchronousQueue如果不存在可用于立即运行任务的线程（即线程池中的线程都在工作），则试图把任务加入缓冲队列将会失败，因此会构造一个新的线程来处理新添加的任务，并将其加入到线程池中（corePoolSize—&gt;maximumPoolSize扩容）Executors.newCachedThreadPool()采用的便是这种策略 无界队列可以使用LinkedBlockingQueue（基于链表的有界队列，FIFO），理论上是该队列可以对无限多的任务排队 将导致在所有corePoolSize线程都工作的情况下将新任务加入到队列中。这样，创建的线程就不会超过corePoolSize，也因此，maximumPoolSize的值也就无效了 有界队列可以使用ArrayBlockingQueue（基于数组结构的有界队列，FIFO），并指定队列的最大长度 使用有界队列可以防止资源耗尽，但也会造成超过队列大小和maximumPoolSize后，提交的任务被拒绝的问题，比较难调整和控制。 RejectedExecutionHandler（饱和策略）线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略： AbortPolicy：直接抛出异常，默认策略； CallerRunsPolicy：用调用者所在的线程来执行任务； DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy：直接丢弃任务； 当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。 线程池的执行流程 如果线程池中的线程数量少于corePoolSize，就创建新的线程来执行新添加的任务 如果线程池中的线程数量大于等于corePoolSize，但队列workQueue未满，则将新添加的任务放到workQueue中 如果线程池中的线程数量大于等于corePoolSize，且队列workQueue已满，但线程池中的线程数量小于maximumPoolSize，则会创建新的线程来处理被添加的任务 如果线程池中的线程数量等于了maximumPoolSize，就用RejectedExecutionHandler来执行拒绝策略 Executors静态工厂创建几种常用线程池newFixedThreadPool123456789101112public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125; 创建一个指定工作线程数的线程池，其中参数 corePoolSize 和 maximumPoolSize 相等，阻塞队列基于LinkedBlockingQueue 它是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建线程时所耗的开销的优点。但是在线程池空闲时，即线程池中没有可运行任务时，它也不会释放工作线程，还会占用一定的系统资源 newSingleThreadExecutor1234567891011121314public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125; 初始化的线程池中只有一个线程，如果该线程异常结束，会重新创建一个新的线程继续执行任务，唯一的线程可以保证所提交任务的顺序执行，内部使用LinkedBlockingQueue作为阻塞队列 newCachedThreadPool123456789101112public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125; 创建一个可缓存工作线程的线程池，默认存活时间60秒，线程池的线程数可达到Integer.MAX_VALUE，即2147483647，内部使用SynchronousQueue作为阻塞队列； 在没有任务执行时，当线程的空闲时间超过keepAliveTime，则工作线程将会终止，当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销 newScheduledThreadPool12345678public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125; public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);&#125; 初始化的线程池可以在指定的时间内周期性的执行所提交的任务，在实际的业务场景中可以使用该线程池定期的同步数据 参考链接 Java线程池ThreadPoolExecutor使用和分析","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"词干提取器","date":"2019-09-21T10:07:16.000Z","path":"2019/09/21/词干提取器/","text":"前言大多数语言的单词都可以 词形变化 ，意味着 下列单词可以改变它们的形态用来表达不同的意思： 单复数变化 ： fox 、foxes 时态变化 ： pay 、 paid 、 paying 性别变化 ： waiter 、 waitress 动词人称变化 ： hear 、 hears 代词变化 ： I 、 me 、 my 不规则变化 ： ate 、 eaten 情景变化 ： so be it 、 were it so 提取程度词干提取是一种遭受两种困扰的模糊的技术：词干弱提取和词干过度提取。 词干弱提取 就是无法将同样意思的单词缩减为同一个词根。例如， jumped和jumps可能被提取为 jump ， 但是 jumping 可能被提取为 jumpi 。弱词干提取会导致搜索时无法返回相关文档。 词干过度提取 就是无法将不同含义的单词分开。例如，general和generate可能都被提取为 gener 。 词干过度提取会降低精准度：不相干的文档会在不需要他们返回的时候返回。 提取方式基于算法Elasticsearch 中的大部分 stemmers （词干提取器）是基于算法的，它们提供了一系列规则用于将一个词提取为它的词根形式，例如剥离复数词末尾的 s 或 es 。提取单词词干时并不需要知道该词的任何信息。 优点 可以作为插件使用，速度快，占用内存少，有规律的单词处理效果好 缺点 没规律的单词例如 be 、 are 、和 am ，或 mice 和 mouse 效果不好 基于字典字典词干提取器在工作机制上与算法化词干提取器完全不同。 不同于应用一系列标准规则到每个词上，字典词干提取器只是简单地在字典里查找词。理论上可以给出比算法化词干提取器更好的结果。一个字典词干提取器应当可以： 返回不规则形式如feet和mice的正确词干 区分出词形相似但词义不同的情形，比如organ and organization 对比实践中一个好的算法化词干提取器一般优于一个字典词干提取器。应该有以下两大原因： 字典质量 字典需要保持最新，这是一项很耗时的任务。通常等到一个字典变得好用后，其中的部分内容已经过时。字典词干提取器对于字典中不存在的词无能为力。而一个基于算法的词干提取器，则会继续应用之前的相同规则，结果可能正确或错误。 大小与性能 字典词干提取器需要加载所有词汇、 所有前缀，以及所有后缀到内存中。这会显著地消耗内存。找到一个词的正确词干，一般比算法化词干提取器的相同过程更加复杂。依赖于不同的字典质量，去除前后缀的过程可能会更加高效或低效。低效的情形可能会明显地拖慢整个词干提取过程。 提取器种类 Porter Stem Token Filter porter_stem语汇单元过滤器（token filter）。 最早的一个基于算法 的英文词干提取器，提取程度较为激进。 KStem Token Filter kstem语汇单元过滤器（token filter）。 是一款合并了词干提取算法和内置词典的英语分词过滤器。为了避免模糊词不正确提取，这个词典包含一系列根词单词和特例单词。 kstem分词过滤器相较于Porter词干提取器而言不那么激进。 Hunspell 词干提取器 基于词典提取词干的hunspell语汇单元过滤器（token filter）. Hunspell hunspell.github.io 是一个 Open Office、LibreOffice、Chrome、Firefox、Thunderbird 等众多其它开源项目都在使用的拼写检查器。Hunspell词典会占用几兆的内存，它不仅能移除前缀还能移除后缀。 一个 Hunspell 词典由两个文件组成 — 具有相同的文件名和两个不同的后缀 — 如 en_US—和下面的两个后缀的其中一个： .dic 包含所有词根，采用字母顺序，再加上一个代表所有可能前缀和后缀的代码表 【集体称之为词缀( affixes 】 .aff 包含实际 .dic 文件每一行代码表对应的前缀和后缀转换 其他 Lovins 提取器、Porter 提取器、Porter2 提取器等 如何选择推荐的词干提取器也许不适用所有场景。 关于哪个是最好的词干提取器，不存在一个唯一的正确答案 — 它要看你具体的需求。 这里有3个方面的因素需要考虑在内： 性能、质量、程度。 提取性能算法提取器一般来说比Hunspell提取器快4到5倍。Hunspell 提取器需要加载所有的词典、前缀和后缀表到内存，可能需要消耗几兆的内存。而算法提取器，由一点点代码组成，只需要使用很少内存。 提取质量最日常用语使用的词往往不规则。一个基于词典的提取器往往取决于词典的好坏。如果 Hunspell 碰到的这个词不在词典里，那它什么也不能做。 Hunspell 需要一个广泛的、高质量的、最新的词典以产生好的结果；这样级别的词典可谓少之又少。 另一方面，一个算法提取器，将愉快的处理新词而不用为新词重新设计算法。如果一个好的算法词干提取器可用于你的语言，那明智的使用它而不是 Hunspell。它会更快并且消耗更少内存，并且会产生和通常一样好或者比 Hunspell 等价的结果.如果精度和可定制性对你很重要，那么你需要（和有精力）来维护一个自定义的词典，那么 Hunspell 会给你比算法提取器更大的灵活性 提取程度是否想要积极提取还是轻量提取取决于你的场景。如果你的搜索结果是要用于聚类算法，你可能会希望匹配的更广泛一点（因此，提取力度要更大一点）。 如果你的搜索结果是面向最终用户，轻量的提取一般会产生更好的结果。对搜索来说，将名称和形容词提干比动词提干更重要，当然这也取决于语言。 另外一个要考虑的因素就是你的文档集的大小。 一个只有 10,000 个产品的小集合，你可能要更激进的提干来确保至少匹配到一些文档。 如果你的文档集很大，使用轻量的弱提取可能会得到更好的匹配结果。 参考链接 将单词还原为词根","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"分析器","slug":"分析器","permalink":"http://langonggong.com/tags/分析器/"}]},{"title":"ES分析器","date":"2019-09-14T17:09:03.000Z","path":"2019/09/15/ES分析器/","text":"分析器CharFilterTokenizerTokenizer Filter转换Lowercase Token Filter小写过滤器。将标记token规范化为小写 Uppercase Token Filter大写过滤器。将术语转写成大写 Synonym Token Filter同义词过滤器 ASCII Folding Token FilterASCII码折叠过滤器。asciifolding过滤器将ASCII码不在ASCII表前127内的字母、数字和Unicode符号转换为ASCII等效字符(如果存在的话) 12345678910111213141516171819202122//新建索引PUT asciifold_example&#123; \"settings\": &#123; \"analysis\": &#123; \"analyzer\": &#123; \"my_analyzer\": &#123; \"tokenizer\": \"standard\", \"filter\": [ \"my_ascii_folding\" ] &#125; &#125;, \"filter\": &#123; \"my_ascii_folding\": &#123; \"type\": \"asciifolding\", \"preserve_original\": false &#125; &#125; &#125; &#125;&#125; 123456//提交文本POST asciifold_example/_analyze&#123; \"analyzer\": \"my_analyzer\", \"text\": \"Êê Ẑẑ Ĉĉ Ŝŝ Ŋŋ Öö\"&#125; 12//获取结果[Ee,Zz,Cc,Ss,Nn,Oo] 词干提取器词干提取器将一个词提取为它的词根形式 Porter Stem Token Filter Stemmer Token Filter：包含了大多数词干提取器 KStem Token Filter Snowball Token Filter过滤 Length Token Filter长度过滤器，会移除token流中太长或太短的标记 Stop Token Filter停用词过滤器，会移除自定义或指定文件中的停用词 Predicate Token Filter根据脚本里面的表达式来判断是否过滤掉某个词条，例如使用standard分析器后的”What Flapdoodle”分隔成两个词条，只保留长度大于5的词条，则”What”将被删除 切割Word Delimiter Token Filter分隔符过滤器，根据一定的规则将单词分割为多个子字符串，或者删除单词中的分隔符。例如： generate_word_parts “Power-Shot”, “(Power,Shot)” -&gt; “Power” “Shot” generate_number_parts 将数字拆出来：”500-42” -&gt; “500” “42” catenate_words 将单词去掉分隔符后合并：”wi-fi” -&gt; “wifi” 其他 Edge NGram Token Filtern-gram 看成一个在词语上 滑动窗口 ， n 代表这个 “窗口” 的长度。如果我们要 n-gram quick 这个词 —— 它的结果取决于 n 的选择长度： 12345长度 1（unigram）： [ q, u, i, c, k ]长度 2（bigram）： [ qu, ui, ic, ck ]长度 3（trigram）： [ qui, uic, ick ]长度 4（four-gram）： [ quic, uick ]长度 5（five-gram）： [ quick ] 朴素的n-gram对词语内部的匹配非常有用，即在 Ngram匹配复合词 介绍的那样。但对于输入即搜索（search-as-you-type）这种应用场景，我们会使用一种特殊的n-gram称为边界n-grams（edge n-grams）。所谓的边界n-gram是说它会固定词语开始的一边，以单词quick为例，它的边界n-gram的结果为： 1[q,qu,qui,quic,quick] 创建索引、实例化 token 过滤器和分析器的完整示例如下 12345678910111213141516171819202122232425PUT /my_index&#123; \"settings\": &#123; \"number_of_shards\": 1, \"analysis\": &#123; \"filter\": &#123; \"autocomplete_filter\": &#123; \"type\": \"edge_ngram\", \"min_gram\": 1, \"max_gram\": 20 &#125; &#125;, \"analyzer\": &#123; \"autocomplete\": &#123; \"type\": \"custom\", \"tokenizer\": \"standard\", \"filter\": [ \"lowercase\", \"autocomplete_filter\" ] &#125; &#125; &#125; &#125;&#125; 可以拿 analyze API 测试这个新的分析器确保它行为正确： 12345GET /my_index/_analyze&#123; \"text\": \"quick brown\", \"analyzer\": \"autocomplete\"&#125; 结果表明分析器能正确工作，并返回以下词： 1[q,qu,qui,quic,quick,b,br,bro,brow,brown] 可以用 update-mapping API 将这个分析器应用到具体字段并添加数据 123456789101112131415PUT /my_index/_mapping/&#123; \"properties\": &#123; \"name\": &#123; \"type\": \"text\", \"analyzer\": \"autocomplete\" &#125; &#125;&#125;POST /my_index/_bulk&#123;\"index\":&#123;\"_id\":1&#125;&#125;&#123;\"name\":\"Brown foxes\"&#125;&#123;\"index\":&#123;\"_id\":2&#125;&#125;&#123;\"name\":\"Yellow furballs\"&#125; 如果使用简单 match 查询测试查询 “brown fo” ,可以看到两个文档同时都能匹配，尽管 Yellow furballs 这个文档并不包含 brown 和 fo 12345678GET /my_index/_validate/query?explain&#123; \"query\": &#123; \"match\": &#123; \"name\": \"brown fo\" &#125; &#125;&#125; 使用validate-query API 分析： 12345678GET /my_index/_validate/query?explain&#123; \"query\": &#123; \"match\": &#123; \"name\": \"brown fo\" &#125; &#125;&#125; explanation 表明查询会查找边界 n-grams 里的每个词： 1name:b name:br name:bro name:brow name:brown name:f name:fo name:f 条件可以满足第二个文档 我们需要保证倒排索引表中包含边界 n-grams 的每个词，但是我们只想匹配用户输入的完整词组（ brown 和 fo ）， 可以通过在索引时使用 autocomplete 分析器，并在搜索时使用 standard 标准分析器来实现这种想法，只要改变查询使用的搜索分析器 analyzer 参数即可： 1234567891011GET /my_index/_search&#123; \"query\": &#123; \"match\": &#123; \"name\": &#123; \"query\": \"brown fo\", \"analyzer\": \"standard\" &#125; &#125; &#125;&#125; 换种方式，我们可以在映射中，为name字段分别指定index_analyzer和 earch_analyzer。因为我们只想改变 search_analyzer，这里只要更新现有的映射而不用对数据重新创建索引： 12345678910PUT /my_index/_mapping&#123; \"properties\": &#123; \"name\": &#123; \"type\": \"text\", \"analyzer\": \"autocomplete\", \"search_analyzer\": \"standard\" &#125; &#125;&#125; 如果再次请求 validate-query API ，当前的解释为： 1name:brown name:fo 再次执行查询就能正确返回 Brown foxes 这个文档。 Shingle Token Filter（滑动窗口）使用 TF/IDF 的标准全文检索将文档或者文档中的字段作一大袋的词语处理。 match 查询可以告知我们这大袋子中是否包含查询的词条，但却无法告知词语之间的关系。 思考下面这几个句子的不同： Sue ate the alligator. The alligator ate Sue. Sue never goes anywhere without her alligator-skin purse. 用match搜索sue alligator上面的三个文档都会得到匹配，但它却不能确定这两个词是否只来自于一种语境，甚至都不能确定是否来自于同一个段落。 理解分词之间的关系是一个复杂的难题，我们也无法通过换一种查询方式去解决。但我们至少可以通过出现在彼此附近或者仅仅是彼此相邻的分词来判断一些似乎相关的分词。 对句子Sue ate the alligator ，不仅要将每一个单词（或者 unigram ）作为词项索引1[\"sue\", \"ate\", \"the\", \"alligator\"] 也要将每个单词以及它的邻近词作为单个词项索引：1[\"sue ate\", \"ate the\", \"the alligator\"] 这些单词对（或者 bigrams ）被称为 shingles 。你也可以索引三个单词（ trigrams ）。Trigrams 提供了更高的精度，但是也大大增加了索引中唯一词项的数量。在大多数情况下，Bigrams 就够了。1[\"sue ate the\", \"ate the alligator\"] 只有当用户输入的查询内容和在原始文档中顺序相同时，shingles 才是有用的；对 sue alligator 的查询可能会匹配到单个单词，但是不会匹配任何 shingles 。只是索引 bigrams 是不够的；我们仍然需要 unigrams ，但可以将匹配 bigrams 作为增加相关度评分的信号。 将它们分开保存在能被独立查询的字段会更清晰：1234567891011121314151617181920212223242526PUT /shingle_index&#123; \"settings\": &#123; \"number_of_shards\": 1, \"analysis\": &#123; \"filter\": &#123; \"my_shingle_filter\": &#123; \"type\": \"shingle\", \"min_shingle_size\": 2, \"max_shingle_size\": 2, \"output_unigrams\": false &#125; &#125;, \"analyzer\": &#123; \"my_shingle_analyzer\": &#123; \"type\": \"custom\", \"tokenizer\": \"standard\", \"filter\": [ \"lowercase\", \"my_shingle_filter\" ] &#125; &#125; &#125; &#125;&#125; 用 analyze API 测试下分析器：12345GET /shingle_index/_analyze&#123; \"analyzer\": \"my_shingle_analyzer\", \"text\": \"Sue ate the alligator\"&#125; 得到了 3 个词项：1[\"sue ate\", \"ate the\", \"the alligator\"] 将unigrams和bigrams分开索引更清晰，所以title字段将创建成一个多字段：1234567891011121314PUT /shingle_index/_mapping/&#123; \"properties\": &#123; \"title\": &#123; \"type\": \"text\", \"fields\": &#123; \"shingles\": &#123; \"type\": \"text\", \"analyzer\": \"my_shingle_analyzer\" &#125; &#125; &#125; &#125;&#125; 索引以下示例文档：1234567POST /shingle_index/_doc/_bulk&#123;\"index\":&#123;\"_id\":1&#125;&#125;&#123;\"title\":\"Sue ate the alligator\"&#125;&#123;\"index\":&#123;\"_id\":2&#125;&#125;&#123;\"title\":\"The alligator ate Sue\"&#125;&#123;\"index\":&#123;\"_id\":3&#125;&#125;&#123;\"title\":\"Sue never goes anywhere without her alligator skin purse\"&#125; 使用The hungry alligator ate Sue 进行简单 match 查询：123456789GET /shingle_index/_doc/_search&#123; \"query\": &#123; \"match\": &#123; \"title\": \"the hungry alligator ate sue\" &#125; &#125;&#125; 这个查询返回了所有的三个文档， 但是注意文档 1 和 2 有相同的相关度评分因为他们包含了相同的单词：123456789101112131415161718192021222324252627282930313233343536&#123; \"total\": &#123; \"value\": 3, \"relation\": \"eq\" &#125;, \"max_score\": 1.3721708, \"hits\": [ &#123; \"_index\": \"shingle_index\", \"_type\": \"_doc\", \"_id\": \"1\", \"_score\": 1.3721708, \"_source\": &#123; \"title\": \"Sue ate the alligator\" &#125; &#125;, &#123; \"_index\": \"shingle_index\", \"_type\": \"_doc\", \"_id\": \"2\", \"_score\": 1.3721708, \"_source\": &#123; \"title\": \"The alligator ate Sue\" &#125; &#125;, &#123; \"_index\": \"shingle_index\", \"_type\": \"_doc\", \"_id\": \"3\", \"_score\": 0.2152618, \"_source\": &#123; \"title\": \"Sue never goes anywhere without her alligator skin purse\" &#125; &#125; ]&#125; 现在在查询里添加 shingles 字段，为了提高相关度评分，我们仍然需要将基本title字段包含到查询中：1234567891011121314151617GET /shingle_index/_doc/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"the hungry alligator ate sue\" &#125; &#125;, \"should\": &#123; \"match\": &#123; \"title.shingles\": \"the hungry alligator ate sue\" &#125; &#125; &#125; &#125;&#125; 仍然匹配到了所有的 3 个文档， 但是文档 2 现在排到了第一名因为它匹配了 shingled 词项 ate sue：123456789101112131415161718192021222324252627282930313233343536&#123; \"total\": &#123; \"value\": 3, \"relation\": \"eq\" &#125;, \"max_score\": 3.6694741, \"hits\": [ &#123; \"_index\": \"shingle_index\", \"_type\": \"_doc\", \"_id\": \"2\", \"_score\": 3.6694741, \"_source\": &#123; \"title\": \"The alligator ate Sue\" &#125; &#125;, &#123; \"_index\": \"shingle_index\", \"_type\": \"_doc\", \"_id\": \"1\", \"_score\": 1.3721708, \"_source\": &#123; \"title\": \"Sue ate the alligator\" &#125; &#125;, &#123; \"_index\": \"shingle_index\", \"_type\": \"_doc\", \"_id\": \"3\", \"_score\": 0.2152618, \"_source\": &#123; \"title\": \"Sue never goes anywhere without her alligator skin purse\" &#125; &#125; ]&#125; 流程Conditional Token Filter根据表达式条件决定是否使用某个其他的过滤器，例如根据一个词条中字符的个数来判断是否要使用Lowercase Token Filter过滤器 Keyword Marker Token Filter保护某些单词不被stemmers（词干提取器）处理，可以自定义单词列表或者指定文件路径 Keyword Repeat Token Filter将每个输入的token复制，生成keyword和non-keyword两个。一般用于交给词干提取器处理，然后去重处理 12345678910111213141516171819202122232425PUT /keyword_repeat_example&#123; \"settings\": &#123; \"analysis\": &#123; \"analyzer\": &#123; \"stemmed_and_unstemmed\": &#123; \"type\": \"custom\", \"tokenizer\": \"standard\", \"filter\": [ \"lowercase\", \"keyword_repeat\", \"porter_stem\", \"unique_stem\" ] &#125; &#125;, \"filter\": &#123; \"unique_stem\": &#123; \"type\": \"unique\", \"only_on_same_position\": true &#125; &#125; &#125; &#125;&#125; 测试用例如下：12345POST /keyword_repeat_example/_analyze&#123; \"analyzer\": \"stemmed_and_unstemmed\", \"text\": \"I like cats\"&#125; 结果如下：1234567891011121314151617181920212223242526272829303132&#123; \"tokens\" : [ &#123; \"token\" : \"i\", \"start_offset\" : 0, \"end_offset\" : 1, \"type\" : \"&lt;ALPHANUM&gt;\", \"position\" : 0 &#125;, &#123; \"token\" : \"like\", \"start_offset\" : 2, \"end_offset\" : 6, \"type\" : \"&lt;ALPHANUM&gt;\", \"position\" : 1 &#125;, &#123; \"token\" : \"cats\", \"start_offset\" : 7, \"end_offset\" : 11, \"type\" : \"&lt;ALPHANUM&gt;\", \"position\" : 2 &#125;, &#123; \"token\" : \"cat\", \"start_offset\" : 7, \"end_offset\" : 11, \"type\" : \"&lt;ALPHANUM&gt;\", \"position\" : 2 &#125; ]&#125;","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"分析器","slug":"分析器","permalink":"http://langonggong.com/tags/分析器/"}]},{"title":"synchronized的内存语义","date":"2019-07-01T15:51:37.000Z","path":"2019/07/01/synchronized的内存语义/","text":"当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中而线程获取锁，JMM会把其对应内存置为无效，从而使被监视器保护的临界区代码必须要从主内存去读取共享变量","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"},{"name":"java内存模型","slug":"java内存模型","permalink":"http://langonggong.com/tags/java内存模型/"},{"name":"synchronized","slug":"synchronized","permalink":"http://langonggong.com/tags/synchronized/"}]},{"title":"SQL优化","date":"2018-12-02T12:21:43.000Z","path":"2018/12/02/SQL优化/","text":"字段类型转换导致不用索引，如字符串类型的不用引号，数字类型的用引号等，这有可能会用不到索引导致全表扫描； mysql 不支持函数转换，所以字段前面不能加函数，否则这将用不到索引； 不要在字段前面加减运算； 字符串比较长的可以考虑索引一部份减少索引文件大小，提高写入效率； like % 在前面用不到索引； 根据联合索引的第二个及以后的字段单独查询用不到索引； 不要使用 select *； 排序请尽量使用升序 ; or 的查询尽量用 union 代替 （Innodb）； 复合索引高选择性的字段排在前面； order by / group by 字段包括在索引当中减少排序，效率会更高。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://langonggong.com/tags/mysql/"},{"name":"DB","slug":"DB","permalink":"http://langonggong.com/tags/DB/"}]},{"title":"InnoDB锁","date":"2018-11-26T16:00:41.000Z","path":"2018/11/27/InnoDB锁/","text":"事务ACID事务是由一组SQL语句组成的逻辑处理单元，事务具有以下4个属性，通常简称为事务的ACID属性。 原子性（Atomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持 事务并发带来的问题 更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题－－最后的更 新覆盖了由其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文 档。最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题 脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加 控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做”脏读” 不可重复读（Non-Repeatable Reads）：一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读” 幻读（Phantom Reads）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读” 事务隔离级别防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。“脏读”、“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。 数据库实现事务隔离的方式，基本上可分为以下两种 在读取数据前，对其加锁，阻止其他事务对数据进行修改。 不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度来看，好像是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制（MultiVersion Concurrency Control，简称MVCC或MCC），也经常称为多版本数据库 4种隔离级别比较 读数据一致性 脏读 不可重复读 幻读 未提交读（Read uncommitted） 最低级别，只能保证不读取物理上损坏的数据 是 是 是 已提交度（Read committed） 语句级 否 是 是 可重复读（Repeatable read 事务级 否 否 是 序列化（Serializable） 最高级别，事务级 否 否 否 各具体数据库并不一定完全实现了上述4个隔离级别，MySQL 支持全部4个隔离级别，但在具体实现时，有一些特点，比如在一些隔离级别下是采用MVCC一致性读，但某些情况下又不是。 锁锁的类型按锁的粒度划分 行级锁：行级锁分为共享锁和排它锁。行级锁是Mysql中锁定粒度最细的锁。InnoDB引擎支持行级锁和表级锁，只有在通过索引条件检索数据的时候，才使用行级锁，否就使用表级锁。行级锁开销大，加锁慢，锁定粒度最小，发生锁冲突概率最低，并发度最高 表级锁：表级锁分为表共享锁和表独占锁。表级锁开销小，加锁快，锁定粒度大、发生锁冲突最高，并发度最低 页级锁：页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁。 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 间隙锁（Next-Key）：对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓 的间隙锁（Next-Key锁） 按锁级别划分 InnoDB实现了以下两种类型的行锁 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 排他锁（X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。 另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。 InnoDB行锁模式兼容性列表 X IX S IS X 冲突 冲突 冲突 冲突 IX 冲突 兼容 冲突 兼容 S 冲突 冲突 兼容 兼容 IS 冲突 兼容 兼容 兼容 如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。 行锁 在不通过索引条件查询的时候，InnoDB使用的是表锁，而不是行锁 由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的 当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁 即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比 如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁 检索值的数据类型与索引字段不同，虽然MySQL能够进行数据类型转换，但却不会使用索引，从而导致InnoDB使用表锁 间隙锁（Next-Key）当用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件 的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，或者叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁。 InnoDB 使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求；另外一方面，是为了满足其恢复和复制的需要 举例： 幻读1Select * from emp where id &gt; 100 for update; 是一个范围条件的检索，InnoDB不仅会对符合条件的记录加锁，也会对id大于101（这些记录并不存在）的“间隙”加锁.要是不使用间隙锁，如果其他事务插入了id大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读 恢复和复制对于“insert into target_tab select * from source_tab where …”和“create table target_tab …select … From source_tab where …(CTAS)”这种SQL语句，MySQL对这种SQL语句做了特别处理。因为不加锁的话，如果在上述语句执行过程中，其他事务对source_tab做了更新操作，造成不符合target_tab的数据在source_tab中变成了符合target_tab，就可能导致数据恢复的结果错误 表锁对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个别特殊事务中，也可以考虑使用表级锁。 事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。 事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。 锁在不同条件的差异InnoDB在不同隔离级别下的一致性读及锁的差异 SQL 条件 Read Uncommited Read Commited Repeatable Read Serializable select 相等 None locks Consisten read/None lock Consisten read/None lock Share locks 范围 None locks Consisten read/None lock Consisten read/None lock Share Next-Key update 相等 exclusive locks exclusive locks exclusive locks exclusive locks 范围 exclusive next-key exclusive next-key exclusive next-key exclusive next-key Insert N/A exclusive locks exclusive locks exclusive locks exclusive locks replace 无键冲突 exclusive locks exclusive locks exclusive locks exclusive locks 键冲突 exclusive next-key exclusive next-key exclusive next-key exclusive next-key delete 相等 exclusive locks exclusive locks exclusive locks exclusive locks 范围 exclusive next-key exclusive next-key exclusive next-key exclusive next-key Select ... from ... Lock in share mode 相等 Share locks Share locks Share locks Share locks 范围 Share locks Share locks Share Next-Key Share Next-Key Select * from ... For update 相等 exclusive locks exclusive locks exclusive locks exclusive locks 范围 exclusive locks Share locks exclusive next-key exclusive next-key 死锁MyISAM表锁是deadlock free的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了在InnoDB中发生死锁是可能的 发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数 innodb_lock_wait_timeout来解决。在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。 死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小，以及访问数据库的SQL语句，绝大部分死锁都可以避免。 避免死锁的常用方法 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。在下面的例子中，由于两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可以避免。 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://langonggong.com/tags/mysql/"},{"name":"DB","slug":"DB","permalink":"http://langonggong.com/tags/DB/"}]},{"title":"mysql索引","date":"2018-11-19T16:27:37.000Z","path":"2018/11/20/mysql索引/","text":"树红黑树 红黑树的特性: 每个节点或者是黑色，或者是红色 根节点是黑色 每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！] 如果一个节点是红色的，则它的子节点必须是黑色的 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点 红黑树的应用比较广泛，主要是用它来存储有序的数据，它的时间复杂度是O(lgn)，效率非常之高。例如，Java集合中的TreeSet和TreeMap，C++ STL中的set、map，以及Linux虚拟内存的管理，都是通过红黑树去实现的。 B树 B 树可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点 根节点至少有两个子节点 每个节点有M-1个key，并且以升序排列 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间 其它节点至少有M/2个子节点 B+树 B+树是对B树的一种变形树，它与B树的差异在于 有k个子结点的结点必然有k个关键码； 非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。 树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。 对比结构上 B树中关键字集合分布在整棵树中，叶节点中不包含任何关键字信息，而B+树关键字集合分布在叶子结点中，非叶节点只是叶子结点中关键字的索引 B树中任何一个关键字只出现在一个结点中，而B+树中的关键字必须出现在叶节点中，也可能在非叶结点中重复出现 性能上 不同于B树只适合随机检索，B+树同时支持随机检索和顺序检索； B+树的磁盘读写代价更低。B+树的内部结点并没有指向关键字具体信息的指针，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素。 B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。 （数据库索引采用B+树的主要原因是）B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低） 索引的分类从数据结构角度 B+树索引 hash索引 从物理存储角度 聚集索引（聚簇索引）（clustered index） 非聚集索引（non-clustered index） 从逻辑角度 普通索引或者单列索引 唯一索引 主键索引：主键索引是一种特殊的唯一索引，不允许有空值 多列索引（复合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合 全文索引 从存储引擎的角度 主键索引 辅助索引(二级索引) B+树索引和哈希索引的明显区别是 如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据 哈希索引无法完成范围查询检索 哈希索引无法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询） 哈希索引也不支持多列联合索引的最左匹配规则 B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题 不同引擎的索引MyISAM索引实现主键索引MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址 辅助索引在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复 InnoDB索引实现主键索引MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引 (图inndb主键索引）是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键 辅助索引InnoDB的所有辅助索引都引用主键作为data域 InnoDB 表是基于聚簇索引建立的。因此InnoDB 的索引能提供一种非常快速的主键查找性能。不过，它的辅助索引（Secondary Index， 也就是非主键索引）也会包含主键列，所以，如果主键定义的比较大，其他索引也将很大。如果想在表上定义 、很多索引，则争取尽量把主键定义得小一些 聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录 InnoDB和MyISAM的区别 一是主索引的区别，InnoDB的数据文件本身就是索引文件。而MyISAM的索引和数据是分开的。 二是辅助索引的区别：InnoDB的辅助索引data域存储相应记录主键的值而不是地址。而MyISAM的辅助索引和主索引没有多大区别。 索引详解前缀索引有时候需要索引很长的字符列，这会让索引变得大且慢。通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。对于BLOB，TEXT，或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整长度。要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。前缀应该足够长，以使得前缀索引的选择性接近于索引的整个列。mysql无法使用其前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描。 多列索引多列索引并不是指建立多个单列索引，而是指在多个字段建立一个索引。 又叫联合索引、复合索引。符合最左前缀规则 多列建索引比对每个列分别建索引更有优势，因为索引建立得越多就越占磁盘空间，在更新数据的时候速度会更慢。那如果我们分别在a和b上创建两个列索引，mysql的处理方式就不一样了，它会选择一个最严格的索引来进行检索，可以理解为检索能力最强的那个索引来检索，另外一个利用不上了，这样效果就不如多列索引了 将选择性最高的列放到索引的最前列 覆盖索引 解释一： 就是select的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。 解释二： 索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。 解释三：是非聚集组合索引的一种形式，它包括在查询里的Select、Join和Where子句用到的所有列（即建立索引的字段正好是覆盖查询语句[select子句]与查询条件[Where子句]中所涉及的字段，也即，索引包含了查询正在查找的所有数据） 使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为using index,MySQL查询优化器在执行查询前会决定是否有索引覆盖查询。覆盖索引也并不适用于任意的索引类型，索引必须存储列的值。Hash 和full-text索引不存储值，因此MySQL只能使用B-TREE 空间索引参考链接 全文索引参考链接 索引的优缺点优点 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能 缺点 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 索引建立原则一般来说，不应该创建索引的的这些列具有下列特点 对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。 当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 常见规则 最左前缀匹配原则 mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整 =和in可以乱序 比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 尽量选择区分度高的列作为索引 区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1 索引列不能参与计算 比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大 尽量的扩展索引，不要新建索引 比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可","tags":[{"name":"mysql","slug":"mysql","permalink":"http://langonggong.com/tags/mysql/"},{"name":"DB","slug":"DB","permalink":"http://langonggong.com/tags/DB/"}]},{"title":"生产者消费者","date":"2018-11-17T13:47:09.000Z","path":"2018/11/17/生产者消费者/","text":"注意：必须使用while循环，因为当前线程被唤醒之前，同时有消费者和生产线程都有执行过，导致当前的条件不满足。例如，size为0导致消费者线程thread1被阻塞，后来成产者线程thread2和消费者线程thread3都有执行，thread2唤醒了thread1，但是此时thread1发现size还是0，继续阻塞 wait() / notify()方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Storage1 &#123; private int MAX_SIZE = 4; private List&lt;Object&gt; list = new ArrayList&lt;&gt;(); public void produce() &#123; synchronized (list) &#123; while (list.size() == MAX_SIZE) &#123; System.out.println(\"full,wait!\"); try &#123; list.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; list.add(new Object()); System.out.println(\"produce,now size is:\" + list.size()); list.notifyAll(); &#125; &#125; public void consume() &#123; synchronized (list) &#123; while (list.size() == 0) &#123; System.out.println(\"empty,wait!\"); try &#123; list.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; list.remove(0); System.out.println(\"consume,new size is:\" + list.size()); list.notifyAll(); &#125; &#125; public static void main(String[] args) &#123; Storage1 storage1 = new Storage1(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; storage1.consume(); &#125; &#125;).start(); &#125; for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; storage1.produce(); &#125; &#125;).start(); &#125; &#125;&#125; await() / signal()方法通过在Lock对象上调用newCondition()方法，将一个condition和一个约束条件进行绑定，进而控制并发程序访问竞争资源的安全 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Storage2 &#123; private int MAX_SIZE = 4; private List&lt;Object&gt; list = new ArrayList&lt;&gt;(); private Lock lock = new ReentrantLock(); private Condition notEmpty = lock.newCondition(); private Condition notFull = lock.newCondition(); public void produce() &#123; lock.lock(); try &#123; while (list.size() == MAX_SIZE) &#123; System.out.println(\"full,wait!\"); notFull.await(); &#125; list.add(new Object()); System.out.println(\"produce,now size is:\" + list.size()); notEmpty.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void consume() &#123; lock.lock(); try &#123; while (list.isEmpty()) &#123; System.out.println(\"empty,wait!\"); notEmpty.await(); &#125; list.remove(0); System.out.println(\"consume,now size is:\" + list.size()); notFull.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; Storage2 Storage2 = new Storage2(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Storage2.consume(); &#125; &#125;).start(); &#125; for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Storage2.produce(); &#125; &#125;).start(); &#125; &#125;&#125; BlockingQueue put()方法：容量达到最大时，自动阻塞。 take()方法：容量为0时，自动阻塞。 1234567891011121314151617181920212223242526272829303132public class Storage3 &#123; private int MAX_SIZE = 4; private LinkedBlockingDeque&lt;Object&gt; deque = new LinkedBlockingDeque&lt;&gt;(MAX_SIZE); public void produce() &#123; if (deque.size() == MAX_SIZE) &#123; System.out.println(\"full,wait!\"); &#125; try &#123; deque.put(new Object()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"produce,now size is:\" + deque.size()); &#125; public void consume() &#123; if (deque.isEmpty()) &#123; System.out.println(\"empty,wait!\"); &#125; try &#123; deque.takeFirst(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"consume,now size is:\" + deque.size()); &#125;","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"CyclicBarrier","date":"2018-11-17T07:11:33.000Z","path":"2018/11/17/CyclicBarrier/","text":"回环栅栏是一个同步工具类，它允许一组线程互相等待，直到到达某个公共屏障点。与CountDownLatch不同的是该barrier在释放等待线程后可以重用，所以称它为循环（Cyclic）的屏障（Barrier） CyclicBarrier支持一个可选的Runnable命令，在一组线程中的最后一个线程到达之后（但在释放所有线程之前），该命令只在每个屏障点运行一次。若在继续所有参与线程之前更新共享状态，此屏障操作很有用 CyclicBarrier(int parties) CyclicBarrier(int parties, Runnable barrierAction)：参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容 int await()：用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务 int await(long timeout, TimeUnit unit)：让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务 使用场景：多个子线程执行部分逻辑后进入就绪状态，停顿一下，然后等待某个关键线程执行，之后多个子线程再继续执行后面的逻辑","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"数组中只出现了一次的数","date":"2018-11-08T07:40:36.000Z","path":"2018/11/08/数组中只出现了一次的数/","text":"一个整型数组里除了两个数字之外，其他的数字都出现了偶数次。请写程序找出这两个只出现一次的数字 1234567891011121314151617181920public void FindNumsAppearOnce(int [] array,int num1[] , int num2[]) &#123; if (array == null || array.length &lt; 2) &#123; return; &#125; int k0 = 0, k1 = 0; //通过抑或运算，出现偶数次的元素消失 for (int i : array) &#123; k0 = k0 ^ i; &#125; //获得该值二进制数字中的最右边的1 int right = k0 &amp; (~k0 + 1); for (int i : array) &#123; if ((right &amp; i) != 0) &#123; k1 = k1 ^ i; &#125; &#125; num1[0] = Math.min(k1, k1 ^ k0); num2[0] = Math.max(k1, k1 ^ k0); &#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"位运算","slug":"位运算","permalink":"http://langonggong.com/tags/位运算/"}]},{"title":"责任链模式","date":"2018-10-29T14:55:07.000Z","path":"2018/10/29/责任链模式/","text":"责任链模式是一种对象的行为模式。在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。Tomcat中的Filter就是使用了责任链模式 Request123456789101112public class Request &#123; String requestStr; public String getRequest() &#123; return requestStr; &#125; public void setRequest(String request) &#123; this.requestStr = request; &#125; &#125; Response123456789101112public class Response &#123; String responseStr; public String getResponse() &#123; return responseStr; &#125; public void setResponse(String response) &#123; this.responseStr = response; &#125; &#125; Filter123public interface Filter &#123; void doFilter(Request request,Response response,FilterChain chain);&#125; HTMLFilter12345678910public class HTMLFilter implements Filter &#123; public void doFilter(Request request, Response response,FilterChain chain) &#123; //将字符串中出现的\"&lt;&gt;\"符号替换成\"[]\" request.requestStr=request.requestStr .replace('&lt;', '[').replace('&gt;', ']'); chain.doFilter(request, response,chain); response.responseStr+=\"---HTMLFilter()\"; &#125;&#125; SensitiveFilter1234567891011public class SensitiveFilter implements Filter&#123; public void doFilter(Request request, Response response,FilterChain chain) &#123; //处理字符串中的敏感信息，将被就业和谐成就业 request.requestStr=request.requestStr .replace(\"被就业\", \"就业\").replace(\"敏感\", \"\"); chain.doFilter(request, response,chain); response.responseStr+=\"---sensitiveFilter()\"; &#125;&#125; FilterChain12345678910111213141516171819202122public class FilterChain implements Filter&#123; //用List集合来存储过滤规则 List&lt;Filter&gt; filters = new ArrayList&lt;Filter&gt;(); //用于标记规则的引用顺序 int index=0; //往规则链条中添加规则 public FilterChain addFilter(Filter f) &#123; filters.add(f); //代码的设计技巧:Chain链添加过滤规则结束后返回添加后的Chain，方便我们下面doFilter函数的操作 return this; &#125; public void doFilter(Request request,Response response,FilterChain chain)&#123; if(index==filters.size())&#123; return; &#125; //每添加一个过滤规则，index自增1 Filter f=filters.get(index); index++; //根据索引值获取对应的规律规则对字符串进行处理 f.doFilter(request, response, chain); &#125;&#125; 测试用例1234567891011121314151617public class Main &#123; public static void main(String args[]) &#123; String msg = \":):,&lt;script&gt;,敏感,被就业,网络授课\"; Request request=new Request(); request.setRequest(msg); Response response=new Response(); response.setResponse(\"response:\"); //FilterChain,过滤规则形成的拦截链条 FilterChain fc=new FilterChain(); fc.addFilter(new HTMLFilter()) .addFilter(new SensitiveFilter()) .addFilter(new FaceFilter()); //按照FilterChain的规则顺序，依次应用过滤规则 fc.doFilter(request, response,fc); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://langonggong.com/tags/设计模式/"}]},{"title":"命令模式","date":"2018-10-29T09:22:57.000Z","path":"2018/10/29/命令模式/","text":"目的 更方便的对命令进行扩展（注意：这不是主要的优势，后面会提到） 对多个命令的统一控制（这种控制包括但不限于：队列、撤销/恢复、记录日志等等） 角色 Command：定义命令的统一接口 ConcreteCommand：Command接口的实现者，用来执行具体的命令，某些情况下可以直接用来充当Receiver Receiver：命令的实际执行者 Invoker：命令的请求者，是命令模式中最重要的角色。这个角色用来对各个命令进行控制 实现抽象角色1234public interface ICommand&#123; void Execute();&#125; 角色A1234567891011121314public class ConcreteCommandA : ICommand&#123; private Receiver receiver = null; public ConcreteCommandA(Receiver receiver) &#123; this.receiver = receiver; &#125; public void Execute() &#123; this.receiver.DoA(); &#125;&#125; 角色B1234567891011121314public class ConcreteCommandB : ICommand&#123; private Receiver receiver = null; public ConcreteCommandB(Receiver receiver) &#123; this.receiver = receiver; &#125; public void Execute() &#123; this.receiver.DoB(); &#125;&#125; Receiver123456789101112public class Receiver&#123; public void DoA() &#123; //DoSomething &#125; public void DoB() &#123; //DoSomething &#125;&#125; Invoker123456789101112131415public class Invoker&#123; private ICommand command = null; //设置命令 public void SetCommand(ICommand command) &#123; this.command = command; &#125; //执行命令 public void RunCommand() &#123; command.Execute(); &#125;&#125; 客户端调用123456789101112public class Client&#123; public Client() &#123; Receiver receiver = new Receiver(); Invoker invoker = new Invoker(); invoker.SetCommand(new ConcreteCommandA(receiver)); invoker.RunCommand(); invoker.SetCommand(new ConcreteCommandB(receiver)); invoker.RunCommand(); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://langonggong.com/tags/设计模式/"}]},{"title":"观察者模式","date":"2018-10-29T06:29:27.000Z","path":"2018/10/29/观察者模式/","text":"Subject（目标）：目标又称为主题，它是指被观察的对象。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供一系列方法来增加和删除观察者对象，同时它定义了通知方法notify()。目标类可以是接口，也可以是抽象类或具体类。 ConcreteSubject（具体目标）：具体目标是目标类的子类，通常它包含有经常发生改变的数据，当它的状态发生改变时，向它的各个观察者发出通知；同时它还实现了在目标类中定义的抽象业务逻辑方法（如果有的话）。如果无须扩展目标类，则具体目标类可以省略。 Observer（观察者）：观察者将对观察目标的改变做出反应，观察者一般定义为接口，该接口声明了更新数据的方法update()，因此又称为抽象观察者。 ConcreteObserver（具体观察者）：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致；它实现了在抽象观察者Observer中定义的update()方法。通常在实现时，可以调用具体目标类的attach()方法将自己添加到目标类的集合中或通过detach()方法将自己从目标类的集合中删除 定义一个抽象被观察者接口1234567public interface Observerable &#123; public void attach(Observer o); public void detach(Observer o); public void notify(); &#125; 定义一个抽象观察者接口123public interface Observer &#123; public void update(String message);&#125; 定义被观察者，实现了Observerable接口，对Observerable接口的三个方法进行了具体实现，同时有一个List集合，用以保存注册的观察者，等需要通知观察者时，遍历该集合即可123456789101112131415161718192021222324252627282930313233343536373839public class WechatServer implements Observerable &#123; //注意到这个List集合的泛型参数为Observer接口，设计原则：面向接口编程而不是面向实现编程 private List&lt;Observer&gt; list; private String message; public WechatServer() &#123; list = new ArrayList&lt;Observer&gt;(); &#125; @Override public void attach(Observer o) &#123; list.add(o); &#125; @Override public void detach(Observer o) &#123; if(!list.isEmpty()) list.remove(o); &#125; //遍历 @Override public void notify() &#123; for(int i = 0; i &lt; list.size(); i++) &#123; Observer oserver = list.get(i); oserver.update(message); &#125; &#125; public void setInfomation(String s) &#123; this.message = s; System.out.println(\"微信服务更新消息： \" + s); //消息更新，通知所有观察者 notifyObserver(); &#125;&#125; 定义具体观察者，微信公众号的具体观察者为用户User1234567891011121314151617181920public class User implements Observer &#123; private String name; private String message; public User(String name) &#123; this.name = name; &#125; @Override public void update(String message) &#123; this.message = message; read(); &#125; public void read() &#123; System.out.println(name + \" 收到推送消息： \" + message); &#125; &#125; 测试用例12345678910111213141516171819public class Test &#123; public static void main(String[] args) &#123; WechatServer server = new WechatServer(); Observer userZhang = new User(\"ZhangSan\"); Observer userLi = new User(\"LiSi\"); Observer userWang = new User(\"WangWu\"); server. attach(userZhang); server. attach(userLi); server. attach(userWang); server.setInfomation(\"PHP是世界上最好用的语言！\"); server.removeObserver(userZhang); server.setInfomation(\"JAVA是世界上最好用的语言！\"); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://langonggong.com/tags/设计模式/"}]},{"title":"https","date":"2018-10-26T09:44:29.000Z","path":"2018/10/26/https/","text":"客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。 Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。 客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。 客户端的浏览器根据双方同意的安全等级，在本地生成一对对称密钥作为会话秘钥，然后利用网站的公钥将会话密钥加密，并传送给网站。 Web服务器利用自己的私钥解密出会话密钥。 Web服务器利用会话密钥加密与客户端之间的通信 为什么要同时用到对称秘钥和非对称秘钥? 对称秘钥加密、解密效率高，涉及web页面和没提内容输出时更高效 对称秘钥不能以明文直接发给服务器，必须用非对称秘钥加密 对称秘钥是长度较短的随机字符，适合用非对称秘钥加密","tags":[{"name":"https","slug":"https","permalink":"http://langonggong.com/tags/https/"}]},{"title":"求二进制数中的1的个数","date":"2018-10-24T16:18:50.000Z","path":"2018/10/25/求二进制数中的1的个数/","text":"输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示 12345678public int NumberOf1(int n) &#123; int count = 0; while (n != 0) &#123; count++; n = n &amp; (n - 1); &#125; return count;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"位运算","slug":"位运算","permalink":"http://langonggong.com/tags/位运算/"}]},{"title":"适配器模式","date":"2018-10-24T15:07:28.000Z","path":"2018/10/24/适配器模式/","text":"配器就是一种适配中间件，它存在于不匹配的二者之间，用于连接二者，将不匹配变得匹配，简单点理解就是平常所见的转接头，转换器之类的存在 类适配器 想要使用一个已经存在的类，但是它却不符合现有的接口规范，导致无法直接去访问，这时创建一个适配器就能间接去访问这个类中的方法 我们有一个类，想将其设计为可重用的类（可被多处访问），我们可以创建适配器来将这个类来适配其他没有提供合适接口的类 接口适配器 想要使用接口中的某个或某些方法，但是接口中有太多方法，我们要使用时必须实现接口并实现其中的所有方法，可以使用抽象类来实现接口，并不对方法进行实现（仅置空），然后我们再继承这个抽象类来通过重写想用的方法的方式来实现。这个抽象类就是适配器 Ps2123public interface Ps2 &#123; void isPs2();&#125; Usb123public interface Usb &#123; void isUsb();&#125; Usber12345678public class Usber implements Usb &#123; @Override public void isUsb() &#123; System.out.println(\"USB口\"); &#125;&#125; Adapter12345678public class Adapter extends Usber implements Ps2 &#123; @Override public void isPs2() &#123; isUsb(); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://langonggong.com/tags/设计模式/"},{"name":"适配器模式","slug":"适配器模式","permalink":"http://langonggong.com/tags/适配器模式/"}]},{"title":"前序、中序序列构建二叉树","date":"2018-10-22T14:12:56.000Z","path":"2018/10/22/前序、中序序列构建二叉树/","text":"描述输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字 思路使用递归，在当前处理中获取前序和中序遍历中的头结点、左子树、右子树，递归处理左右子树，返回构建好的树结构 代码12345678910111213141516171819202122232425public TreeNode reConstructBinaryTree(int [] pre,int [] in) &#123; return solve(pre, 0, pre.length - 1, in, 0, in.length - 1);&#125;public TreeNode solve(int[] pre, int preStart, int preEnd, int[] in, int inStart, int inEnd) &#123; if (preStart &gt; preEnd) &#123; return null; &#125; if (preStart == preEnd) &#123; return new TreeNode(pre[preStart]); &#125; int cur = pre[preStart]; int index = inStart; while (index &lt;= inEnd &amp;&amp; cur != in[index]) &#123; index++; &#125; //左子树的长度 int leftLength = index - inStart; TreeNode head = new TreeNode(pre[preStart]); TreeNode left = solve(pre, preStart + 1, preStart + leftLength, in, inStart, index - 1); TreeNode right = solve(pre, preStart + leftLength + 1, preEnd, in, index + 1, inEnd); head.left = left; head.right = right; return head;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"二叉树","slug":"二叉树","permalink":"http://langonggong.com/tags/二叉树/"}]},{"title":"判断完全二叉树","date":"2018-10-19T13:20:47.000Z","path":"2018/10/19/判断完全二叉树/","text":"123456789101112131415161718192021222324252627282930313233 public boolean chk(TreeNode root) &#123; TreeNode[] arr = new TreeNode[501]; int head = 0, tail = 0; TreeNode cur; arr[tail++] = root; while (head != tail) &#123; cur = arr[head++]; if (cur.left != null) &#123; arr[tail++] = cur.left; &#125; if (cur.right != null) &#123; arr[tail++] = cur.right; &#125; &#125;///判断是否应该是最后一个节点 boolean isTail = false; for(int i=0;i&lt;tail;i++) &#123; cur = arr[i]; if (cur.left == null || cur.right == null) &#123; if (cur.left == null &amp;&amp; cur.right != null) &#123; return false; &#125; if (!isTail) &#123; isTail = true; &#125; else if (cur.left != null || cur.right != null) &#123; return false; &#125; &#125; &#125; return true; &#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"完全二叉树","slug":"完全二叉树","permalink":"http://langonggong.com/tags/完全二叉树/"}]},{"title":"判断二叉平衡树","date":"2018-10-19T12:10:38.000Z","path":"2018/10/19/判断二叉平衡树/","text":"1234567891011121314151617public boolean check(TreeNode root) &#123; return chk(root) != -1;&#125;public int chk(TreeNode treeNode) &#123; if (treeNode == null) &#123; return 0; &#125; int left = chk(treeNode.left); int right = chk(treeNode.right); if (left &lt; 0 || right &lt; 0 || Math.abs(left - right) &gt; 1) &#123; return -1; &#125; return Math.max(left, right) + 1;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"二叉树","slug":"二叉树","permalink":"http://langonggong.com/tags/二叉树/"},{"name":"二叉平衡树","slug":"二叉平衡树","permalink":"http://langonggong.com/tags/二叉平衡树/"}]},{"title":"非递归遍历二叉树","date":"2018-10-19T10:50:40.000Z","path":"2018/10/19/遍历二叉树/","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576private int[] pre(TreeNode node) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode cur; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); stack.push(node); while (!stack.isEmpty()) &#123; cur = stack.pop(); list.add(cur.val); if (cur.right != null) &#123; stack.push(cur.right); &#125; if (cur.left != null) &#123; stack.push(cur.left); &#125; &#125; return list2arr(list);&#125;public int[] mid(TreeNode node) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode cur = node; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); stack.push(node); while (!stack.isEmpty()) &#123; while (cur != null &amp;&amp; cur.left != null) &#123; stack.push(cur.left); cur = cur.left; &#125; cur = stack.pop(); list.add(cur.val); if (cur.right != null) &#123; stack.push(cur.right); &#125; cur = cur.right; &#125; return list2arr(list);&#125;private int[] after(TreeNode node) &#123; Stack&lt;TreeNode&gt; stack1 = new Stack&lt;&gt;(); Stack&lt;TreeNode&gt; stack2 = new Stack&lt;&gt;(); TreeNode cur; stack1.push(node); while (!stack1.isEmpty()) &#123; cur = stack1.pop(); stack2.push(cur); if (cur.left != null) &#123; stack1.push(cur.left); &#125; if (cur.right != null) &#123; stack1.push(cur.right); &#125; &#125; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while (!stack2.isEmpty()) &#123; list.add(stack2.pop().val); &#125; return list2arr(list);&#125;private int[] list2arr(List&lt;Integer&gt; list) &#123; int[] arr = new int[list.size()]; for (int i = 0; i &lt; list.size(); i++) &#123; arr[i] = list.get(i); &#125; return arr;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"二叉树","slug":"二叉树","permalink":"http://langonggong.com/tags/二叉树/"}]},{"title":"长连接","date":"2018-10-14T07:33:17.000Z","path":"2018/10/14/长连接/","text":"短连接 （挥手的地方，第一次发送FIN应该是客户端而非服务端）http协议是无状态协议，每次的请求响应都是独立的客户端通过http进程发起与服务主机的tcp连接，向所建立的tcp连接相关的本地套接字发送一个http请求消息。服务器与tcp相关的本地套接字收到这个请求后，进行处理，经由同一个套接字发出相应消息，同时告知tcp关闭tcp连接 长连接http1.1采用持续连接机制，即客户端和服务器建立tcp连接后，多个http请求可以重复利用已经建立起来的tcp连接。这个持续的tcp连接会空闲一段特定的时间后关闭 不带流水线用户的http请求只能在上一个请求得到响应后发出 带流水线客户端在web页面发现引用时就可以发起请求，无需考虑上一个请求的响应是否已经收到","tags":[{"name":"http","slug":"http","permalink":"http://langonggong.com/tags/http/"},{"name":"长连接","slug":"长连接","permalink":"http://langonggong.com/tags/长连接/"}]},{"title":"DispatcherServlet","date":"2018-10-13T07:11:17.000Z","path":"2018/10/13/DispatcherServlet/","text":"容器配置123456789101112131415161718192021222324252627&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:redis/spring-redis.xml &lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:spring/spring-mvc.xml &lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 参数 描述 contextClass 实现WebApplicationContext接口的类，当前的servlet用它来创建上下文。如果这个参数没有指定， 默认使用XmlWebApplicationContext contextConfigLocation 传给上下文实例（由contextClass指定）的字符串，用来指定上下文的位置。这个字符串可以被分成多个字符串（使用逗号作为分隔符） 来支持多个上下文（在多上下文的情况下，如果同一个bean被定义两次，后面一个优先） namespace WebApplicationContext命名空间。默认值是[server-name]-servlet ContextLoaderListener初始化的上下文和DispatcherServlet初始化的上下文关系 从图中可以看出 ContextLoaderListener初始化的上下文加载的Bean是对于整个应用程序共享的，不管是使用什么表现层技术，一般如DAO层、Service层Bean DispatcherServlet初始化的上下文加载的Bean是只对Spring Web MVC有效的Bean，如Controller、HandlerMapping、HandlerAdapter等等，该初始化上下文应该只加载Web相关组件 启动过程Spring MVC容器的初始化ContextLoaderListener监听器的作用就是启动Web容器（如tomcat）时，自动装配ApplicationContext的配置信息。因为它实现了ServletContextListener这个接口，在web.xml配置了这个监听器，启动容器时，就会默认执行它实现的contextInitialized()方法初始化WebApplicationContext实例，并放入到ServletContext中。由于在ContextLoaderListener继承了ContextLoader这个类，所以整个加载配置过程由ContextLoader来完成 ServletContextListener接口ServletContextListener中的核心逻辑便是初始化WebApplicationContext实例并存放至ServletContext中 12345678910111213141516171819public interface ServletContextListener extends EventListener &#123; /** ** Notification that the web application initialization ** process is starting. ** All ServletContextListeners are notified of context ** initialization before any filter or servlet in the web ** application is initialized. */ public void contextInitialized ( ServletContextEvent sce ); /** ** Notification that the servlet context is about to be shut down. ** All servlets and filters have been destroy()ed before any ** ServletContextListeners are notified of context ** destruction. */ public void contextDestroyed ( ServletContextEvent sce );&#125; ContextLoaderListener类这是ContextLoaderListener中的contextInitialized()方法，这里主要是用initWebApplicationContext()方法来初始化WebApplicationContext。这里涉及到一个常用类WebApplicationContext：它继承自ApplicationContext，在ApplicationContext的基础上又追加了一些特定于Web的操作及属性 1234567891011121314151617181920212223242526272829public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public ContextLoaderListener() &#123; &#125; public ContextLoaderListener(WebApplicationContext context) &#123; super(context); &#125; /** * Initialize the root web application context. */ @Override public void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext()); &#125; /** * Close the root web application context. */ @Override public void contextDestroyed(ServletContextEvent event) &#123; closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &#125;&#125; ContextLoader类在initWebApplicationContext()方法中主要体现了WebApplicationContext实例的创建过程。首先，验证WebApplicationContext的存在性，通过查看ServletContext实例中是否有对应key的属性验证WebApplicationContext是否已经创建过实例。如果没有通过createWebApplicationContext()方法来创建实例，并存放至ServletContext中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * Initialize Spring's web application context for the given servlet context, * using the application context provided at construction time, or creating a new one */public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException( \"Cannot initialize context because there is already a root application context present - \" + \"check whether you have multiple ContextLoader* definitions in your web.xml!\"); &#125; Log logger = LogFactory.getLog(ContextLoader.class); servletContext.log(\"Initializing Spring root WebApplicationContext\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Root WebApplicationContext: initialization started\"); &#125; long startTime = System.currentTimeMillis(); try &#123; if (this.context == null) &#123; this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; if (!cwac.isActive()) &#123; if (cwac.getParent() == null) &#123; ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Published root WebApplicationContext as ServletContext attribute with name [\" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + \"]\"); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info(\"Root WebApplicationContext: initialization completed in \" + elapsedTime + \" ms\"); &#125; return this.context; &#125; catch (RuntimeException ex) &#123; logger.error(\"Context initialization failed\", ex); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; logger.error(\"Context initialization failed\", err); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125;&#125; 在createWebApplicationContext()方法中，通过BeanUtils.instanceClass()方法创建实例，而WebApplicationContext的实现类名称则通过determineContextClass()方法获得 123456789101112/** * Instantiate the root WebApplicationContext for this loader, either the * default context class or a custom context class if specified. */protected WebApplicationContext createWebApplicationContext(ServletContext sc) &#123; Class&lt;?&gt; contextClass = determineContextClass(sc); if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException(\"Custom context class [\" + contextClass.getName() + \"] is not of type [\" + ConfigurableWebApplicationContext.class.getName() + \"]\"); &#125; return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; determineContextClass()方法，通过defaultStrategies.getProperty()方法获得实现类的名称，而defaultStrategies是在ContextLoader类的静态代码块中赋值的。具体的途径，则是读取ContextLoader类的同目录下的ContextLoader.properties属性文件来确定的 1234567891011121314151617181920212223242526/** * Return the WebApplicationContext implementation class to use, either the * default XmlWebApplicationContext or a custom context class if specified. */protected Class&lt;?&gt; determineContextClass(ServletContext servletContext) &#123; String contextClassName = servletContext.getInitParameter(CONTEXT_CLASS_PARAM); if (contextClassName != null) &#123; try &#123; return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( \"Failed to load custom context class [\" + contextClassName + \"]\", ex); &#125; &#125; else &#123; contextClassName = defaultStrategies.getProperty(WebApplicationContext.class.getName()); try &#123; return ClassUtils.forName(contextClassName, ContextLoader.class.getClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( \"Failed to load default context class [\" + contextClassName + \"]\", ex); &#125; &#125;&#125; ContextLoader.properties 1org.springframework.web.context.WebApplicationContext=org.springframework.web.context.support.XmlWebApplicationContext diapatcherServlet的初始化DispatcherServlet实现了Servlet接口的实现类。Servlet的生命周期分为3个阶段：初始化、运行和销毁。而其初始化阶段可分为 Servlet容器加载Servlet类，把类的.class文件中的数据读到内存中 Servlet容器中创建一个ServletConfig对象。该对象中包含了Servlet的初始化配置信息 Servlet容器创建一个Servlet对象 Servlet容器调用Servlet对象的init()方法进行初始化 HttpServletBeanServlet的初始化阶段会调用它的init()方法，DispatcherServlet也不例外，在它的父类HttpServletBean中找到了该方法 init()方法中先通过ServletConfigPropertiesValues()方法对Servlet初始化参数进行封装，然后再将这个Servlet转换成一个BeanWrapper对象，从而能够以spring的方式来对初始化参数的值进行注入。这些属性如contextConfigLocation、namespace等等。同时注册一个属性编辑器，一旦在属性注入的时候遇到Resource类型的属性就会使用ResourceEditor去解析。再留一个initBeanWrapper(bw)方法给子类覆盖，让子类处真正执行BeanWrapper的属性注入工作。但是HttpServletBean的子类FrameworkServlet和DispatcherServlet都没有覆盖其initBeanWrapper(bw)方法，所以创建的BeanWrapper对象没有任何作用 123456789101112131415161718192021222324252627282930313233343536373839public abstract class HttpServletBean extends HttpServlet implements EnvironmentCapable, EnvironmentAware &#123; /** * Map config parameters onto bean properties of this servlet, and * invoke subclass initialization. */ @Override public final void init() throws ServletException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Initializing servlet '\" + getServletName() + \"'\"); &#125; // Set bean properties from init parameters. try &#123; PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; logger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex); throw ex; &#125; // Let subclasses do whatever initialization they like. initServletBean(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\"); &#125; &#125; protected void initServletBean() throws ServletException &#123; &#125;&#125; FrameworkServlet程序接着往下走，运行到了initServletBean()方法。在之前，ContextLoaderListener加载的时候已经创建了WebApplicationContext实例，而在这里是对这个实例的进一步补充初始化。这个方法在HttpServletBean的子类FrameworkServlet中得到了重写 12345678910111213141516171819202122232425262728293031323334public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; /** * Overridden method of &#123;@link HttpServletBean&#125;, invoked after any bean properties * have been set. Creates this servlet's WebApplicationContext. */ @Override protected final void initServletBean() throws ServletException &#123; getServletContext().log(\"Initializing Spring FrameworkServlet '\" + getServletName() + \"'\"); if (this.logger.isInfoEnabled()) &#123; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization started\"); &#125; long startTime = System.currentTimeMillis(); try &#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; catch (RuntimeException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; if (this.logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization completed in \" + elapsedTime + \" ms\"); &#125; &#125;&#125; initWebApplicationContext()方法主要用于创建或刷新WebApplicationContext实例，并对Servlet功能所使用的变量进行初始化。它获得ContextLoaderListener中初始化的rootContext。再通过构造函数和Servlet的contextAttribute属性查找ServletContext来进行webApplicationContext实例的初始化，如果都不行，只能重新创建一个新的实例。最终都要执行configureAndRefreshWebApplicationContext()方法中的refresh()方法完成servlet中配置文件的加载和与rootContext的整合 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Initialize and publish the WebApplicationContext for this servlet. * &lt;p&gt;Delegates to &#123;@link #createWebApplicationContext&#125; for actual creation * of the context. Can be overridden in subclasses. * @return the WebApplicationContext instance * @see #FrameworkServlet(WebApplicationContext) * @see #setContextClass * @see #setContextConfigLocation */protected WebApplicationContext initWebApplicationContext() &#123; WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // A context instance was injected at construction time -&gt; use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; set // the root application context (if any; may be null) as the parent cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; if (wac == null) &#123; // No context instance was injected at construction time -&gt; see if one // has been registered in the servlet context. If one exists, it is assumed // that the parent context (if any) has already been set and that the // user has performed any initialization such as setting the context id wac = findWebApplicationContext(); &#125; if (wac == null) &#123; // No context instance is defined for this servlet -&gt; create a local one wac = createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; // Either the context is not a ConfigurableApplicationContext with refresh // support or the context injected at construction time had already been // refreshed -&gt; trigger initial onRefresh manually here. onRefresh(wac); &#125; if (this.publishContext) &#123; // Publish the context as a servlet context attribute. String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Published WebApplicationContext of servlet '\" + getServletName() + \"' as ServletContext attribute with name [\" + attrName + \"]\"); &#125; &#125; return wac;&#125; onRefresh(wac)方法是FrameworkServlet提供的模板方法，在其子类DispatcherServlet的onRefresh()方法中进行了重写 123protected void onRefresh(ApplicationContext context) &#123; // For subclasses: do nothing by default.&#125; DispatcherServlet在onRefresh()方法中调用了initStrategies()方法来完成初始化工作，初始化Spring MVC的9个组件 123456789101112131415161718192021222324252627public class DispatcherServlet extends FrameworkServlet &#123; /** * This implementation calls &#123;@link #initStrategies&#125;. */ @Override protected void onRefresh(ApplicationContext context) &#123; initStrategies(context); &#125; /** * Initialize the strategy objects that this servlet uses. * &lt;p&gt;May be overridden in subclasses in order to initialize further strategy objects. */ protected void initStrategies(ApplicationContext context) &#123; initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); initHandlerMappings(context); initHandlerAdapters(context); initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); initViewResolvers(context); initFlashMapManager(context); &#125; &#125; DispatcherServlet详解默认配置DispatcherServlet的默认配置在DispatcherServlet.properties（和DispatcherServlet类在一个包下）中，而且是当Spring配置文件中没有指定配置时使用的默认策略 1234567891011121314151617181920org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolverorg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolverorg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\\ org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMappingorg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\ org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapterorg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolverorg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslatororg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolverorg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager 使用的特殊的BeanDispatcherServlet默认使用WebApplicationContext作为上下文，该上下文中有些特殊的Bean Controller 处理器/页面控制器，做的是MVC中的C的事情，但控制逻辑转移到前端控制器了，用于对请求进行处理 HandlerMapping 请求到处理器的映射，如果映射成功返回一个HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器）对象；如BeanNameUrlHandlerMapping将URL与Bean名字映射，映射成功的Bean就是此处的处理器 HandlerAdapter HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；如SimpleControllerHandlerAdapter将对实现了Controller接口的Bean进行适配，并且掉处理器的handleRequest方法进行功能处理 ViewResolver ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；如InternalResourceViewResolver将逻辑视图名映射为jsp视图 LocalResover 本地化解析，因为Spring支持国际化，因此LocalResover解析客户端的Locale信息从而方便进行国际化 ThemeResovler 主题解析，通过它来实现一个页面多套风格，即常见的类似于软件皮肤效果 MultipartResolver 文件上传解析，用于支持文件上传 HandlerExceptionResolver 处理器异常解析，可以将异常映射到相应的统一错误界面，从而显示用户友好的界面（而不是给用户看到具体的错误信息） RequestToViewNameTranslator 当处理器没有返回逻辑视图名等相关信息时，自动将请求URL映射为逻辑视图名 FlashMapManager 用于管理FlashMap的策略接口，FlashMap用于存储一个请求的输出，当进入另一个请求时作为该请求的输入，通常用于重定向场景，后边会细述 流程 用户发请求—&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制。 DispatcherServlet—&gt;HandlerMapping，HandlerMapping将会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器,多个HandlerInterceptor拦截器)。 DispatcherServlet—&gt;HandlerAdapter,HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器。 HandlerAdapter—&gt;处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理，并返回一个ModelAndView对象(包含模型数据，逻辑视图名) ModelAndView的逻辑视图名—&gt;ViewResolver，ViewResoler将把逻辑视图名解析为具体的View。 View—&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构 返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户。","tags":[{"name":"DispatcherServlet","slug":"DispatcherServlet","permalink":"http://langonggong.com/tags/DispatcherServlet/"},{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://langonggong.com/tags/SpringMvc/"}]},{"title":"tomcat","date":"2018-10-13T07:11:17.000Z","path":"2018/10/13/tomcat/","text":"tomcat架构Tomcat系统架构 Tomcat系统架构 Tomcat系统架构 ConnectorConnector 分析 Tomcat中的设计模式设计模式 责任链模式","tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://langonggong.com/tags/tomcat/"}]},{"title":"代理","date":"2018-10-09T15:45:25.000Z","path":"2018/10/09/代理/","text":"正向代理正向代理（Forward Proxy）方式下，使用者需要配置网络访问的代理服务器为Cache设备的地址，内网对互联网的所有访问都是通过代理服务器完成 正向代理多用于与小企业网络环境，Cache设备作为企业网的出口网关提供代理服务（例如翻墙访问谷歌）、内容缓存、Internet访问控制、安全认证等功能 反向代理透明代理","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://langonggong.com/tags/计算机网络/"}]},{"title":"CND加速","date":"2018-10-05T14:01:53.000Z","path":"2018/10/05/CND加速/","text":"网页加速CDN服务商通过将网页内容缓存到各个CND节点上，并将用户请求调度到最优节点上来获取所需的内容，从而加速页面相应速度、减轻源站点的访问负担 流媒体加速将流媒体内容推送到离用户最近的POP点，使得用户能够从网络边缘获取内容，从而提高视频传输质量，缩短访问时间，节省骨干网络流量，避免单一中心的服务器瓶颈问题 文件传输加速使用CND分布式POP点提供下载服务，网站可以将大量文件下载的性能压力和带宽压力交给CND来分担，提高用户的下载速度 应用协议加速不针对特定内容类型进行加速，而是通过对TCP/IP等传输协议优化，或对SSL协议加速 广域网应用加速目的是“让广域网像局域网一样” 将分布式的IT基础设施如文件服务器、邮件服务器、网络附加存储（NAS）和远程办公室备份系统集中起来，整合到统一的数据中心 SSL应用加速由CDN的专用SSL加速硬件来完成加密解密运算工作，通过认证之后方可建立起数据传输通道。用户的源站点只需信任有限的CDN cache，而无需面对海量用户，从而减轻了繁重的运算和认证压力 网页压缩可以在服务器端对网页数据进行压缩，将压缩后的文件提供给用户，在浏览器端解压显示。CDN为网站提供网页内容的压缩传输，从而加快内容传输速度","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://langonggong.com/tags/计算机网络/"},{"name":"CDN","slug":"CDN","permalink":"http://langonggong.com/tags/CDN/"}]},{"title":"负载均衡","date":"2018-10-05T13:52:21.000Z","path":"2018/10/05/负载均衡/","text":"全局负载均衡（GSLB）DNS解析本地负载均衡（SLB）4层调度7层调度链路负载调度","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://langonggong.com/tags/计算机网络/"}]},{"title":"CDN","date":"2018-10-05T13:49:15.000Z","path":"2018/10/05/CDN/","text":"","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://langonggong.com/tags/计算机网络/"},{"name":"CDN","slug":"CDN","permalink":"http://langonggong.com/tags/CDN/"}]},{"title":"uml","date":"2018-10-03T02:43:16.000Z","path":"2018/10/03/uml/","text":"类图","tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://langonggong.com/tags/软件工程/"},{"name":"uml","slug":"uml","permalink":"http://langonggong.com/tags/uml/"}]},{"title":"linux IO模型","date":"2018-09-27T11:49:04.000Z","path":"2018/09/27/IO模型/","text":"简介在linux系统下面，根据IO操作的是否被阻塞以及同步异步问题进行分类，可以得到下面五种IO模型 阻塞I/O（blocking I/O） 非阻塞I/O （nonblocking I/O） I/O复用(select 和poll) （I/O multiplexing） 信号驱动I/O （signal driven I/O (SIGIO)） 异步I/O （asynchronous I/O (the POSIX aio_functions)） 对于一个network IO (以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中(Copying the data from the kernel to the process) 这些IO模型的区别就是在两个阶段上各有不同的情况 阻塞IO（blocking IO） 调用blocking IO会一直block住对应的进程直到操作完成 非阻塞IO（non-blocking IO） 在kernel还在准备数据的情况下会立刻返回。在执行recvfrom这个系统调用的时候，如果kernel的数据没有准备好，这时候不会block进程。但是当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内进程是被block的 同步IO（synchronous IO） 做IO 操作的时候会将进程阻塞。按照这个定义，blocking IO，non-blocking IO，IO multiplexing都属于同步IO 异步IO（asynchronous IO） 当进程发起IO操作之后，就直接返回，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block 详解阻塞IO（blocking IO） 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。 可能同时出现的上千甚至上万次的客户端请求，“线程池”或“连接池”或许可以缓解部分压力，但是不能解决所有问题。总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞接口来尝试解决这个问题 非阻塞IO（non-blocking IO）Linux下，可以通过设置socket使其变为non-blocking 从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有。 循环调用recv()将大幅度推高CPU 占用率；此外，在这个方案中recv()更多的是起到检测“操作是否完成”的作用，实际操作系统提供了更为高效的检测“操作是否完成“作用的接口，例如select()多路复用模式，可以一次检测多个连接是否活跃 多路复用IO（IO multiplexing）有些地方也称这种IO方式为事件驱动IO(event driven IO)。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection 在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。因此select()与非阻塞IO类似 select()接口并不是实现“事件驱动”的最好选择。因为当需要探测的句柄值较大时，select()接口本身需要消耗大量时间去轮询各个句柄 信号驱动I/O（signal driven I/O） 两次调用，两次返回允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据 异步I/O （asynchronous I/O） 用户进程发起read操作之后，立刻就可以开始去做其它的事。从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了 对比非阻塞IO ，IO请求时加上O_NONBLOCK一类的标志位，立刻返回，IO没有就绪会返回错误，需要请求进程主动轮询不断发IO请求直到返回正确。 IO复用同非阻塞IO本质一样，不过利用了新的select系统调用，由内核来负责本来是请求进程该做的轮询操作。看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才算提高了效率。 信号驱动IO，调用sigaltion系统调用，当内核中IO数据就绪时以SIGIO信号通知请求进程，请求进程再把数据从内核读入到用户空间，这一步是阻塞的。 异步IO，如定义所说，不会因为IO操作阻塞，IO操作全部完成才通知请求进程 左边四种方式，第一阶段不同，第二阶段相同（调用recvFrom发生阻塞） 参考链接 socket阻塞与非阻塞，同步与异步、I/O模型网络IO模型","tags":[{"name":"linux","slug":"linux","permalink":"http://langonggong.com/tags/linux/"},{"name":"IO","slug":"IO","permalink":"http://langonggong.com/tags/IO/"}]},{"title":"BlockingQueue","date":"2018-09-25T07:53:14.000Z","path":"2018/09/25/BlockingQueue/","text":"阻塞队列与我们平常接触的普通队列(LinkedList或ArrayList等)的最大不同点，在于阻塞队列支持阻塞添加和阻塞删除方法 Java中的阻塞队列接口BlockingQueue继承自Queue接口123456789101112131415161718192021222324public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; //将指定的元素插入到此队列的尾部（如果立即可行且不会超过该队列的容量） //在成功时返回 true，如果此队列已满，则抛IllegalStateException。 boolean add(E e); //将指定的元素插入到此队列的尾部（如果立即可行且不会超过该队列的容量） // 将指定的元素插入此队列的尾部，如果该队列已满， //则在到达指定的等待时间之前等待可用的空间,该方法可中断 boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; //将指定的元素插入此队列的尾部，如果该队列已满，则一直等到（阻塞）。 void put(E e) throws InterruptedException; //获取并移除此队列的头部，如果没有元素则等待（阻塞）， //直到有元素将唤醒等待线程执行该操作 E take() throws InterruptedException; //获取并移除此队列的头部，在指定的等待时间前一直等到获取元素， //超过时间方法将结束 E poll(long timeout, TimeUnit unit) throws InterruptedException; //从此队列中移除指定元素的单个实例（如果存在）。 boolean remove(Object o); &#125; 插入方法：add(E e) : 添加成功返回true，失败抛IllegalStateException异常offer(E e) : 成功返回 true，如果此队列已满，则返回 false。put(E e) :将元素插入此队列的尾部，如果该队列已满，则一直阻塞 删除方法:remove(Object o) :移除指定元素,成功返回true，失败返回falsepoll() : 获取并移除此队列的头元素，若队列为空，则返回 nulltake()：获取并移除此队列头元素，若没有元素则一直阻塞。 检查方法element() ：获取但不移除此队列的头元素，没有元素则抛异常peek() :获取但不移除此队列的头；若队列为空，则返回 null。 ArrayBlockingQueue原理ArrayBlockingQueue的内部是通过一个可重入锁ReentrantLock和两个Condition条件对象来实现阻塞123456789101112131415161718192021222324252627282930public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; /** 存储数据的数组 */ final Object[] items; /**获取数据的索引，主要用于take，poll，peek，remove方法 */ int takeIndex; /**添加数据的索引，主要用于 put, offer, or add 方法*/ int putIndex; /** 队列元素的个数 */ int count; /** 控制并非访问的锁 */ final ReentrantLock lock; /**notEmpty条件对象，用于通知take方法队列已有元素，可执行获取操作 */ private final Condition notEmpty; /**notFull条件对象，用于通知put方法队列未满，可执行添加操作 */ private final Condition notFull; /** 迭代器 */ transient Itrs itrs = null;&#125; put方法put方法，它是一个阻塞添加的方法123456789101112131415//put方法，阻塞时可中断 public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly();//该方法可中断 try &#123; //当队列元素个数与数组长度相等时，无法添加元素 while (count == items.length) //将当前调用线程挂起，添加到notFull条件队列中等待唤醒 notFull.await(); enqueue(e);//如果队列没有满直接添加。。 &#125; finally &#123; lock.unlock(); &#125; &#125; take方法take()方法，是一个阻塞方法，直接获取队列头元素并删除1234567891011121314//从队列头部删除，队列没有元素就阻塞，可中断 public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly();//中断 try &#123; //如果队列没有元素 while (count == 0) //执行阻塞操作 notEmpty.await(); return dequeue();//如果队列有元素执行删除操作 &#125; finally &#123; lock.unlock(); &#125; &#125; LinkedBlockingQueueLinkedBlockingQueue是一个由链表实现的有界队列阻塞队列，但大小默认值为Integer.MAX_VALUE，所以在使用LinkedBlockingQueue时建议手动传值，为其提供我们所需的大小，避免队列过大造成机器负载或者内存爆满等情况 在正常情况下，链接队列的吞吐量要高于基于数组的队列（ArrayBlockingQueue），因为其内部实现添加和删除操作使用的两个ReenterLock来控制并发执行，而ArrayBlockingQueue内部只是使用一个ReenterLock控制并发，因此LinkedBlockingQueue的吞吐量要高于ArrayBlockingQueue12345678910111213141516171819202122232425262728293031323334353637383940414243public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; /** * 节点类，用于存储数据 */ static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125; &#125; /** 阻塞队列的大小，默认为Integer.MAX_VALUE */ private final int capacity; /** 当前阻塞队列中的元素个数 */ private final AtomicInteger count = new AtomicInteger(); /** * 阻塞队列的头结点 */ transient Node&lt;E&gt; head; /** * 阻塞队列的尾节点 */ private transient Node&lt;E&gt; last; /** 获取并移除元素时使用的锁，如take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** notEmpty条件对象，当队列没有数据时用于挂起执行删除的线程 */ private final Condition notEmpty = takeLock.newCondition(); /** 添加元素时使用的锁如 put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** notFull条件对象，当队列数据已满时用于挂起执行添加的线程 */ private final Condition notFull = putLock.newCondition();&#125; take方法 如果队列没有数据就挂起当前线程到 notEmpty条件对象的等待队列中一直等待，如果有数据就删除节点并返回数据项，同时唤醒后续消费线程(如果不为空) 尝试唤醒条件对象notFull上等待队列中的添加线程 123456789101112131415161718192021public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; notEmpty.await(); &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125; 123456789private void signalNotFull() &#123; final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125;&#125; put方法 如果队列已满就挂起当前线程到notFull条件对象的等待队列中一直等待，如果有空余节点就添加当前节点，同时唤醒后续生产线程(如果队列未满) 尝试唤醒条件对象notEmpty上等待队列中的添加线程 123456789101112131415161718192021public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; notFull.await(); &#125; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty();&#125; 123456789private void signalNotEmpty() &#123; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125;&#125; 区别 队列大小有所不同，ArrayBlockingQueue是有界的初始化必须指定大小，而LinkedBlockingQueue可以是有界的也可以是无界的(Integer.MAX_VALUE)，对于后者而言，当添加速度大于移除速度时，在无界的情况下，可能会造成内存溢出等问题。 数据存储容器不同，ArrayBlockingQueue采用的是数组作为数据存储容器，而LinkedBlockingQueue采用的则是以Node节点作为连接对象的链表。 由于ArrayBlockingQueue采用的是数组的存储容器，因此在插入或删除元素时不会产生或销毁任何额外的对象实例，而LinkedBlockingQueue则会生成一个额外的Node对象。这可能在长时间内需要高效并发地处理大批量数据的时，对于GC可能存在较大影响。 两者的实现队列添加或移除的锁不一样，ArrayBlockingQueue实现的队列中的锁是没有分离的，即添加操作和移除操作采用的同一个ReenterLock锁，而LinkedBlockingQueue实现的队列中的锁是分离的，其添加采用的是putLock，移除采用的则是takeLock，这样能大大提高队列的吞吐量，也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"synchronized","date":"2018-09-23T07:59:04.000Z","path":"2018/09/23/synchronized/","text":"对象的内存布局 对象头标记字（32位虚拟机4B，64位虚拟机8B） + 类型指针（32位虚拟机4B，64位虚拟机8B）+ [数组长（对于数组对象才需要此部分信息）]。用于存储对象的元数据信息 Mark Word：数据的长度在32位和64位虚拟机（未开启压缩指针）中分别为32bit和64bit，存储对象自身的运行时数据如哈希值等。Mark Word一般被设计为非固定的数据结构，以便存储更多的数据信息和复用自己的存储空间。 类型指针：指向它的类元数据的指针，用于判断对象属于哪个类的实例 实例数据存储的是真正有效数据，如各种字段内容，各字段的分配策略为longs/doubles、ints、shorts/chars、bytes/boolean、oops(ordinary object pointers)，相同宽度的字段总是被分配到一起，便于之后取数据。父类定义的变量会出现在子类定义的变量的前面 对齐填充对于64位虚拟机来说，对象大小必须是8B的整数倍，不够的话需要占位填充。仅仅起到占位符的作用，并非必须 Java对象头对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，Mark Word会随着程序的运行发生变化，变化状态如下（32位虚拟机） 锁状态 25 bit 4 bit 1 bit 2 bit 23 bit 2 bit 是否是偏向锁 锁标志位 无锁状态 对象HashCode 对象分代年龄 0 01 轻量级锁 指向栈中锁记录的指针 00 偏向锁 线程ID Epoch 对象分代年龄 1 01 重量级锁 指向互斥量（重量级锁）的指针 10 GC标记 空 11 monitor重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; //指向持有ObjectMonitor对象的线程 _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示 底层原理1234567891011public class SyncCodeBlock &#123; public int i; public void syncTask() &#123; //同步代码库 synchronized (this) &#123; i++; &#125; &#125;&#125; 编译上述代码并使用javap反编译后得到字节码如下 从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置，当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令 方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放 12345678public class SyncMethod &#123; public int i; public synchronized void syncTask() &#123; i++; &#125;&#125; 使用javap反编译后的字节码如下 锁的类型锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率1无锁 --&gt; 偏向锁 --&gt; 轻量级 --&gt; 重量级 偏向锁引入背景：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁，减少不必要的CAS操作。 加锁：当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程（此时会引发竞争，偏向锁会升级为轻量级锁）。 膨胀过程：当前线程执行CAS获取偏向锁失败（这一步是偏向锁的关键），表示在该锁对象上存在竞争并且这个时候另外一个线程获得偏向锁所有权。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，并从偏向锁所有者的私有Monitor Record列表中获取一个空闲的记录，并将Object设置LightWeight Lock状态并且Mark Word中的LockRecord指向刚才持有偏向锁线程的Monitor record，最后被阻塞在安全点的线程被释放，进入到轻量级锁的执行路径中，同时被撤销偏向锁的线程继续往下执行同步代码。 轻量级锁引入背景：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态（即单线程执行环境），在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒 加锁：（1）当对象处于无锁状态时（RecordWord值为HashCode，状态位为001），线程首先从自己的可用moniter record列表中取得一个空闲的moniter record，初始Nest和Owner值分别被预先设置为1和该线程自己的标识，一旦monitor record准备好然后我们通过CAS原子指令安装该monitor record的起始地址到对象头的LockWord字段，如果存在其他线程竞争锁的情况而调用CAS失败，则只需要简单的回到monitorenter重新开始获取锁的过程即可。 （2）对象已经被膨胀同时Owner中保存的线程标识为获取锁的线程自己，这就是重入（reentrant）锁的情况，只需要简单的将Nest加1即可。不需要任何原子操作，效率非常高。 （3）对象已膨胀但Owner的值为NULL，当一个锁上存在阻塞或等待的线程同时锁的前一个拥有者刚释放锁时会出现这种状态，此时多个线程通过CAS原子指令在多线程竞争状态下试图将Owner设置为自己的标识来获得锁，竞争失败的线程在则会进入到第四种情况（4）的执行路径。 （4）对象处于膨胀状态同时Owner不为NULL(被锁住)，在调用操作系统的重量级的互斥锁之前先自旋一定的次数，当达到一定的次数时如果仍然没有成功获得锁，则开始准备进入阻塞状态，首先将rfThis的值原子性的加1，由于在加1的过程中可能会被其他线程破坏Object和monitor record之间的关联，所以在原子性加1后需要再进行一次比较以确保LockWord的值没有被改变，当发现被改变后则要重新monitorenter过程。同时再一次观察Owner是否为NULL，如果是则调用CAS参与竞争锁，锁竞争失败则进入到阻塞状态。 不同锁的比较 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法仅存在纳秒级差别 如果线程间存在竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步块的场景 轻量级锁 竞争的线程不会阻塞，提高响应速度 始终得不到锁的竞争线程自旋消耗CPU 追求响应时间，同步代码块执行较快 重量级锁 线程竞争不使用自旋，不消耗CPU 线程阻塞，响应时间慢 追求吞吐量，同步块执行比较慢 参考链接 深入理解Java并发之synchronized实现原理Java中synchronized的实现原理与应用","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"condition","date":"2018-09-22T01:14:04.000Z","path":"2018/09/22/condition/","text":"引言在java中，对于任意一个java对象，它都拥有一组定义在java.lang.Object上监视器方法，包括wait()，wait(long timeout)，notify()，notifyAll()，这些方法配合synchronized关键字一起使用可以实现等待/通知模式。 同样，Condition接口也提供了类似Object监视器的方法，通过与Lock配合来实现等待/通知模式 对比项 Object监视器 Condition 前置条件 获取对象的锁 调用Lock.lock获取锁，调用Lock.newCondition获取Condition对象 调用方式 直接调用，比如object.notify() 直接调用，比如condition.await() 等待队列的个数 一个 多个 当前线程释放锁进入等待状态 支持 支持 当前线程释放锁进入等待状态，在等待状态中不断响中断 不支持 支持 当前线程释放锁并进入超时等待状态 支持 支持 当前线程释放锁并进入等待状态直到将来的某个时间 不支持 支持 唤醒等待队列中的一个线程 支持 支持 唤醒等待队列中的全部线程 支持 支持 示例实现一个简单的有界队列，队列为空时，队列的删除操作将会阻塞直到队列中有新的元素，队列已满时，队列的插入操作将会阻塞直到队列出现空位 主要方法1234567891011121314151617181920212223242526272829303132public interface Condition &#123; /** * 使当前线程进入等待状态直到被通知(signal)或中断 * 当其他线程调用singal()或singalAll()方法时，该线程将被唤醒 * 当其他线程调用interrupt()方法中断当前线程 * await()相当于synchronized等待唤醒机制中的wait()方法 */ void await() throws InterruptedException; //当前线程进入等待状态，直到被唤醒，该方法不响应中断要求 void awaitUninterruptibly(); //调用该方法，当前线程进入等待状态，直到被唤醒或被中断或超时 //其中nanosTimeout指的等待超时时间，单位纳秒 long awaitNanos(long nanosTimeout) throws InterruptedException; //同awaitNanos，但可以指明时间单位 boolean await(long time, TimeUnit unit) throws InterruptedException; //调用该方法当前线程进入等待状态，直到被唤醒、中断或到达某个时 //间期限(deadline),如果没到指定时间就被唤醒，返回true，其他情况返回false boolean awaitUntil(Date deadline) throws InterruptedException; //唤醒一个等待在Condition上的线程，该线程从等待方法返回前必须 //获取与Condition相关联的锁，功能与notify()相同 void signal(); //唤醒所有等待在Condition上的线程，该线程从等待方法返回前必须 //获取与Condition相关联的锁，功能与notifyAll()相同 void signalAll();&#125; 实现原理Condition的具体实现类是AQS的内部类ConditionObject。AQS中存在两种队列，一种是同步队列，一种是等待队列，而等待队列就相对于Condition而言的。注意在使用Condition前必须获得锁，同时在Condition的等待队列上的结点与前面同步队列的结点是同一个类即Node，其结点的waitStatus的值为CONDITION。在实现类ConditionObject中有两个结点分别是firstWaiter和lastWaiter，firstWaiter代表等待队列第一个等待结点，lastWaiter代表等待队列最后一个等待结点，如下 1234567public class ConditionObject implements Condition, java.io.Serializable &#123; //等待队列第一个等待结点 private transient Node firstWaiter; //等待队列最后一个等待结点 private transient Node lastWaiter; //省略其他代码.......&#125; 每个Condition都对应着一个等待队列，也就是说如果一个锁上创建了多个Condition对象，那么也就存在多个等待队列。等待队列是一个FIFO的队列，在队列中每一个节点都包含了一个线程的引用，而该线程就是Condition对象上等待的线程。当一个线程调用了await()相关的方法，那么该线程将会释放锁，并构建一个Node节点封装当前线程的相关信息加入到等待队列中进行等待，直到被唤醒、中断、超时才从队列中移出 await()实现123456789101112131415161718192021222324252627public final void await() throws InterruptedException &#123; //判断线程是否被中断 if (Thread.interrupted()) throw new InterruptedException(); //创建新结点加入等待队列并返回 Node node = addConditionWaiter(); //释放当前线程锁即释放同步状态 int savedState = fullyRelease(node); int interruptMode = 0; //判断结点是否同步队列(SyncQueue)中,即是否被唤醒 while (!isOnSyncQueue(node)) &#123; //挂起线程 LockSupport.park(this); //判断是否被中断唤醒，如果是退出循环。 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; //被唤醒后执行自旋操作争取获得锁，同时判断线程是否被中断 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // clean up if cancelled if (node.nextWaiter != null) //清理等待队列中不为CONDITION状态的结点 unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 12345678910111213141516171819//添加到等待队列private Node addConditionWaiter() &#123; Node t = lastWaiter; // 判断是否为结束状态的结点并移除 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; //创建新结点状态为CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); //加入等待队列 if (t == null) &#123; firstWaiter = node; &#125; else &#123; t.nextWaiter = node; &#125; lastWaiter = node; return node;&#125; 调用addConditionWaiter()方法将当前线程封装成node结点加入等待队列 调用fullyRelease(node)方法释放同步状态并唤醒同步队列后继结点的线程 调用isOnSyncQueue(node)方法判断结点是否在同步队列中，注意是个while循环，如果同步队列中没有该结点就直接挂起该线程，如果线程被唤醒后就调用acquireQueued(node, savedState)执行自旋操作争取锁，即当前线程结点从等待队列转移到同步队列并开始努力获取锁 signal()实现1234567891011public final void signal() &#123; //判断是否持有独占锁，如果不是抛出异常 //只有独占模式采用等待队列，而共享模式下是没有等待队列的，也就没法使用Condition if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; //唤醒等待队列第一个结点的线程 if (first != null) &#123; doSignal(first); &#125;&#125; 1234567891011private void doSignal(Node first) &#123; do &#123; //移除条件等待队列中的第一个结点 //然后重新维护条件等待队列的firstWaiter和lastWaiter的指向 if ((firstWaiter = first.nextWaiter) == null) &#123; lastWaiter = null; &#125; first.nextWaiter = null; //如果被通知节点没有进入到同步队列并且条件等待队列还有不为空的节点，则继续循环通知后续结点 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125; 1234567891011121314151617181920final boolean transferForSignal(Node node) &#123; //尝试设置唤醒结点的waitStatus为0，即初始化状态 //如果设置失败，说明当前结点node的waitStatus已不为 //CONDITION状态，那么只能是结束状态了，因此返回false //返回doSignal()方法中继续唤醒其他结点的线程，注意这里并 //不涉及并发问题，所以CAS操作失败只可能是预期值不为CONDITION， //而不是多线程设置导致预期值变化，毕竟操作该方法的线程是持有锁的。 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //加入同步队列并返回前驱结点p Node p = enq(node); int ws = p.waitStatus; //判断前驱结点是否为结束结点(CANCELLED=1)或者在设置 //前驱节点状态为Node.SIGNAL状态失败时，唤醒被通知节点代表的线程 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) //唤醒node结点的线程 LockSupport.unpark(node.thread); return true;&#125; 被唤醒后的线程，将从前面的await()方法中的while循环中退出，因为此时该线程的结点已在同步队列中，那么while (!isOnSyncQueue(node))将不在符合循环条件，进而调用AQS的acquireQueued()方法加入获取同步状态的竞争中，这就是等待唤醒机制的整个流程实现原理 参考链接 深入剖析基于并发AQS的(独占锁)重入锁(ReetrantLock)及其Condition实现原理java并发编程之Condition","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"滑动窗口算法","date":"2018-09-19T14:56:15.000Z","path":"2018/09/19/滑动窗口算法/","text":"题目描述 有一个整型数组 arr 和一个大小为 w 的窗口从数组的最左边滑到最右边,窗口每次向右边滑一个位置。 返回一个长度为n-w+1的数组res，res[i]表示每一种窗口状态下的最大值。 以数组为[4,3,5,4,3,3,6,7]，w=3为例。因为第一个窗口[4,3,5]的最大值为5，第二个窗口[3,5,4]的最大值为5，第三个窗口[5,4,3]的最大值为5。第四个窗口[4,3,3]的最大值为4。第五个窗口[3,3,6]的最大值为6。第六个窗口[3,6,7]的最大值为7。所以最终返回[5,5,5,4,6,7]。 给定整形数组arr及它的大小n，同时给定w，请返回res数组。保证w小于等于n，同时保证数组大小小于等于500。 解题思路 使用一个长度为w的双端队列，存储数组的索引。每次有新元素加入，将小于或等于改元素的值的原有元素对应的索引删掉，将不在该窗口范围的索引删掉。队列的索引对应的元素值倒序排序。则队列的第一个元素始终为该窗口内最大值的索引 参考代码12345678910111213141516171819202122232425public class SlideWindow &#123; public int[] slide(int[] arr, int n, int w) &#123; if (arr == null || arr.length == 0 || arr.length &lt; w) &#123; return new int[0]; &#125; LinkedList&lt;Integer&gt; list = new LinkedList&lt;&gt;(); int[] result = new int[arr.length - w + 1]; int index = 0; for (int i = 0; i &lt; arr.length; i++) &#123; //把较小的值挤掉，按照从大到小排序 while (!list.isEmpty() &amp;&amp; arr[list.peekLast()] &lt;= arr[i]) &#123; list.pollLast(); &#125; list.addLast(i); //不在窗口里面的元素删掉 if (i - list.peekFirst() == w) &#123; list.pollFirst(); &#125; if (i + 1 &gt;= w) &#123; result[index++] = arr[list.peekFirst()]; &#125; &#125; return result; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"队列","slug":"队列","permalink":"http://langonggong.com/tags/队列/"}]},{"title":"小范围排序","date":"2018-09-06T17:04:14.000Z","path":"2018/09/07/小范围排序/","text":"题目描述 已知一个几乎有序的数组，几乎有序是指，如果把数组排好顺序的话，每个元素移动的距离可以不超过k，并且k相对于数组来说比较小。请选择一个合适的排序算法针对这个数据进行排序 解题思路 使用变种的堆排序：维护一个长度为k的最小根堆，将数组的元素不断的加入堆中，调整后将堆顶弹出赋给数组，将排序的范围始终限制在长度为k、近乎排序的堆中 参考代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class ScaleSort &#123; public int[] sortElement(int[] arr, int k) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; //构建长度为k的小根堆，此过程也可以在heap数组中进行 for (int i = k / 2; i &gt;= 0; i--) &#123; headAdjust(arr, i, k); &#125; //将调整好的最小根堆赋值给heap数组 int[] heap = new int[k]; for (int i = 0; i &lt; k; i++) &#123; heap[i] = arr[i]; &#125; //每从最小跟堆中弹出堆顶给数组，就从数组中弹出一个元素给堆，再次调整为最小跟堆 for (int i = k; i &lt; arr.length; i++) &#123; arr[i - k] = heap[0]; heap[0] = arr[i]; headAdjust(heap, 0, k); &#125; //最小根堆不能保证左右节点之间的大小顺序，所以不能直接将heap完整复制给arr for (int i = arr.length - k; i &lt; arr.length; i++) &#123; arr[i] = heap[0]; //由于堆中没有新的元素加入，只能每次将堆顶放到后面，对前面一部分进行堆调整 swap(heap, 0, arr.length - i - 1); headAdjust(heap, 0, arr.length - i - 1); &#125; return arr; &#125; //堆调整，保证[index,length)这条支线满足最小根堆 private void headAdjust(int[] arr, int index, int length) &#123; int minIndex, left, right; while (index &lt; length) &#123; minIndex = index; left = 2 * index + 1; right = 2 * index + 2; if (left &lt; length &amp;&amp; arr[left] &lt; arr[minIndex]) &#123; minIndex = left; &#125; if (right &lt; length &amp;&amp; arr[right] &lt; arr[minIndex]) &#123; minIndex = right; &#125; //临界条件，表示无需再调整 if (index == minIndex) &#123; break; &#125; swap(arr, index, minIndex); index = minIndex; &#125; &#125; public static void swap(int[] arr, int index1, int index2) &#123; if (index1 == index2) &#123; return; &#125; int tmp = arr[index1]; arr[index1] = arr[index2]; arr[index2] = tmp; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"DNS解析","date":"2018-09-06T08:46:42.000Z","path":"2018/09/06/DNS解析/","text":"nslookup 第一行Server是：DNS服务器的主机名—10.4.1.14第二行Address是：它的IP地址—10.4.1.14#53 百度有一个cname = www.a.shifen.com的别名 下面的Name是：解析的URL—www.a.shifen.comAddress是：解析出来的IP—220.181.112.244和220.181.111.188 dig www.baidu.com +trace Dig工具会在本地计算机做迭代，然后记录查询的过程 第一步，向我这台机器的ISPDNS获取到根域服务区的13个IP和主机名[b-j].root-servers.net. 第二步，向其中的一台根域服务器（m.root-servers.net）发送www.baidu.com的查询请求，他返回了com.顶级域的服务器名称 第三步，向com.域的一台服务器i.gtld-servers.net请求,www.baidu.com，他返回了baidu.com域的服务器IP（未显示）和名称，百度有5台顶级域的服务器 第四步，向百度的顶级域服务器（202.108.22.220）请求www.baidu.com，他发现这个www有个别名，而不是一台主机，别名是www.a.shifen.com 当dns请求到别名的时候，查询不会终止，而是重新发起查询别名的请求，此处返回的是www.a.shifen.com，然后继续请求 使用dig www.a.shifen.com +trace查看 再一次去请求com域，重复上面的步骤，最终从ns X.a.shifen.com中一台拿到了一条A记录，便是www.baidu.com的IP地址了","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://langonggong.com/tags/计算机网络/"},{"name":"DNS","slug":"DNS","permalink":"http://langonggong.com/tags/DNS/"}]},{"title":"基数排序","date":"2018-09-05T15:41:05.000Z","path":"2018/09/05/基数排序/","text":"1、构造从0到9的10个桶，将数组的每个元素按照个位数的大小放入对应的桶中2、构造新的10个桶，将原桶中的数字依次弹出，按照十位数的大小依次放入对应的新桶中3、对百位、千位等按照上述步骤处理 需考虑负数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class RadixSort &#123; public int[] radixSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; int posNum = 0; for (int i : arr) &#123; if (i &gt;= 0) &#123; posNum++; &#125; &#125; int[] posArr = new int[posNum]; int[] negArr = new int[arr.length - posNum]; int posIndex = 0, negIndex = 0, posMax = 0, negMax = 0; for (int i : arr) &#123; if (i &gt;= 0) &#123; posArr[posIndex++] = i; posMax = Math.max(posMax, i); &#125; else &#123; int j = -i; negArr[negIndex++] = j; negMax = Math.max(j, negMax); &#125; &#125; radixSortForPositive(posArr, posMax); radixSortForPositive(negArr, negMax); int index = 0; for(int i=negArr.length-1;i&gt;=0;i--) &#123; arr[index++] = -negArr[i]; &#125; for(int i=0;i&lt;posArr.length;i++) &#123; arr[index++] = posArr[i]; &#125; return arr; &#125; //针对正数的基数排序 private static void radixSortForPositive(int[] arr, int max) &#123; List&lt;LinkedList&lt;Integer&gt;&gt; temp1 = new ArrayList&lt;&gt;(); List&lt;LinkedList&lt;Integer&gt;&gt; temp2 = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; temp1.add(new LinkedList&lt;&gt;()); temp2.add(new LinkedList&lt;&gt;()); &#125; //按照个位数的大小将元素放入桶中 for (int i : arr) &#123; temp1.get(i % 10).add(i); &#125; for (int base = 10; base &lt;= max; base *= 10) &#123; for (LinkedList&lt;Integer&gt; integers : temp1) &#123; while (!integers.isEmpty()) &#123; Integer integer = integers.pop(); temp2.get((integer / base) % 10).add(integer); &#125; &#125; List&lt;LinkedList&lt;Integer&gt;&gt; temp; temp = temp1; temp1 = temp2; temp2 = temp; &#125; int index = 0; for (LinkedList&lt;Integer&gt; integers : temp1) &#123; for (Integer integer : integers) &#123; arr[index++] = integer; &#125; &#125; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"计数排序","date":"2018-09-05T15:37:25.000Z","path":"2018/09/05/计数排序/","text":"根据数组最大最小值构建数组，记录每个数字出现次数 123456789101112131415161718192021222324public class CountingSort &#123; public int[] countingSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; int min = arr[0], max = arr[0]; for(int i=0;i&lt;arr.length;i++) &#123; min = Math.min(min, arr[i]); max = Math.max(max, arr[i]); &#125; int[] store = new int[max - min + 1]; for(int j=0;j&lt;arr.length;j++) &#123; store[arr[j] - min]++; &#125; int index = 0; for(int k=0;k&lt;store.length;k++) &#123; while (store[k]-- &gt; 0) &#123; arr[index++] = k + min; &#125; &#125; return arr; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"希尔排序","date":"2018-09-05T15:00:26.000Z","path":"2018/09/05/希尔排序/","text":"令k=21、将数组分成k等分，构建length/2个间隔为k的数组，对每个数组进行插入排序2、k=k*2,重复步骤1 插入排序:假设前面的数组已经有序，则找到改点合适的位置插入(该点下沉到合适的位置) 123456789101112131415161718192021222324252627282930public class ShellSort &#123; public int[] shellSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; int length = arr.length ; //将数组2等分，4等分...直到一等分 for (int gap = length &gt;&gt; 1; gap &gt; 0; gap &gt;&gt;= 1) &#123; //对生成的多个数组进行插入排序 for (int start = gap; start &lt; arr.length; start++) &#123; //对单个数组进行插入排序 for (int index = start; index &gt;= gap; index -= gap) &#123; if (arr[index - gap] &gt; arr[index]) &#123; swap(arr, index - gap, index); &#125; &#125; &#125; &#125; return arr; &#125; public static void swap(int[] arr, int index1, int index2) &#123; if (index1 == index2) &#123; return; &#125; int tmp = arr[index1]; arr[index1] = arr[index2]; arr[index2] = tmp; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"堆排序","date":"2018-09-04T16:28:14.000Z","path":"2018/09/05/堆排序/","text":"1、构建大根堆，满足父大于子，堆顶为最大值2、将堆顶与最后一位进行替换，将前n-1位调整为大根堆3、对前n-1位大根堆重复过程2 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class HeapSort &#123; public int[] heapSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; //构建大根堆，使整棵树满足:父&gt;子 for (int i = arr.length / 2; i &gt;= 0; i--) &#123; //每次调整，都要保证将后面所有的都调整一遍 headAdjust(arr, i, arr.length); &#125; //将堆顶（最大值）替换到第j个点，然后将前面j-1个点调整为大根堆， //对前j-1个点重复此过程 for(int j=arr.length-1;j&gt;=0;j--) &#123; swap(arr, 0, j); headAdjust(arr, 0, j); &#125; return arr; &#125; //不能保证[index,length)是大顶堆，只能尽量把大的点网上冒 private void headAdjust(int[] arr, int index,int length) &#123; //如果父节点与左右子节点进行交换，发生交换的子节点所在的堆可能不满足大顶堆，例如[2,10,null,4,5]-&gt;[10,2,null,4,5] //所以需要往底部继续遍历处理 while (index &lt; length) &#123; int left = 2 * index + 1; int right = 2 * index + 2; int max = index; if (left &lt; length &amp;&amp; arr[left] &gt; arr[index]) &#123; max = left; &#125; if (right &lt; length &amp;&amp; arr[right] &gt; arr[max]) &#123; max = right; &#125; if (index == max) &#123; break; &#125; swap(arr, index, max); index = max; &#125; &#125; public static void swap(int[] arr, int index1, int index2) &#123; if (index1 == index2) &#123; return; &#125; int tmp = arr[index1]; arr[index1] = arr[index2]; arr[index2] = tmp; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"快速排序","date":"2018-09-03T15:56:00.000Z","path":"2018/09/03/快速排序/","text":"选择任意一点，将元素划分为小于该值和大于该值的左右两部分，递归次过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class QuickSort &#123; public int[] quickSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; process(arr, 0, arr.length - 1); return arr; &#125; public static void process(int[] arr, int left, int right) &#123; if (left &gt;= right) &#123; return; &#125; int random = left + (int) Math.random() * (right - left + 1); swap(arr, random, right); int partition = partition(arr, left, right); process(arr, left, partition - 1); process(arr, partition + 1, right); &#125; /** * 将小于或等于right的元素替换到左边，大于right的元素保持不动 * partition加一递增，指向最近一个被替换到左边的位置 * 当数组遍历完，right处的元素被替换到partition所指的位置 * partition左边的值全部小于或等于该值，右边的值全部大于该值 **/ public static int partition(int[] arr, int left, int right) &#123; int partition = left - 1; int index = left; while (index &lt;= right) &#123; if (arr[index] &lt;= arr[right]) &#123; swap(arr, ++partition, index); &#125; index++; &#125; return partition; &#125; public static void swap(int[] arr, int index1, int index2) &#123; if (index1 == index2) &#123; return; &#125; int tmp = arr[index1]; arr[index1] = arr[index2]; arr[index2] = tmp; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"归并排序","date":"2018-09-03T13:24:32.000Z","path":"2018/09/03/归并排序/","text":"二分后递归调用自身，然后对这两部分处理后的结果进行排序时间复杂度：\\(O (nlog_2 n)\\) 12345678910111213141516171819202122232425262728293031323334353637383940public class MergeSort &#123; public int[] mergeSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; divide(arr, 0, arr.length - 1); return arr; &#125; private void divide(int[] arr, int left, int right) &#123; if (left &gt;= right) &#123; return; &#125; int mid = (left + right) / 2; divide(arr, left, mid); divide(arr, mid + 1, right); merge(arr, left, mid, right); &#125; private void merge(int[] arr, int left, int mid, int right) &#123; int[] result = new int[right - left + 1]; int i = left, j = mid + 1, index = 0; while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; if (arr[i] &lt; arr[j]) &#123; result[index++] = arr[i++]; &#125; else &#123; result[index++] = arr[j++]; &#125; &#125; while (i &lt;= mid) &#123; result[index++] = arr[i++]; &#125; while (j &lt;= right) &#123; result[index++] = arr[j++]; &#125; for(int k=0;k&lt;result.length;k++) &#123; arr[left + k] = result[k]; &#125; &#125;&#125; 时间复杂度推导 如果假设一个序列有n个数的排序时间为T(n)，T(n)是一个关于n的函数，随着n的变化而变化。那么我们将n个数的序列，分为两个(n/2)的序列，那么 T(n)=2*T(n/2)+合并时间由于合并时，两个子序列已经组内排好序了，那我们将两个排好序的序列组合成一个大的有序序列，只需要一个if循环即可。if循环中有n个数需要比较，所以时间复杂度为n。那么 T(n)=2*T(n/2)+n将T(n/2)带入到T(n)中，\\(T(n)=2*(2*T(n/4)+n/2)+n\\) ，通过化简得到 T(n)=4*T(n/4)+2n将T(n/4)带入到黄色公式中，\\(T(n)=4*(2*T(n/8)+n/4)+2n\\),通过化简得到 T(n)=8*T(n/8)+3n最终可得 T(n)=n*T(1)+(log_2n)*nT(1)=0，那么 T(n)=(log_2n)*n","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"插入排序","date":"2018-09-02T15:10:00.000Z","path":"2018/09/02/插入排序/","text":"假设前面的数组已经有序，则找到改点合适的位置插入(该点下沉到合适的位置) 1234567891011121314151617181920212223242526272829public class InsertionSort &#123; public int[] insertionSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; for (int i=1;i&lt;arr.length;i++) &#123; int j = i; while (j &gt; 0) &#123; if (arr[j - 1] &gt; arr[j]) &#123; swap(arr, j, j - 1); j--; &#125; else &#123; break; &#125; &#125; &#125; return arr; &#125; private void swap(int[] arr, int i, int j) &#123; if (i == j) &#123; return; &#125; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"选择排序","date":"2018-09-02T14:58:40.000Z","path":"2018/09/02/选择排序/","text":"选择最小值与第一个数字交换 1234567891011121314151617181920212223242526public class SelectSort &#123; public int[] selectionSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; for (int i = 0; i &lt; arr.length - 1; i++) &#123; int mini = i; for (int j = i + 1; j &lt; arr.length; j++) &#123; mini = arr[j] &lt; arr[mini] ? j : mini; &#125; swap(arr, i, mini); &#125; return arr; &#125; private void swap(int[] arr, int i, int j) &#123; if (i == j) &#123; return; &#125; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"冒泡排序","date":"2018-09-02T14:49:03.000Z","path":"2018/09/02/冒泡排序/","text":"最大值上浮 12345678910111213141516171819202122public class BubbleSort &#123; public int[] bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return arr; &#125; for (int i=arr.length-1;i&gt;0;i--) &#123; for (int j=0;j&lt;i;j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; swap(arr, j, j + 1); &#125; &#125; &#125; return arr; &#125; private void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://langonggong.com/tags/排序/"}]},{"title":"AQS","date":"2018-09-01T06:14:14.000Z","path":"2018/09/01/AQS/","text":"引言在JDK1.5之前，一般是靠synchronized关键字来实现线程对共享变量的互斥访问。synchronized是在字节码上加指令，依赖于底层操作系统的Mutex Lock实现。AQS定义了一套多线程访问共享资源的同步器框架，是整个java.util.concurrent包的基石，Lock、ReadWriteLock、CountDowndLatch、CyclicBarrier、Semaphore、ThreadPoolExecutor等都是在AQS的基础上实现的。 同步队列(CLH)AQS维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列） AQS的内部队列是CLH同步锁的一种变形。其主要从两方面进行了改造，节点的结构与节点等待机制 在结构上引入了头结点和尾节点，分别指向队列的头和尾，尝试获取锁、入队列、释放锁等实现都与头尾节点相关 为了可以处理timeout和cancel操作，每个node维护一个指向前驱的指针。如果一个node的前驱被cancel，这个node可以前向移动使用前驱的状态字段 在每个node里面使用一个状态字段来控制阻塞/唤醒，而不是自旋 head结点使用的是傀儡结点 12345678910111213public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer&#123;//指向同步队列队头private transient volatile Node head;//指向同步的队尾private transient volatile Node tail;//同步状态，在不同的子类有不同的含义private volatile int state;//省略其他代码......&#125; Node节点Node结点是对每一个访问同步代码的线程的封装，从图中的Node的数据结构也可看出，其包含了需要同步的线程本身以及线程的状态，如是否被阻塞，是否等待唤醒，是否已经被取消等。每个Node结点内部关联其前继结点prev和后继结点next，这样可以方便线程释放锁后快速唤醒下一个在等待的线程，Node是AQS的内部类，其数据结构如下 12345678910111213141516171819202122232425262728293031323334353637383940414243static final class Node &#123; //共享模式 static final Node SHARED = new Node(); //独占模式 static final Node EXCLUSIVE = null; //标识线程已处于结束状态 static final int CANCELLED = 1; //等待被唤醒状态 static final int SIGNAL = -1; //条件状态 static final int CONDITION = -2; //在共享模式中使用表示获得的同步状态会被传播 static final int PROPAGATE = -3; //等待状态,存在CANCELLED、SIGNAL、CONDITION、PROPAGATE 4种 volatile int waitStatus; //同步队列中前驱结点 volatile Node prev; //同步队列中后继结点 volatile Node next; //请求锁的线程 volatile Thread thread; //等待队列中的后继结点，这个与Condition有关 Node nextWaiter; //判断是否为共享模式 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; //获取前驱结点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; //.....&#125; 其中SHARED和EXCLUSIVE常量分别代表共享模式和独占模式，所谓共享模式是一个锁允许多条线程同时操作，如Semaphore、CountDownLatch采用的就是基于AQS的共享模式实现的，而独占模式则是同一个时间段只能有一个线程对共享资源进行操作，多余的请求线程需要排队等待，如ReentranLock。变量waitStatus则表示当前被封装成Node结点的等待状态，共有4种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE CANCELLED：值为1，在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的结点，其结点的waitStatus为CANCELLED，即结束状态，进入该状态后的结点将不会再变化。 SIGNAL：值为-1，被标识为该等待唤醒状态的后继结点，当其前继结点的线程释放了同步锁或被取消，将会通知该后继结点的线程执行。说白了，就是处于唤醒状态，只要前继结点释放锁，就会通知标识为SIGNAL状态的后继结点的线程执行。 CONDITION：值为-2，与Condition相关，该标识的结点处于等待队列中，结点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。 PROPAGATE：值为-3，与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。 0状态：值为0，代表初始化状态。 AQS lock()操作 Sync与State实现state机制volatile 变量 state; 用于同步线程之间的共享状态。通过 CAS 和 volatile 保证其原子性和可见性。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。 12345678// 同步状态 private volatile int state; //CAS protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; 不同实现类的Sync与State基于AQS构建的Synchronizer包括ReentrantLock,Semaphore,CountDownLatch, ReetrantRead WriteLock,FutureTask等，这些Synchronizer实际上最基本的东西就是原子状态的获取和释放，只是条件不一样而已 ReentrantLock需要记录当前线程获取原子状态的次数，如果次数为零，那么就说明这个线程放弃了锁（也有可能其他线程占据着锁从而需要等待），如果次数大于1，也就是获得了重进入的效果，而其他线程只能被park住，直到这个线程重进入锁次数变成0而释放原子状态。以下为ReetranLock的FairSync的tryAcquire实现代码解析 123456789101112131415161718192021222324//公平获取锁protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); //如果当前重进入数为0,说明有机会取得锁 if (c == 0) &#123; //如果是第一个等待者，并且设置重进入数成功，那么当前线程获得锁 if (isFirst(current) &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程本身就持有锁，那么叠加重进入数，并且继续获得锁 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; //以上条件都不满足，那么线程进入等待队列。 return false;&#125; 公平锁和非公平锁 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面 相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态 Semaphore信号量维护了一个许可集，我们在初始化Semaphore时需要为这个许可集传入一个数量值，该数量值代表同一时间能访问共享资源的线程数量。以下为Semaphore的FairSync实现 1234567891011121314151617protected int tryAcquireShared(int acquires) &#123; Thread current = Thread.currentThread(); for (;;) &#123; Thread first = getFirstQueuedThread(); //如果当前等待队列的第一个线程不是当前线程，那么就返回-1表示当前线程需要等待 if (first != null &amp;&amp; first != current) return -1; //如果当前队列没有等待者，或者当前线程就是等待队列第一个等待者， //那么先取得semaphore还有几个许可证，并且减去当前线程需要的许可证得到剩下的值 int available = getState(); int remaining = available - acquires; //如果remining&lt;0，那么反馈给AQS当前线程需要等待，如果remaining&gt;0，并且设置availble成功设置成剩余数， //那么返回剩余值(&gt;0)，也就告知AQS当前线程拿到许可，可以继续执行。 if (remaining &lt; 0 ||compareAndSetState(available, remaining)) return remaining; &#125;&#125; void acquire()：从此信号量获取一个许可前线程将一直阻塞 void acquire(int n)：从此信号量获取给定数目许可，在提供这些许可前一直将线程阻塞 void release()：释放一个许可，将其返回给信号量 void release(int n)：释放n个许可 使用场景：一般用于控制对某组资源的访问控制 CountDownLatch闭锁则要保持其状态，在这个状态到达终止态之前，所有线程都会被park住，闭锁可以设定初始值，这个值的含义就是这个闭锁需要被countDown()几次，因为每次CountDown是sync.releaseShared(1),而一开始初始值为10的话，那么这个闭锁需要被countDown()十次，才能够将这个初始值减到0，从而释放原子状态，让等待的所有线程通过 1234567891011121314151617181920//await时候执行，只查看当前需要countDown数量减为0了，如果为0，说明可以继续执行，//否则需要park住，等待countDown次数足够，并且unpark所有等待线程public int tryAcquireShared(int acquires) &#123; return getState() == 0? 1 : -1;&#125; //countDown 时候执行，如果当前countDown数量为0，说明没有线程await，//直接返回false而不需要唤醒park住线程，//如果不为0，得到剩下需要 countDown的数量并且compareAndSet,//最终返回剩下的countDown数量是否为0,供AQS判定是否释放所有await线程。public boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; void await()：调用await()方法的线程会被挂起，它会等待直到countDown值为0才继续执行 boolean await(long timeout, TimeUnit unit)：await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行 void countDown()：将countDown值减1 使用场景：多个子线程都结束后才运行主线程，并且子线程不会阻塞，例如多步计算后的汇总工作 FutureTask需要记录任务的执行状态，当调用其实例的get方法时,内部类Sync会去调用AQS的acquireSharedInterruptibly()方法，而这个方法会反向调用Sync实现的tryAcquireShared()方法，即让具体实现类决定是否让当前线程继续还是park,而FutureTask的tryAcquireShared方法所做的唯一事情就是检查状态，如果是RUNNING状态那么让当前线程park。而跑任务的线程会在任务结束时调用FutureTask 实例的set方法（与等待线程持相同的实例），设定执行结果，并且通过unpark唤醒正在等待的线程，返回结果 123456789101112131415161718192021222324252627282930313233343536373839404142//get时待用，只检查当前任务是否完成或者被Cancel，如果未完成并且没有被cancel，那么告诉AQS当前线程需要进入等待队列并且park住protected int tryAcquireShared(int ignore) &#123; return innerIsDone()? 1 : -1;&#125; //判定任务是否完成或者被Cancelboolean innerIsDone() &#123; return ranOrCancelled(getState()) &amp;&amp; runner == null;&#125; //get时调用，对于CANCEL与其他异常进行抛错V innerGet(long nanosTimeout) throws InterruptedException, ExecutionException, TimeoutException &#123; if (!tryAcquireSharedNanos(0,nanosTimeout)) throw new TimeoutException(); if (getState() == CANCELLED) throw new CancellationException(); if (exception != null) throw new ExecutionException(exception); return result;&#125; //任务的执行线程执行完毕调用（set(V v)）void innerSet(V v) &#123; for (;;) &#123; int s = getState(); //如果线程任务已经执行完毕，那么直接返回（多线程执行任务？） if (s == RAN) return; //如果被CANCEL了，那么释放等待线程，并且会抛错 if (s == CANCELLED) &#123; releaseShared(0); return; &#125; //如果成功设定任务状态为已完成，那么设定结果，unpark等待线程(调用get()方法而阻塞的线程),以及后续清理工作（一般由FutrueTask的子类实现） if (compareAndSetState(s, RAN)) &#123; result = v; releaseShared(0); done(); return; &#125; &#125;&#125; MutexMutex是一个不可重入的互斥锁实现。锁资源（AQS里的state）只有两种状态：0表示未锁定，1表示锁定。下边是Mutex的核心源码 123456789101112131415161718192021222324// 判断是否锁定状态protected boolean isHeldExclusively() &#123; return getState() == 1;&#125;// 尝试获取资源，立即返回。成功则返回true，否则false。public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // 这里限定只能为1个量 if (compareAndSetState(0, 1)) &#123;//state为0才设置为1，不可重入！ setExclusiveOwnerThread(Thread.currentThread());//设置为当前线程独占资源 return true; &#125; return false;&#125;// 尝试释放资源，立即返回。成功则为true，否则false。protected boolean tryRelease(int releases) &#123; assert releases == 1; // 限定为1个量 if (getState() == 0)//既然来释放，那肯定就是已占有状态了。只是为了保险，多层判断！ throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0);//释放资源，放弃占有状态 return true;&#125; 参考链接 深入剖析基于并发AQS的(独占锁)重入锁(ReetrantLock)及其Condition实现原理剖析基于并发AQS的共享锁的实现(基于信号量Semaphore)Java多线程（七）之同步器基础：AQS框架深入分析非阻塞算法简介","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"KMP","date":"2018-08-29T16:44:12.000Z","path":"2018/08/30/KMP/","text":"求next数组字符串组成为 p_0...p_k...p_i...p_{i+k}...p_j...p_{j+k}...p_m...p_{m+k}...假设\\(next_{[i+k]}==next_{[m+k]}\\)，表示\\(p_0…p_{i+k}=p_j…p_{m+k}\\) 如果\\(p_{i+k+1}=p_{m+k+1}\\)，则\\(next_{[m+k+1]}==next_{[m+k]}+1\\) 如果\\(p_{i+k+1}!=p_{m+k+1}\\)，有\\(next_{[i+k]}=k\\)，表示\\(p_0…p_{k}=p_i…p_{i+k}=p_m…p_{m+k}\\)， 如果\\(p_{m+k+1}=p_{k+1}\\)，则\\(next_{[m+k+1]}=next_{[k]}+1\\) 如果\\(p_{m+k+1}!=p_{k+1}\\)，则有\\(next_{[k]}=l\\)，继续上面的过程 总结下来，若\\(next_{[i]}==next_{[j]}\\) if \\(p_{i+1}=p_{j+1}\\), then \\(next_{[j+1]}==next_{[j]+1}\\) else \\(i==next_{[i]}\\),继续上一步 实现代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class KMP &#123; private int[] getNextArr(char[] pattern) &#123; if (pattern == null || pattern.length == 1) &#123; return new int[]&#123;-1&#125;; &#125; int[] next = new int[pattern.length]; next[0] = -1; next[1] = 0; int currentNext=0; int pos = 2; while (pos &lt; pattern.length) &#123; if (pattern[pos - 1] == pattern[currentNext]) &#123; next[pos++] = ++currentNext; &#125; else if (currentNext &gt; 0) &#123; currentNext = next[currentNext]; &#125; else &#123; next[pos++] = 0; &#125; &#125; return next; &#125; public int getIndexOf(String ori, String pattern) &#123; if (ori.length() &lt; pattern.length()) &#123; return -1; &#125; char[] oriArr = ori.toCharArray(); char[] patternArr = pattern.toCharArray(); int indexOfOri = 0; int indexOfPattern = 0; int[] next = getNextArr(patternArr); while (indexOfOri &lt; oriArr.length &amp;&amp; indexOfPattern &lt; patternArr.length) &#123; if (oriArr[indexOfOri] == patternArr[indexOfPattern]) &#123; indexOfOri++; indexOfPattern++; &#125; else if (next[indexOfPattern] &gt;= 0) &#123; indexOfPattern = next[indexOfPattern]; &#125; else &#123; indexOfOri++; &#125; &#125; return indexOfPattern == patternArr.length ? indexOfOri - indexOfPattern : -1; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://langonggong.com/tags/算法/"},{"name":"字符串匹配","slug":"字符串匹配","permalink":"http://langonggong.com/tags/字符串匹配/"}]},{"title":"内存屏障","date":"2018-08-23T15:15:18.000Z","path":"2018/08/23/内存屏障/","text":"内存屏障的目的每个CPU都会有自己的缓存（有的甚至L1,L2,L3），缓存的目的就是为了提高性能，避免每次都要向内存取。但是这样的弊端也很明显：不能实时的和内存发生信息交换，分在不同CPU执行的不同线程对同一个变量的缓存值不同 内存屏障的作用硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见 内存屏障有两个作用 阻止屏障两侧的指令重排序 强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效 java内存屏障内存屏障可以被分为以下几种类型: LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能 volatile语义中的内存屏障volatile的内存屏障策略非常严格、悲观 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障 在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障 volatile重排序规则： volatile写与之前的读写不能重排序 volatile读与之后的读写不能重排序 相邻的volatile之间不能重排序 volatile内存屏障规则： volatile写之前，所有的读写都必须已经完成 volatile读结束后，所有的读写才能开始 相邻的volatile必须有序实行 final语义中的内存屏障 新建对象过程中，构造体中对final域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序 123x.finalField = v; ... ;构建方法边界sharedRef = x;v.afield = 1; x.finalField = v; ... ; 构建方法边界sharedRef = x;这两条语句中，构建方法边界前后的指令都不能重排序。 初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序 1x = sharedRef; ... ; i = x.finalField; 为了保证final字段的特殊语义，也会在下面的语句加入内存屏障 1x.finalField = v; StoreStore; sharedRef = x; 参考链接 内存屏障 JVM内存模型、指令重排、内存屏障概念解析 java内存模型 内存屏障","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"},{"name":"java内存模型","slug":"java内存模型","permalink":"http://langonggong.com/tags/java内存模型/"}]},{"title":"volatile","date":"2018-08-23T12:54:28.000Z","path":"2018/08/23/volatile/","text":"内存可见性volatile变量在每次被线程访问时，都强迫从主内存中重读该变量的值，而当该变量发生变化时，又会强迫线程将最新的值刷新到主内存。这样任何时刻，不同的线程总能看到该变量的最新值 线程写volatile变量的过程 改变线程工作内存中volatile变量副本的值 将改变后的副本的值从工作内存刷新到主内存 线程读volatile变量的过程 从主内存中读取volatile变量的最新值到线程的工作内存中 从工作内存中读取volatile变量的副本 禁止指令重排序多线程版本(错误的)123456789101112class Foo &#123; private Helper helper = null; public Helper getHelper() &#123; if (helper == null) synchronized(this) &#123; if (helper == null) helper = new Helper(); &#125; return helper; &#125; // other functions and members... &#125; volatile关键字修改版123456789101112class Foo &#123; private volatile Helper helper = null; public Helper getHelper() &#123; if (helper == null) &#123; synchronized (this) &#123; if (helper == null) helper = new Helper(); &#125; &#125; return helper; &#125;&#125; 在给helper对象初始化的过程中，jvm做了下面3件事: 给helper对象分配内存 调用构造函数 将helper对象指向分配的内存空间 由于jvm的”优化”,指令2和指令3的执行顺序是不一定的，当执行完指定3后，此时的helper对象就已经不在是null的了,但此时指令2不一定已经被执行。 假设线程1和线程2同时调用getHelper()方法，此时线程1执行完指令1和指令3，线程2抢到了执行权，此时helper对象是非空的 volatile关键字可以保证jvm执行的一定的“有序性”，在指令1和指令2执行完之前，指定3一定不会被执行 volatile变量被修改后立刻刷新会驻内存中 不保证复合操作的原子性1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 线程A读取最新的值并在工作内存修改后，还未更新到主存就耗尽cpu时间片，等再次获取时间片后主存的变量值已被线程B修改，但线程A并未感知，继续将值更新到主存，导致B的修改无效","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"}]},{"title":"hexo高级特性","date":"2018-08-19T08:35:51.000Z","path":"2018/08/19/cool/","text":"网易云通过外链添加在网易云音乐的网页版生成歌单外链 1&lt;iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=450 src=\"//music.163.com/outchain/player?type=0&amp;id=2343741251&amp;auto=1&amp;height=430\"&gt;&lt;/iframe&gt; 通过aplayer插件MeingJS 支持id为网页上url后面的id值1&#123;% meting \"468513829\" \"netease\" \"song\" \"autoplay\" \"mutex: true\" \"listmaxheight:340px\" \"preload:none\" \"theme:#ad7a86\"%&#125; 1&#123;% meting \"384485381\" \"netease\" \"playlist\" \"autoplay\" \"mutex: true\" \"listmaxheight:340px\" \"preload:none\" \"theme:#ad7a86\"%&#125; 行间公式 f(n)=\\begin{cases} n/2, & \\text{如果$ x2 $} \\end{cases}行内公式比如 \\(x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\\)","tags":[{"name":"hexo","slug":"hexo","permalink":"http://langonggong.com/tags/hexo/"},{"name":"新特性","slug":"新特性","permalink":"http://langonggong.com/tags/新特性/"}]},{"title":"mysql","date":"2018-08-19T05:47:35.000Z","path":"2018/08/19/mysql/","text":"基本概念mysql体系结构 参考链接 存储引擎 特点 MyISAM BDB Memory InnoDB Archive 存储限制 没有 没有 有 64TB 没有 事务安全 支持 支持 锁机制 表锁 页锁 表锁 行锁 行锁 B数索引 支持 支持 支持 支持 哈希索引 支持 支持 全文索引 支持 集群索引 支持 数据缓存 支持 支持 索引缓存 支持 支持 支持 数据可压缩 支持 支持 空间使用 低 低 N/A 高 非常低 内存使用 低 低 中等 高 低 批量插入的速度 高 高 高 低 非常高 支持外键 支持 InnoDB与MyISAM原理比较 InnoDB与MyISAM索引比较 索引索引的类型B-Tree索引参考链接B树中关键字集合分布在整棵树中，叶节点中不包含任何关键字信息，而B+树关键字集合分布在叶子结点中，非叶节点只是叶子结点中关键字的索引 Hash索引B Tree索引和哈希索引的区别 缺点不支持范围查询和排序、最左匹配规则 空间(R-Tree)索引 参考链接 全文(Full-text)索引类似es搜索的Lucene分词策略 参考链接 索引策略前缀索引高性能mysql章节 概念使用该列开始的部分长度字符串作 注意选择足够长的前缀以保证较高的选择性，同时又不能太长以便节约空间 缺点mysql无法使用其前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描 多列索引mysql多列索引的生效规则 聚簇索引(Clustered Indexes)及二级索引(辅助索引)高性能mysql章节 InnoDB与MyISAM的主键索引和二级索引的区别 聚集索引表数据按照索引的顺序来存储的，也就是说索引项的顺序与表中记录的物理顺序一致。对于聚集索引，叶子结点即存储了真实的数据行，不再有另外单独的数据页。 在一张表上最多只能创建一个聚集索引，因为真实数据的物理顺序只能有一种 非聚集索引表数据存储顺序与索引顺序无关。对于非聚集索引，叶结点包含索引字段值及指向数据页数据行的逻辑指针，其行数量与数据表行数据量一致 覆盖索引(Covering Indexes)建立索引的字段正好是覆盖查询语句[select子句]与查询条件[Where子句]中所涉及的字段,数据列只用从索引中就能够取得，不必从数据表中读取参考&lt;&lt;高性能mysql&gt;&gt; 参考链接参考链接 其他压缩(前缀压缩)索引参考链接 重复索引相同列上按照相同的顺序创建的相同类型的索引 冗余索引若存在索引(a,b),则(a)是冗余,因为a是前缀,(a,b)可以当成(a)使用;（b,a）和(b)不是冗余索引 分形树(fractal treeindex)索引块级别元数据 Infobright高性能数据仓库 查询优化explain关键字参考链接 查询路径 参考链接 joinjoin原理 JOIN算法 Nested-Loop Join Simple Nested-Loop Join Index Nested-Loop Join Block Nested-Loop Join 哈希关联 合并连接 mysql高级特性分库、分区、分表、分片参考链接 视图内部存储代码存储过程函数触发器事件其他游标绑定变量XA查询缓存主从复制mvcc与锁MVCC原理 快照读当前读","tags":[{"name":"mysql","slug":"mysql","permalink":"http://langonggong.com/tags/mysql/"},{"name":"DB","slug":"DB","permalink":"http://langonggong.com/tags/DB/"}]},{"title":"spring cloud","date":"2018-08-19T05:12:12.000Z","path":"2018/08/19/springcloud/","text":"基础知识 四大神器 auto-configuration starters cli：Spring Boot Commad Line Autuator监控 服务注册与发现Eureka 参考链接 Feature Consul zookeeper etcd Eureka 服务健康检查 服务状态，内存，硬盘等 (弱)长连接，keepalive 连接心跳 可配支持 多数据中心 支持 — — — kv存储服务 支持 支持 支持 — 一致性 raft paxos raft — cap ca cp cp ap 使用接口(多语言能力) 支持http和dns 客户端 http/grpc http（sidecar） watch支持 全量/支持long polling 支持 支持 long polling 支持 long polling/大部分增量 自身监控 metrics — metrics metrics 安全 acl /https acl https支持（弱） — spring cloud集成 已支持 已支持 已支持 已支持 CAP理论与BASE思想服务发现的方式 客户端发现 服务器端发现 负载均衡LB方案参考链接1 参考链接2 硬负载 软负载 DNS负载 CDN负载 Ribbon核心组件 ServerList 用于获取地址列表。它既可以是静态的(提供一组固定的地址)，也可以是动态的(从注册中心中定期查询地址列表) ServerListFilter 仅当使用动态ServerList时使用，用于在原始的服务列表中使用一定策略过虑掉一部分地址 IRule 选择一个最终的服务地址作为LB结果。选择策略有轮询、根据响应时间加权、断路器(当Hystrix可用时)等 rest调用Feign容错处理参考链接1参考链接2 Hystrix 限流 降级 熔断 Dashboard 服务监控Turbine 聚合监控微服务网关Zuul过滤器机制 标准过滤器类型 PRE 鉴权 流量转发 ROUTING POST 跨域 统计 ERROR request生命周期 参考链接1 参考链接2 稳定性 隔离机制 重试机制 主要功能 验证与安全保障 审查与监控 动态路由 压力测试 负载分配 静态响应处理 多区域弹性 微服务配置Spring Cloud Config Spring Cloud Bus 参考链接 提交代码触发post请求给bus/refresh server端接收到请求并发送给Spring Cloud Bus Spring Cloud bus接到消息并通知给其它客户端 其它客户端接收到通知，请求Server端获取最新配置 全部客户端均获取到最新的配置 微服务跟踪Spring Cloud SleuthZipKinDocker入门Docker Compose","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"http://langonggong.com/tags/spring-cloud/"},{"name":"网关","slug":"网关","permalink":"http://langonggong.com/tags/网关/"},{"name":"docker","slug":"docker","permalink":"http://langonggong.com/tags/docker/"}]},{"title":"java-concurrency","date":"2018-08-19T04:48:15.000Z","path":"2018/08/19/java-concurrency/","text":"concurrent包 locks(锁) 锁的种类锁分类1锁分类2 公平锁/非公平锁 可重入锁 可中断锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 自旋锁 锁的优化锁的优化 减少锁持有时间 减小锁粒度 锁分离 锁粗化 锁消除 AQS参考链接参考1参考2AQS、ReetrantLock、Condition实现原理 重要方法: isHeldExclusively() tryAcquire(int) tryRelease(int) tryAcquireShared(int) tryReleaseShared(int) Lock参考链接参考1参考2 重要方法 lock() lockInterruptibly() throws InterruptedException tryLock() tryLock(long time, TimeUnit unit) throws InterruptedException unlock() Condition newCondition() ReentrantLock 参考链接 参考1 ReentrantReadWriteLock 参考链接参考1参考2 condition参考链接 生产者、消费者三种实现 atomic(原子变量) AtomicInteger AtomicLong AtomicBoolean AtomicReference AtomicIntegerArray/AtomicLongArray/AtomicReferenceArray CASUnsafe类ABA问题 executor(线程池)参考链接 框架类图 ThreadPoolExecutor 构造方法和规则 执行原理 线程池终止 关键参数 workQueue(排队策略) threadFactory RejectedExecutionHandler(饱和策略) 常用方法 Executors 创建线程池 newFixedThreadPool newCachedThreadPool newSingleThreadExecutor newScheduledThreadPool collections(并发容器)List和Set CopyOnWriteArrayList 参考1 CopyOnWriteArraySet 参考1 Map ConcurrentHashMap 参考 ConcurrentSkipListMap 参考 ConcurrentSkipListSet Queue ArrayBlockingQueue 123final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull; notEmpty和notFull是锁的两个Condition条件 实现原理 LinkedBlockingQueue LinkedBlockingDeque ConcurrentLinkedQueue ConcurrentLinkedDeque tools(同步工具) CountDownLatch CyclicBarrier Semaphore java内存模型java内存模型synchronized原理 内存模型概述 主内存 工作内存 Java内存模型与硬件内存架构的关系 特性 原子性 可见性 有序性 重排序 指令重排 编译器重排 as-if-serialhappens-before 原则 程序顺序原则 锁规则 volatile规则 线程启动规则 传递性 线程终止规则 线程中断规则 对象终结规则 volatile内存语义 可见性 禁止重排优化 内存屏障（Memory Barrier）参考链接 LoadLoad Barriers StoreStore Barriers LoadStore Barriers StoreLoad Barriers","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://langonggong.com/tags/多线程/"},{"name":"jvm","slug":"jvm","permalink":"http://langonggong.com/tags/jvm/"}]},{"title":"Elasticsearch常用搜索","date":"2018-08-19T04:41:41.000Z","path":"2018/08/19/Elasticsearch/","text":"多字段查找multi_match 以下表达式等价于field1 = value1 or field2 = value1 12345678910GET index/type/_search&#123; \"query\": &#123; \"multi_match\": &#123; \"query\": \"value1\", \"fields\": [\"field1\",\"field2\"] &#125; &#125; , \"_source\": [\"field1\",\"field2\"]&#125; 布尔查询must等价于and,must_not等价于not, should等价于or 以下表达式等价于( field1 = value1 or field2 = value2 ) and field3 != value3 123456789101112131415161718192021222324252627282930313233343536GET index/type/_search&#123; \"size\": 100, \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"bool\": &#123; \"should\": [ &#123; \"match\": &#123; \"field1\": \"value1\" &#125; &#125;, &#123; \"match\": &#123; \"field2\": \"value2\" &#125; &#125; ] &#125; &#125; ], \"must_not\": [ &#123; \"match\": &#123; \"field3\": \"value3\" &#125; &#125; ] &#125; &#125;, \"_source\": [ \"field1\",\"field2\",\"field3\" ]&#125; 模糊查询fuzziness 参考链接 123456789101112131415161718192021GET index/type/_search&#123; \"size\": 100, \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match\": &#123; \"city\": &#123; \"query\": \"Hoiliste\", \"fuzziness\": \"auto\" &#125; &#125; &#125; ] &#125; &#125;, \"_source\": [ \"city\" ]&#125; 通配符查询*匹配零个或多个字符 1234567891011121314151617181920GET index/type/_search&#123; \"size\": 100, \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"wildcard\": &#123; \"field1\": &#123; \"value\": \"wu*\" &#125; &#125; &#125; ] &#125; &#125;, \"_source\": [ \"field1\" ]&#125; 正则查询regexp 123456789101112GET index/type/_search&#123; \"size\": 100, \"query\": &#123; \"regexp\":&#123; \"field1\":\"[a-zA-Z]+[0-9]*\" &#125; &#125;, \"_source\": [ \"field1\" ]&#125; 范围查询range 1234567891011121314151617GET index/type/_search&#123; \"size\": 100, \"query\": &#123; \"range\": &#123; \"field1\": &#123; \"from\": \"2018-04-16 05:22:39\", \"to\": \"2018-06-23 05:22:39\", \"include_lower\": true, \"include_upper\": true &#125; &#125; &#125;, \"_source\": [ \"field1\" ]&#125; 排序sort 1234567891011121314151617GET index/type/_search&#123; \"size\": 100, \"query\": &#123; \"bool\": &#123;&#125; &#125;, \"sort\": [ &#123; \"field1\": &#123; \"order\": \"desc\" &#125; &#125; ], \"_source\": [ \"field1\" ]&#125; 多重过滤filter 12345678910111213141516171819202122232425262728GET index/type/_search&#123; \"size\": 100, \"query\": &#123; \"bool\": &#123; \"filter\": [ &#123; \"bool\": &#123; \"must\": &#123; \"term\": &#123; \"field1\": \"value1\" &#125; &#125; &#125; &#125;, &#123; \"bool\": &#123; \"must\": &#123; \"term\": &#123; \"field2\": \"value1\" &#125; &#125; &#125; &#125; ] &#125; &#125;, \"_source\": [\"cityTerm\", \"mlsOrgId\"]&#125; 脚本查询参考链接 script支持Groovy、java等多种语言的脚本 12345678910111213141516171819&#123; \"query\": &#123; \"bool\": &#123; \"filter\": [ &#123; \"bool\": &#123; \"filter\": &#123; \"script\": &#123; \"script\": &#123; \"inline\": \"doc['field1'].value - doc['field2'].value &gt; 0\" &#125; &#125; &#125; &#125; &#125; ] &#125; &#125;&#125;","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://langonggong.com/tags/Elasticsearch/"},{"name":"DSL","slug":"DSL","permalink":"http://langonggong.com/tags/DSL/"}]},{"title":"mysql分库、分区、分表、分片","date":"2018-08-19T01:20:32.000Z","path":"2018/08/19/mysql分库、分区、分表、分片/","text":"分表概念mysql的分表是真正的分表，一张表分成很多表后，每一个小表都是完正的一张表，都对应三个文件（MyISAM引擎：一个.MYD数据文件，.MYI索引文件，.frm表结构文件）分表后数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面 适用场景 一张表的查询速度已经慢到影响使用的时候 当频繁插入或者联合查询时，速度变慢 实现利用merge存储引擎来实现分表 1234567891011121314151617181920CREATE TABLE `tb_member1` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL, `sex` tinyint(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`)) ENGINE=MyISAM AUTO_INCREMENT=2 DEFAULT CHARSET=utf8CREATE TABLE `tb_member2` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL, `sex` tinyint(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`)) ENGINE=MyISAM AUTO_INCREMENT=2 DEFAULT CHARSET=utf8CREATE TABLE `tb_member` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL, `sex` tinyint(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`)) ENGINE=MRG_MyISAM DEFAULT CHARSET=utf8 INSERT_METHOD=LAST UNION=(`tb_member1`,`tb_member2`) 说明 分表数据库引擎是MyISAM 分表与主表的字段定义一致 参考链接参考链接1 参考链接2 分区概念把存放数据的文件分成了许多小块，分区后的表还是一张表 适用场景 一张表的查询速度已经慢到影响使用的时候 表中的数据是分段的 对数据的操作往往只涉及一部分数据，而不是所有的数据 历史数据或不常访问的数据占很大部分，最新或热点数据占的比例不是很大，可以根据有些条件进行表分区。例如，表中有大量的历史记录，而“热数据”却位于表的末尾 分区类型 分区类型 特点 RANGE 基于属于一个给定连续区间的列值，把多行分配给分区 LIST 类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择 HASH 基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式 KEY 类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值 操作方式创建分区 1234567891011CREATE TABLE sales ( id INT AUTO_INCREMENT, amount DOUBLE NOT NULL, order_day DATETIME NOT NULL, PRIMARY KEY(id, order_day)) ENGINE=Innodb PARTITION BY RANGE(YEAR(order_day)) ( PARTITION p_2010 VALUES LESS THAN (2010), PARTITION p_2011 VALUES LESS THAN (2011), PARTITION p_2012 VALUES LESS THAN (2012),PARTITION p_catchall VALUES LESS THAN MAXVALUE); 常用操作 参考链接参考链接1 参考链接2 分库参考链接 分片参考链接","tags":[{"name":"mysql","slug":"mysql","permalink":"http://langonggong.com/tags/mysql/"}]},{"title":"java虚拟机","date":"2018-08-18T22:07:10.000Z","path":"2018/08/19/java虚拟机/","text":"运行时数据区 Java堆（Heap）对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区（Method Area）方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 程序计数器（Program Counter Register）程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈（JVM Stacks）与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。运行时栈帧结构 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stacks）本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 对象的访问定位句柄方式如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息 优点使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改 直接指针方式如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址 优点使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本 GC对象存活分析引用计数法原理给对象中每一个对象分配一个引用计数器，每当有地方引用该对象时，引用计数器的值加一，当引用失效时，引用计数器的值减一，不管什么时候，只要引用计数器的值等于0了，说明该对象不可能再被使用了 优缺点实现原理简单，而且判定效率很高。大部分情况下都是一个不错的算法。但很难解决对象之间相互循环引用的问题 可达性分析原理通过一系列被称为“GC Roots‘’的对象作为起始点，从这些节点向下搜索，搜索所走过的路径叫做引用链，当一个节点到GC Roots没有任何引用链时，证明该对象不可用了 被作为GC Roots的对象有以下几种: 虚拟机栈中引用的对象（栈帧中的引用变量表） 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中Native方法（JNI）引用的对象 方法区的垃圾回收永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类 废弃常量回收回收废弃常量与回收Java堆中的对象非常相似。以常量池中字面量的回收为例，若字符串“abc”已经进入常量池中，但当前系统没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用该字面量，若发生内存回收，且必要的话，该“abc”就会被系统清理出常量池。常量池中其他的类（接口）、方法、字段的符号引用与此类似 无用的类回收 该类所有的实例都已经被回收，即Java堆中不存在该类的任何实例 加载该类的ClassLoader已经被回收 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法 在大量使用反射、动态代理、CGLib等bytecode框架的场景，以及动态生成JSP和OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出 新生代、老年代以及永久代 堆大小 = 新生代 + 老年代 新生代1个Eden区和2个Survivor区（分别叫from和to）,默认比例为8：1。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。 因为年轻代中的对象基本都是朝生夕死的(80%以上)，所以在年轻代的垃圾回收算法使用的是复制算法 在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To” 老年代老年代与新生代不同，对象存活的时间比较长，比较稳定，因此采用标记（Mark）算法来进行回收 永久代在JDK的HotSpot虚拟机中，可以认为方法区就是永久代，但是在其他类型的虚拟机中，没有永久代的概念 GC分类 Minor GC 发生在新生代中的垃圾收集动作，所采用的是复制算法 FullGC (Major GC) 发生在老年代的垃圾收集动作，所采用的是标记-清除算法 JVM内存管理参数JVM参数使用总结 -Xms 设置堆的最小空间大小 -Xmx 设置堆的最大空间大小 -XX:NewSize 设置新生代最小空间大小 -XX:MaxNewSize 设置新生代最大空间大小 -Xmn:设置新生代的内存空间大小 -XX:PermSize 设置永久代最小空间大小 -XX:MaxPermSize 设置永久代最大空间大小 -Xss 设置每个线程的堆栈大小。 -XX:NewRatio 设置新生代和老生代的相对大小 -XX:SurvivorRatio 指定Eden区和Survivor区的大小比例,注意两个幸存区是一样大的 垃圾收集算法 复制算法(新生代)该算法的核心是将可用内存按容量划分为大小相等的两块, 每次只用其中一块, 当这一块的内存用完, 就将还存活的对象复制到另外一块上面, 然后把已使用过的内存空间一次清理掉 标记清除算法(老年代)(mark-sweep)该算法分为“标记”和“清除”两个阶段: 首先标记出所有需要回收的对象(可达性分析), 在标记完成后统一清理掉所有被标记的对象 该算法会有以下两个问题 效率问题: 标记和清除过程的效率都不高; 空间问题: 标记清除后会产生大量不连续的内存碎片, 空间碎片太多可能会导致在运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集 标记整理算法(老年代)(mark-compact)标记清除算法会产生内存碎片问题, 而复制算法需要有额外的内存担保空间, 于是针对老年代的特点, 又有了标记整理算法. 标记整理算法的标记过程与标记清除算法相同, 但后续步骤不再对可回收对象直接清理, 而是让所有存活的对象都向一端移动,然后清理掉端边界以外的内存 垃圾收集器 GC收集器内存分配、GC原理与垃圾收集器 串行收集器 Serial开头的 Serial Serial Old(MSC) 并行收集器 Parallel开头的 ParNew Parallel Scavenge Parallel Old 并发收集器 CMS (Concurrent Mark Sweep) G1(Garbage First) 图片中的问号位置 JDK 1.7后有G1 说明： Parallel Scanvenge 也叫吞吐量优先收集器，吞吐量=运行用户代码时间/(运行用户代码时间 + GC时间)。停顿时间短，适合与用户交互的程序；高吞吐量，可以有效利用CPU时间，尽管完成计算任务，适合后台运算而不需要太多交互的任务 CMS 目标：最短回收停顿时间。并发收集，低停顿，适合B/S架构，需要低延迟时间的应用需求 GC日志日志格式 1[GC（GC类型，当前是Minor GC） (Allocation Failure) [DefNew（GC的区域，当前为新生代）: 5688K（垃圾回收前的大小）-&gt;790K（垃圾回收以后的大小）(9216K)（该区域总大小）, 0.0060899 secs] 5688K（堆在垃圾回收前的大小）-&gt;4886K（堆在垃圾回收后的大小）(19456K)（堆的总大小）, 0.0061183 secs] [Times: user=0.00（用户态消耗CPU时间） sys=0.01（内核态小时CPU时间）, real=0.00 secs（操作的实际时间）] 理解GC日志GC收集器与GC日志 大对象直接进入老年代 长期存活的对象进入老年代 Class文件结构 参考系列 类加载机制 参考链接参考章节 加载 通过一个类的全限定名来获取其定义的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口 除了可以使用系统提供的引导类加载器外，还可以使用用户自定义的类加载器。任意一个类，都需要由加载它的类加载器和这个类本身共同确定其在Java 虚拟机中的唯一性 类加载器 启动类加载器：启动类加载器无法被 java 程序直接引用，如需要，直接使用 null 代替即可 扩展类加载器 应用程序类加载器：它负责加载用户路径(ClassPath)上所指定的类库，开发者可以使用这个类加载器，如果应用程序没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器 双亲委派模型如果一个类加载器收到了类加载器的请求，它首先不会自己尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类时），子加载类才会尝试自己去加载 验证验证阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全 文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求，主要是验证类的继承关系、数据类型是否符合 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。对类的方法体进行校验分析，以保证被校验类的方法在运行时不会做出危害虚拟机安全的事件 符号引用验证：发生在虚拟机将符号引用转化为直接引用的时候,对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配 这阶段进行内存分配的仅包括类变量（即被static修饰的变量），不包括实例变量 这里所说的初始值“通常情况”下是数据类型的零值 解析解析阶段是虚拟机将常量池中的符号引用转化为直接引用的过程 符号引用（Symbolic References）：即用一组符号来描述所引用的目标。它与虚拟机的内存布局无关，引用的目标不一定已经加载到内存中 直接引用（Direct References）：直接引用可以是指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。它是和虚拟机内存布局相关的，如果有了直接引用，那引用的目标必定已经在内存中存在了 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7类符号引用进行 初始化初始化是类加载过程的最后一步，此阶段才开始真正执行类中定义的Java程序代码（或者说字节码，也仅限与执行()方法）。在准备阶段，我们已经给变量付过一次系统要求的初始值（零值），而在初始化阶段，则会根据程序员的意愿给类变量和其他资源赋值。主要是通过()方法来执行的 虚拟机字节码执行引擎章节参考 Java编译期优化 解析与填充符号表过程解析步骤包含了词法分析和语法分析两个过程，首先词法分析是将源代码的字符流转变成为标记集合（token），然后语法分析是根据token序列来构造抽象语法树（一种用来描述程序代码语法结构的树状表示方式）。完成词法分析和语法分析之后，下一步是填充符号表，符号表是由一组符号地址和符号信息构成的表格，符号表中所登记的信息在编译的不同阶段都要用到（比如语义分析中符号表所登记的内容将用于语义检查和产生中间代码，目标代码生成阶段当对符号名进行地址分配时，符号表是地址分配的依据） 插入式注解处理器的注解处理过程插入式注解处理器可以看做是一组编译器的插件，在这些插件里面，可以读取、修改、添加抽象语法树中的任意元素。如果这些插件在处理注解期间对语法树进行了修改，那么编译器将回到解析及填充符号表的过程重新处理，直到所有的插入式注解处理器都没有再对语法树进行修改为止 语义分析与字节码生成过程语法分析之后，编译器获得了程序代码的抽象语法树表示，语法树能够表示结构正确的源程序的抽象，但是无法保证源程序是否符合逻辑，而语义分析主要是对结构上正确的源程序进行上下文有关性质的检查 标注检查标注检查步骤检查的内容包括诸如变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配，等等。还有一个重要的动作称为常量折叠也在此阶段完成 数据及控制流分析数据及控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否有返回值、是否所有的受查异常都被正确处理了等问题 解语法糖语法糖是指在计算机语言中添加某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。java中的泛型，变长参数，自动拆箱与装箱，条件编译等就属于语法糖，它们在编译阶段就被还原成简单的语法结构（比如List和List在运行期间其实是同一个类） 字节码生成此过程是javac编译过程的最后一个阶段，字节码生成阶段将之前各个步骤所生成的信息转化成字节码写到磁盘中，另外还进行少量的代码添加和转换工作 Java运行期优化 在部分商用虚拟机中，java程序最初是通过解释器进行解释执行的，当虚拟机发现某个方法或代码块运行特别频繁，就会把这些代码认定为“热点代码”，为了提高热点代码的执行效率，在运行时，虚拟机就会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为即时编译器或JIT编译器。 即时编译器并不是虚拟机必须的部分，但是即时编译器编译性能的好坏、代码优化程度的高低确是衡量一款商用虚拟机优秀与否的最关键的指标之一。 众多主流的虚拟机都同时包含解释器和JIT编译器，解释器与JIT编译器各有优势：当程序需要迅速启动和执行时，解释器可以首先发挥作用，省去编译的时间，立即执行。当程序运行后，随着事件的推移，JIT编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率 会被即时编译器编译的热点代码有两类 被多次调用的方法体 被多次调用的循环体 即时编译器会以整个方法作为编译对象，将其编译成机器码。这种编译方式因为编译发生在方法执行过程之中，因此被称作栈上替换（OSR） 判断一段代码是否是热点代码的方式（热点探测）有两种 基于采样的热点探测：此方法会周期性检查各个线程的栈顶，如果发现某个或某些方法经常出现在栈顶，那么这个方法就是热点方法。此方法的缺点是很难精确地确认一个方法的热度，容易受到诸如线程阻塞等因素影响 基于计数器的热点探测：此方法会为每个方法甚至是代码块建立计数器，统计方法的执行次数，如果执行次数超过一个阀值就认为它是热点方法 默认设置下，执行引擎并不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成。当编译工作完成之后，这个方法的调用入口地址就会被系统自动改写成新的地址，下一次调用该方法时就会使用已编译的版本。也就是说，在编译器还未完成之前，执行引擎仍按照解释方式继续执行，而编译动作则在后台的编译线程中进行 优化技术一般来说即时编译器所产生的本地代码会比javac产生的字节码更优秀。即时编译器采用了一系列的技术来优化代码，比如公共子表达式消除，数组范围内检查消除，方法内联，逃逸分析等","tags":[{"name":"java","slug":"java","permalink":"http://langonggong.com/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://langonggong.com/tags/jvm/"}]}]